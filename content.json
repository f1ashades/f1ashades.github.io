{"meta":{"title":"f1ashades' blogs","subtitle":"","description":"once again I am a child","author":"f1ashades","url":"http://example.com","root":"/"},"pages":[{"title":"categories","date":"2022-06-05T08:58:34.000Z","updated":"2022-06-05T09:42:38.092Z","comments":false,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2022-06-05T09:03:17.000Z","updated":"2022-06-05T09:04:01.712Z","comments":false,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"计网-网络层","slug":"3.计网-网络层","date":"2022-04-15T03:36:48.000Z","updated":"2022-06-23T10:30:23.388Z","comments":true,"path":"2022/04/15/3.计网-网络层/","link":"","permalink":"http://example.com/2022/04/15/3.%E8%AE%A1%E7%BD%91-%E7%BD%91%E7%BB%9C%E5%B1%82/","excerpt":"计算机网络&#x3D; . &#x3D;","text":"计算机网络&#x3D; . &#x3D; 三、net-work1.IPv4地址1）分类编址①A类地址 A类地址网络号占8比特，主机号占24比特 网络号最高位固定为0 注意： 最小网络号是全0，保留不指派 最小可分配网络号：00000001 ——&gt; 1 最大可分配网络号：01111110 ——&gt; 126 最小本地环回测试地址主机号为1，因为全0就是127.0.0.0代表网络号 最大本地环回测试地址主机号为255-1（最后一位为0），因为全1就是127.255.255.255代表广播地址了 ②B类地址 B类地址网络号和主机号分别占16比特 B类地址网络号前两位固定为10 注意： 最小可分配网络号：10000000 . 00000000 ——&gt; 127.0 最大网可分配络号：10111111 . 11111111 ——&gt; 191(2^7+2^6-1).255 ③C类地址 C类地址网络号占24位，主机号占8位 C类地址网络号前三位固定为110 注意： 最小可分配网络号：11000000.00000000.00000000 ——&gt; 192.0.0 最大可分配网络号：11011111 . 11111111.11111111 ——&gt; 223(2^7+2^6+2^5-1).255.255 2）划分子网编址 ①子网掩码 ②eg1 218开头是110，所以这是一个C类地址，其子网掩码255.255.255.128（前三部分为C类网络号，最后从主机号借用的地址） 可以看出从主机号中借用了1位，1位可以划分出两个子网（0,1），每个子网有7位可以来编码 ②eg2 ③eg3 3）无分类编址 ①eg1②eg2 ③路由聚合（构建超网） 对于图中R1连接了5个网络，若R1要将这五个网络信息发送给R2，就需要发送5个路由信息给R2（也就是需要5个网络编号）： 很显然，这五个网络网络号中由很多部分是共同前缀的，那么这部分能不能采用CIDR路由聚合成一个网络再发送给R2来降低路由表大小呢，显然是可以的： 因此其聚合地址块为： 这样就把5条记录缩小到一条记录，当R2的目的网络是该聚合地址块就会跳R1 在路由过程中，我们可以得出两个结论： 网络前缀越长，地址块越小（主机号），路由约具体。 若地址块转发分组时发现由多条路由可选，则选择网络前缀最长的那条，这样子的路由更具体（网络号越长，说明再继续聚合的可能性越低，也就越具体） ④eg3 ⑤eg4 2.IP首部格式 1）版本 2）首部长度 3）可选字段 4）填充字段 5）区分服务字段 6）总长度字段 eg： 7）标识、标志、片偏移字段 ①数据报分片 ②eg 8）生存时间 9）协议字段 10）首部检验和 11）源IP地址、目的IP地址字段 3.ICMP1）差错报文 ①终点不可达 ②源点抑制 ③时间超过 ④参数问题 ⑤改变路由 ⑥不发送给ICMP差错报告报文情况 2）ICMP询问报文回送回答和回答报文： ICMP回送回答报文是由主机和路由向一个特定的目的主机发出的询问 收到此报文的主机必须给源主机或路由器发送ICMP回送回答报文 主要用来测试目的站是否可达以及了解其有关状态 时间戳请求和回答： ICMP时间戳请求报文时请某个主机或路由器回答当前的日期和时间 ICMP时间戳回答报文中有一个32位的字段，写入的整数代表从1900年1月1日到当前时刻一共有多少秒 主要用来进行时钟同步和测量时间 3）应用①PING 用来测试主机或路由器之间的连通性 应用层直接使用网际层的ICMP(没有经过运输层的TCP或UDP) 使用ICMP回送请求和回答报文 ②traceroute 跟踪路由traceroute实现原理： ​ 简单来说，就是先发送一个TTL &#x3D; 1的报文，当TTL到达第一个主机后TTL变为0，此时路由器会回送时间超过差错报文，此时就能知道第一个路由位置。此时源主机再发送TTL &#x3D; 2 的报文，当TTL到达第二个主机后TTL变为0，此时路由器会回送时间超过差错报文，此时就能够知道第二个路由的地址。如此反复，直到到达最后一个路由。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"Spring Boot基本使用","slug":"spring Boot实用开发","date":"2022-04-12T04:06:12.000Z","updated":"2022-06-23T10:58:18.160Z","comments":true,"path":"2022/04/12/spring Boot实用开发/","link":"","permalink":"http://example.com/2022/04/12/spring%20Boot%E5%AE%9E%E7%94%A8%E5%BC%80%E5%8F%91/","excerpt":"一些Spring Boot的实用开发—_—","text":"一些Spring Boot的实用开发—_— 1.程序打包1）不带插件打包当我们**注释掉**如下pluging： 12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 执行mvn打包后会得到如下的package 而当我们运行会发现无法运行，出现以下情况 2）带插件打包当我们**添加**如下pluging： 12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 执行mvn打包后会得到如下的package 当我们执行该jar，发现可以正常执行： 3）两者对比①大小对比当我们查看两者的大小，可以看出带插件package后会大很多 当我们解压jar包中的内容 插件打包： 不带插件打包： ​ 通过以上对比，我们知道了，带插件打包为了让boot的jar独立运行，会将程序依赖的jar包一起打包，正是这些jar包导致了package出来的jar的大小较大 ②启动对比​ 在带插件package的最外层有一个org文件夹，其中有如下内容 进入目录：org\\springframework\\boot\\loader，在里面可以找到一个JarLauncher.class的文件，这显然是用于启动的class ​ 然后回到两个程序包的最外层目录，查看名称相同的文件夹META-INF下都有一个叫做MANIFEST.MF的文件，但是大小不同，打开文件，比较内容区别 小容量文件的MANIFEST.MF 12345Manifest-Version: 1.0Implementation-Title: springboot_08_ssmpImplementation-Version: 0.0.1-SNAPSHOTBuild-Jdk-Spec: 1.8Created-By: Maven Jar Plugin 3.2.0 大容量文件的MANIFEST.MF 123456789101112Manifest-Version: 1.0Spring-Boot-Classpath-Index: BOOT-INF/classpath.idxImplementation-Title: springboot_08_ssmpImplementation-Version: 0.0.1-SNAPSHOTSpring-Boot-Layers-Index: BOOT-INF/layers.idxStart-Class: com.itheima.SSMPApplication //引导类名Spring-Boot-Classes: BOOT-INF/classes/Spring-Boot-Lib: BOOT-INF/lib/Build-Jdk-Spec: 1.8Spring-Boot-Version: 2.5.4Created-By: Maven Jar Plugin 3.2.0Main-Class: org.springframework.boot.loader.JarLauncher //jar中需要执行的类，该类会找到引导类并执行 ​ 大文件中明显比小文件中多了几行信息，其中最后一行信息是Main-Class: org.springframework.boot.loader.JarLauncher。如果使用java -jar执行此程序包，将执行Main-Class属性配置的类，这个类恰巧就是前面看到的那个文件。SpringBoot打包程序中出现Spring框架的东西是为这里服务的。而这个org.springframework.boot.loader.JarLauncher类内部要查找Start-Class属性中配置的类，并执行对应的类。这个属性在当前配置中也存在，对应的就是我们的引导类类名。 现在我们就明白了这一组设定的作用： SpringBoot程序添加配置后会打出一个特殊的包，包含Spring框架部分功能，原始工程内容，原始工程依赖的jar包 首先读取MANIFEST.MF文件中的Main-Class属性，用来标记执行java -jar命令后运行的类 JarLauncher类执行时会找到Start-Class属性，也就是启动类类名 运行启动类时会运行当前工程的内容 运行当前工程时会使用依赖的jar包，从lib目录中查找 ​ SpringBoot打出来了包为了能够独立运行，将所有需要使用的资源全部都添加到了这个包里，这就是为什么这个jar包能独立运行的原因。 4）相关命令①windows12345678910# 查询端口netstat -ano# 查询指定端口netstat -ano |findstr &quot;端口号&quot;# 根据进程PID查询进程名称tasklist |findstr &quot;进程PID号&quot;# 根据PID杀死任务taskkill /F /PID &quot;进程PID号&quot;# 根据进程名称杀死任务，不常用，因为同一个进程名常常对应多个服务taskkill -f -t -im &quot;进程名称&quot; ​ ②linux123456#根据条件查询端口信息ps -ef | grep &quot;java -jar&quot; #后台执行并指定日志文件nohup java -jar &#x27;jar名&#x27; &gt; &#x27;文件名&#x27; 2&gt;&amp;1 &amp;#结束进程kiil -9 &#x27;pid&#x27; ​ 2.配置1）临时属性配置①命令行​ yml配置： 123456789server: port: 8080spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db username: root password: root ​ SpringBoot提供了灵活的配置方式，如果你发现你的项目中有个别属性需要重新配置，可以使用临时属性的方式快速修改某些配置。方法也特别简单，在启动的时候添加上对应参数就可以了。 1java –jar springboot.jar –-server.port=80 ​ 上面的命令是启动SpringBoot程序包的命令，在命令输入完毕后，空一格，然后输入两个-号。下面按照属性名&#x3D;属性值的形式添加对应参数就可以了。记得，这里的格式不是yaml中的书写格式，当属性存在多级名称时，中间使用点分隔，和properties文件中的属性格式完全相同。 ​ 如果你发现要修改的属性不止一个，可以按照上述格式继续写，属性与属性之间使用空格分隔。 1java –jar springboot.jar –-server.port=80 --spring.datasource.password=1234 ②idea中​ 打开SpringBoot引导类的运行界面，在里面找到配置项。其中Program arguments对应的位置就是添加临时属性的，可以加几个试试效果。 运行main方法的时候，arg所接收的参数就是这个位置配置的参数，通过这个args就可以获取到参数： 123public static void main(String[] args) &#123; SpringApplication.run(SSMPApplication.class,args);//提供args&#125; ​ Idea中配置的临时参数就是通过这个位置传递到我们的程序中的，如果不用这个args是不是就断开了外部传递临时属性的入口。我们可以使用下面的调用方式，这样外部临时属性就无法进入到SpringBoot程序中了。 123public static void main(String[] args) &#123; SpringApplication.run(SSMPApplication.class);//不提供args&#125; ​ 我们还可以通过以下的方式进行测试，这时候程序会认为参数是arg而不是args 12345public static void main(String[] args) &#123; String[] arg = new String[1]; arg[0] = &quot;--server.port=8082&quot;; SpringApplication.run(SSMPApplication.class, arg);&#125; ③属性加载优先级https://docs.spring.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-external-config Default properties (specified by setting SpringApplication.setDefaultProperties). @PropertySource annotations on your @Configuration classes. Please note that such property sources are not added to the Environment until the application context is being refreshed. This is too late to configure certain properties such as logging.* and spring.main.* which are read before refresh begins. Config data (such as application.properties files). A RandomValuePropertySource that has properties only in random.*. OS environment variables. Java System properties (System.getProperties()). JNDI attributes from java:comp/env. ServletContext init parameters. ServletConfig init parameters. Properties from SPRING_APPLICATION_JSON (inline JSON embedded in an environment variable or system property). Command line arguments. properties attribute on your tests. Available on @SpringBootTest and the test annotations for testing a particular slice of your application. @TestPropertySource annotations on your tests. Devtools global settings properties in the $HOME/.config/spring-boot directory when devtools is active. 其中，3就是程序内配置，11就是命令行配置，优先级↓（由上至下升高） 2）4级配置文件​ SpringBoot提供了配置文件和临时属性的方式来对程序进行配置，spring提供了4级配置文件： 类路径下配置文件（resources目录中的application.yml文件） 类路径下config目录下配置文件 程序包所在目录中配置文件 程序包所在目录中config目录下配置文件 ​ 它们的优先级如下： file ：config&#x2F;application.yml 【最高】 file ：application.yml classpath：config&#x2F;application.yml classpath：application.yml 【最低】 4级配置文件，相同的配置低级会被高级的覆盖，不同配置会一起生效，其使用环境如下 项目类路径配置文件：服务于开发人员本机开发与测试 项目类路径config目录中配置文件：服务于项目经理整体调控 工程路径配置文件：服务于运维人员配置涉密线上环境 工程路径config目录中配置文件：服务于运维经理整体调控 3）自定义配置文件​ 自定义配置文件方式有如下两种： 方式一：使用临时属性设置配置文件名，注意仅仅是名称，不要带扩展名 ​ 参数名：spring.config.name 方式二：使用临时属性设置配置文件路径，这个是全路径名 ​ 参数名：spring.config.location ​ 也可以设置加载多个配置文件 ​ 多个配置文件，优先级最高的是最后设置的这个配置文件 注意：使用的属性一个是pring.config.name，另一个是spring.config.location， 总结 配置文件可以修改名称，通过启动参数设定 配置文件可以修改路径，通过启动参数设定 微服务开发中配置文件通过配置中心进行设置 3.多环境开发1）配置多环境①单一文件​ 每个环境用—进行隔开 123456789101112131415161718192021222324spring: profiles: active: pro # 启动pro---spring: config: activate: on-profile: proserver: port: 80---spring: config: activate: on-profile: proserver: port: 81---spring: config: activate: on-profile: proserver: port: 82 ​ 其中关于环境名称定义上述格式是标准格式，过时格式如下： 12spring: profiles: test ②多文件主配置文件 123spring: profiles: active: pro # 启动pro application-pro.yaml 12server: port: 80 application-dev.yaml 12server: port: 81 ​ 文件的命名规则为：application-环境名.yml。 ​ 在配置文件中，如果某些配置项所有环境都一样，可以将这些项写入到主配置中，只有哪些有区别的项才写入到环境配置文件中。 主配置文件中设置公共配置（全局） 环境分类配置文件中常用于设置冲突属性（局部） 作用： 可以使用独立配置文件定义环境属性 独立配置文件便于线上系统维护更新并保障系统安全性 2）配置拆分将所有的配置根据功能对配置文件中的信息进行拆分，并制作成独立的配置文件，命名规则如下 application-devDB.yml application-devRedis.yml application-devMVC.yml ①include方式​ 使用include属性在激活指定环境的情况下，同时对多个环境进行加载使其生效，多个环境间使用逗号分隔 1234spring: profiles: active: dev include: devDB,devRedis,devMVC ​ 相当于加载dev配置时，再加载对应的3组配置，结构上很清晰，用了什么，对应的名称是什么 注意：加载的顺序是**devDB,devRedis,devMVC,dev**，dev是在最后才加载的 覆盖的顺序是后面覆盖前面（优先级高–&gt;低） ②group方式（主流）​ include的设置有一个问题，比如要切换dev环境为pro时，include也要修改，因为include属性只能使用一次。 ​ SpringBoot从2.4版开始使用group属性替代include属性，降低了配置书写量。 1234567spring: profiles: active: dev group: &quot;dev&quot;: devDB,devRedis,devMVC &quot;pro&quot;: proDB,proRedis,proMVC &quot;test&quot;: testDB,testRedis,testMVC ​ 现在再来看，如果切换dev到pro，只需要改以下active 注意：加载的顺序是**dev,devDB,devRedis,devMVC**，dev是最开始就加载了 覆盖的顺序是后面覆盖前面（优先级高–&gt;低） 3）maven控制环境​ 目前我们的环境还是由spring控制的，我们需要手动修改active，我们应该通过maven来控制这里选择的版本 1234567spring: profiles: active: dev group: &quot;dev&quot;: devDB,devRedis,devMVC &quot;pro&quot;: proDB,proRedis,proMVC &quot;test&quot;: testDB,testRedis,testMVC maven中设置多环境（使用属性方式区分环境） 123456789101112131415161718&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;env_dev&lt;/id&gt; &lt;properties&gt; &lt;profile.active&gt;dev&lt;/profile.active&gt; &lt;!--profile.active是自己定义的变量，方便我们取值--&gt; &lt;/properties&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;!--默认启动环境--&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;env_pro&lt;/id&gt; &lt;properties&gt; &lt;profile.active&gt;pro&lt;/profile.active&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt; SpringBoot中读取maven设置值 123spring: profiles: active: @profile.active@ ​ 上面的@属性名@就是读取maven中配置的属性值的语法格式，这样我们就通过了maven所定义的变量来控制环境了 4.日志1）使用日志步骤①：添加日志对象log 12345678910111213141516@RestController@RequestMapping(&quot;/books&quot;)public class BookController extends BaseClass&#123; //添加日志对象 private static final Logger log = LoggerFactory.getLogger(BookController.class); @GetMapping public String getById()&#123; //写日志 log.debug(&quot;debug...&quot;); log.info(&quot;info...&quot;); log.warn(&quot;warn...&quot;); log.error(&quot;error...&quot;); return &quot;springboot is running...2&quot;; &#125;&#125; ​ 上述代码中log对象就是用来记录日志的对象，下面的log.debug，log.info这些操作就是写日志的API了。 步骤②：设置日志输出级别 ​ 日志设置好以后可以根据设置选择哪些参与记录。这里是根据日志的级别来设置的。日志的级别分为6种，分别是： TRACE：运行堆栈信息，使用率低 DEBUG：程序员调试代码使用 INFO：记录运维过程数据 WARN：记录运维过程报警数据 ERROR：记录错误堆栈信息 FATAL：灾难信息，合并计入ERROR ​ 一般情况下，开发时候使用DEBUG，上线后使用INFO，运维信息记录使用WARN即可。下面就设置一下日志级别： 12# 开启debug模式，输出调试信息，常用于检查系统运行状况debug: true ​ 这么设置太简单粗暴了，日志系统通常都提供了细粒度的控制 1234567# 开启debug模式，输出调试信息，常用于检查系统运行状况debug: true# 设置日志级别，root表示根节点，即整体应用日志级别logging: level: root: debug ​ 还可以再设置更细粒度的控制 步骤③：设置日志组，控制指定包对应的日志输出级别，也可以直接控制指定包对应的日志输出级别 123456789101112logging: # 设置日志组 group: # 自定义组名，设置当前组中所包含的包 ebank: com.fla.controller,com.fla.service level: # 1.root相当于最大的group，整个项目都会记录到 root: warn # 2.为对应组设置日志级别（常用） ebank: debug # 3.为对包设置日志级别 com.itheima.controller: debug ​ 注意：记得导包 2）log对象创建1private static final Logger log = LoggerFactory.getLogger(BookController.class); 由于每个需要记录日志的类我们都需要一个这样的log对象，这样重读的地方我们应想办法解决 ①继承BaseClass： 123456789public class Baseclass &#123; private class clazz; public static Logger Log; public Baseclass()&#123; clazz = this.getclass(); log = LoggerFactory.getLogger(clazz); &#125;&#125; 继承后： 12345@RestController@RequestMapping(&quot;/books&quot;)public class BookController extends BaseClass&#123; private static final Logger log = LoggerFactory.getLogger(BookController.class); //这一句可以不写了&#125; 这样BookController在bean实例化的时候就会执行构造函数，获得当前的class，并生成log对象。 ②lombok​ 导入lombok后使用注解搞定，日志对象名为log，基于lombok提供的@Slf4j注解为类快速添加日志对象： 123456@Slf4j //这个注解替代了下面那一行@RestController@RequestMapping(&quot;/books&quot;)public class BookController extends BaseClass&#123; private static final Logger log = LoggerFactory.getLogger(BookController.class); //@Slf4j代替了&#125; 3）日志格式​ 日志已经能够记录了，但是目前记录的格式是SpringBoot给我们提供的，如果想自定义控制就需要自己设置了。先分析一下当前日志的记录格式。 ​ 对于单条日志信息来说，日期，触发位置，记录信息是最核心的信息。级别用于做筛选过滤，PID与线程名用于做精准分析。 ​ 我们可以手动diy该配置 123logging: pattern: console: &quot;%d %clr(%p) --- [%16t] %clr(%-40.40c)&#123;cyan&#125; : %m %n&quot; 4）日志文件日志信息不仅能显示在控制台上，还应该将其打印到文件中进行保存： 记录日志到文件中格式非常简单，设置日志文件名即可。 123logging: file: name: server.log ​ 虽然使用上述格式可以将日志记录下来了，但是面对线上的复杂情况，一个文件记录肯定是不能够满足运维要求的，通常会每天记录日志文件，同时为了便于维护，还要限制每个日志文件的大小。下面是日志文件的常用配置方式： 12345logging: logback: rollingpolicy: max-file-size: 3KB #定义每个文件的大小 file-name-pattern: server.%d&#123;yyyy-MM-dd&#125;.%i.log #定义每个文件的名字 ​ 以上格式是基于logback日志技术设置每日日志文件的设置格式，要求容量到达3KB以后就转存信息到第二个文件中。文件命名规则中的%d标识日期，%i是一个递增变量，用于区分日志文件。 5.热部署1）手动热部署步骤①：导入开发者工具对应的坐标 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;!-- 通过来devtools实现--!&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 步骤②：构建项目，可以使用快捷键激活此功能 ​ 对应的快捷键快捷键如下： 1&lt;CTR&gt;L+&lt;F9&gt; ​ 以上过程就实现了springboot工程的热部署，其底层的工作如下： 重启与重载 ​ 一个springboot项目在运行时实际上是分两个过程进行的，根据加载的东西不同，划分成base类加载器与restart类加载器。 base类加载器：用来加载jar包中的类，jar包中的类和配置文件由于不会发生变化，因此不管加载多少次，加载的内容不会发生变化 restart类加载器：用来加载开发者自己开发的类、配置文件、页面等信息，这一类文件受开发者影响 ​ 当springboot项目启动时，base类加载器执行，加载jar包中的信息后，restart类加载器执行，加载开发者制作的内容。当执行构建项目后，由于jar中的信息不会变化，因此base类加载器无需再次执行，所以仅仅运行restart类加载即可，也就是将开发者自己制作的内容重新加载就行了，这就完成了一次热部署的过程，也可以说热部署的过程实际上是重新加载restart类加载器中的信息。 2）自动热部署自动热部署其实就是设计一个开关，打开这个开关后，IDE工具就可以自动热部署。因此这个操作和IDE工具有关，以下以idea为例设置idea中启动热部署 步骤①：设置自动构建项目 ​ 打开【File】-&gt;【settings…】-&gt;【Compile】-&gt;【Build project automatically】 步骤②：允许在程序运行时进行自动构建 ​ 使用快捷键【Ctrl】+【Alt】+【Shit】+【&#x2F;】打开维护面板，选择第1项【Registry…】 ​ 在选项中搜索comple，然后勾选对应项即可 ​ 这样程序在运行的时候就可以进行自动构建了，实现了热部署的效果。 注意： ​ 如果每敲一个字母，服务器就重新构建一次，这有点太频繁了，所以idea设置当idea工具失去焦点5秒后进行热部署。其实就是从idea工具中切换到其他工具时进行热部署，比如改完程序需要到浏览器上去调试，这个时候idea就自动进行热部署操作。 3）参与范围配置参与热部署监控的文件范围配置 ​ 通过修改项目中的文件，可以发现其实并不是所有的文件修改都会激活热部署的，原因在于在开发者工具中有一组配置，当满足了配置中的条件后，才会启动热部署，配置中默认不参与热部署的目录信息如下 &#x2F;META-INF&#x2F;maven &#x2F;META-INF&#x2F;resources &#x2F;resources &#x2F;static &#x2F;public &#x2F;templates ​ 以上目录中的文件如果发生变化，是不参与热部署的。如果想修改配置，可以通过application.yml文件进行设定哪些文件不参与热部署操作 12345spring: devtools: restart: # 设置不参与热部署的文件或文件夹 exclude: static/**,public/**,config/application.yml 4）关闭热部署​ 线上环境运行时是不可能使用热部署功能的，所以需要强制关闭此功能，通过配置可以关闭此功能。 1234spring: devtools: restart: enabled: false ​ 如果当心配置文件层级过多导致相符覆盖最终引起配置失效，可以提高配置的层级，在更高层级中配置关闭热部署。例如在启动容器前通过系统属性设置关闭热部署功能。（高优先级配置文件覆盖低优先级文件，4级配置） 1234567@SpringBootApplicationpublic class SSMPApplication &#123; public static void main(String[] args) &#123; System.setProperty(&quot;spring.devtools.restart.enabled&quot;,&quot;false&quot;);//设置系统参数 SpringApplication.run(SSMPApplication.class); &#125;&#125; 6.配置数据注入相关1）注入数据①注入自定义bean​ @ConfigurationProperties，此注解的作用是用来为bean绑定属性的。开发者可以在yml配置文件中以对象的格式添加若干属性 1234servers: ip-address: 192.168.0.1 port: 2345 timeout: -1 ​ 然后再开发一个用来封装数据的实体类，注意要提供属性对应的setter方法（这里是lombok提供） 1234567@Component@Data //lombokpublic class ServerConfig &#123; private String ipAddress; private int port; private long timeout;&#125; ​ 使用@ConfigurationProperties注解就可以将配置中的属性值关联到开发的模型类上 12345678@Component@Data@ConfigurationProperties(prefix = &quot;servers&quot;)public class ServerConfig &#123; private String ipAddress; private int port; private long timeout;&#125; ​ 这样加载对应bean的时候就可以直接加载配置属性值了。 ②注入第三方beana）@ConfigurationProperties 使用@ConfigurationProperties注解其实可以为第三方bean加载属性 步骤①：使用@Bean注解定义第三方bean 12345@Beanpublic DruidDataSource datasource()&#123; DruidDataSource ds = new DruidDataSource(); return ds;&#125; 步骤②：在yml中定义要绑定的属性，注意datasource此时全小写 12datasource: driverClassName: com.mysql.jdbc.Driver 步骤③：使用@ConfigurationProperties注解为第三方bean进行属性绑定，注意前缀是全小写的datasource 123456@Bean@ConfigurationProperties(prefix = &quot;datasource&quot;)public DruidDataSource datasource()&#123; DruidDataSource ds = new DruidDataSource(); return ds;&#125; ​ 操作方式完全一样，只不过@ConfigurationProperties注解不仅能添加到类上，还可以添加到方法上，添加到类上是为spring容器管理的当前类的对象绑定属性，添加到方法上是为spring容器管理的当前方法的返回值对象绑定属性，其实本质上都一样。 b）@EnableConfigurationProperties() ​ 这里出现了一个新的问题，目前我们定义bean不是通过@Component就是通过@Bean定义，使用@ConfigurationProperties注解可以为bean进行属性绑定，那在一个业务系统中，哪些bean通过注解@ConfigurationProperties去绑定属性了呢？ ​ 因为这个注解不仅可以写在类上，还可以写在方法上，所以找起来就比较麻烦了。为了解决这个问题，spring提供了一个全新的注解，专门标注使用@ConfigurationProperties注解绑定属性的bean是哪些，这个注解叫做@EnableConfigurationProperties。 步骤①：在配置类上开启@EnableConfigurationProperties注解，并标注要使用@ConfigurationProperties注解绑定属性的类 1234@SpringBootApplication@EnableConfigurationProperties(ServerConfig.class) //在引导类上配置public class Springboot13ConfigurationApplication &#123;&#125; 步骤②：在对应的类上直接使用@ConfigurationProperties进行属性绑定 1234567@Data@ConfigurationProperties(prefix = &quot;servers&quot;)public class ServerConfig &#123; private String ipAddress; private int port; private long timeout;&#125; 注意： ​ 现在绑定属性的ServerConfig类并没有声明@Component注解。当使用@EnableConfigurationProperties注解时，spring会默认将其标注的类定义为bean，因此无需再次声明@Component注解了。 ​ 一个小问题，使用@ConfigurationProperties注解时，会出现一个提示信息 出现这个提示后只需要添加一个坐标此提醒就消失了 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;&lt;/dependency&gt; 总结 使用@ConfigurationProperties可以为使用@Bean声明的第三方bean绑定属性 当使用@EnableConfigurationProperties声明进行属性绑定的bean后，无需使用@Component注解再次进行bean声明 2）宽松绑定&#x2F;松散绑定在进行属性绑定时，可能会遇到如下情况，为了进行标准命名，开发者会将属性名严格按照驼峰命名法书写，在yml配置文件中将datasource修改为dataSource，如下： 12dataSource: driverClassName: com.mysql.jdbc.Driver ​ 此时程序可以正常运行，然后又将代码中的前缀datasource修改为dataSource，如下： 123456@Bean@ConfigurationProperties(prefix = &quot;dataSource&quot;)//这里完全按照yml中的写法，但还是报错了public DruidDataSource datasource()&#123; DruidDataSource ds = new DruidDataSource(); return ds;&#125; ​ 此时就发生了编译错误，而且并不是idea工具导致的，运行后依然会出现问题，配置属性名dataSource是无效的 12345678Configuration property name &#x27;dataSource&#x27; is not valid: Invalid characters: &#x27;S&#x27; Bean: datasource Reason: Canonical names should be kebab-case (&#x27;-&#x27; separated), lowercase alpha-numeric characters and must start with a letterAction:Modify &#x27;dataSource&#x27; so that it conforms to the canonical names requirements. ​ 这里涉及到有关属性名称的宽松绑定，也可以称为宽松绑定。 ​ 实际上是springboot进行编程时人性化设计的一种体现，即配置文件中的命名格式与变量名的命名格式可以进行格式上的最大化兼容，几乎主流的命名格式都支持，例如： ​ 在ServerConfig中的ipAddress属性名 123456@Component@Data@ConfigurationProperties(prefix = &quot;servers&quot;)public class ServerConfig &#123; private String ipAddress;&#125; ​ 可以与下面的配置属性名规则全兼容 12345servers: ipAddress: 192.168.0.2 # 驼峰模式 ip_address: 192.168.0.2 # 下划线模式 ip-address: 192.168.0.2 # 烤肉串模式 IP_ADDRESS: 192.168.0.2 # 常量模式 ​ 也可以说，以上4种模式最终都可以匹配到ipAddress这个属性名。原因就是在进行匹配时，配置中的名称要去掉中划线和下划线后，忽略大小写的情况下去与java代码中的属性名进行忽略大小写的等值匹配，以上4种命名去掉下划线中划线忽略大小写后都是一个词ipaddress，java代码中的属性名忽略大小写后也是ipaddress，这样就可以进行等值匹配了，这就是为什么这4种格式都能匹配成功的原因。不过springboot官方推荐使用烤肉串模式，也就是中划线模式。 ​ 再来看开始出现的编程错误信息中的Reason 12345678Configuration property name &#x27;dataSource&#x27; is not valid: Invalid characters: &#x27;S&#x27; Bean: datasource Reason: Canonical names should be kebab-case (&#x27;-&#x27; separated), lowercase alpha-numeric characters and must start with a letter //原因希望prefix使用烤肉串模式Action:Modify &#x27;dataSource&#x27; so that it conforms to the canonical names requirements. ​ 其中Reason描述了报错的原因，规范的名称应该是烤肉串(kebab)模式(case)，即使用-分隔，使用小写字母数字作为标准字符，且必须以字母开头。然后再看我们写的名称dataSource，就不满足上述要求。在书写前缀时，这个词不是随意支持的，必须使用上述标准。 注意： 以上规则仅针对springboot中**@ConfigurationProperties**注解进行属性绑定时有效，对@Value注解进行属性映射无效。 所以@Value(ipAddress)是不能获取yml配置中ipaddress的，必须要完全一致 ​ 3）计量数据​ 如下写明了timeout的时间是240，但是这个240具体的单位无法确定（默认时间是ms，大小是B）： 1234servers: ip-address: 192.168.0.1 port: 2345 timeout: 240 ​ 除了加强约定之外，springboot充分利用了JDK8中提供的全新的用来表示计量单位的新数据类型，从根本上解决这个问题。以下模型类中添加了两个JDK8中新增的类，分别是Duration和DataSize 12345678910@Component@Data@ConfigurationProperties(prefix = &quot;servers&quot;)public class ServerConfig &#123; @DurationUnit(ChronoUnit.HOURS) //定义的单位是hour private Duration serverTimeOut; @DataSizeUnit(DataUnit.MEGABYTES) //定义的单位是MB private DataSize dataSize;&#125; Duration：表示时间间隔，可以通过@DurationUnit注解描述时间单位，例如上例中描述的单位为小时（ChronoUnit.HOURS） DataSize：表示存储空间，可以通过@DataSizeUnit注解描述存储空间单位，例如上例中描述的单位为MB（DataUnit.MEGABYTES） ​ 使用上述两个单位就可以有效避免因沟通不同步或文档不健全导致的信息不对称问题，从根本上解决了问题，避免产生误读。 Druation常用单位如下： DataSize常用单位如下： 4）数据校验​ 目前我们在进行属性绑定时可以通过松散绑定规则在书写时放飞自我了，但是在书写时由于无法感知模型类中的数据类型，就会出现类型不匹配的问题，比如代码中需要int类型，配置中给了非法的数值，例如写一个“a”，这种数据肯定无法有效的绑定，还会引发错误。 SpringBoot给出了强大的数据校验功能，可以有效的避免此类问题的发生。在JAVAEE的JSR303规范中给出了具体的数据校验标准，开发者可以根据自己的需要选择对应的校验框架，此处使用Hibernate提供的校验框架来作为实现进行数据校验。书写应用格式非常固定，话不多说，直接上步骤 步骤①：开启校验框架 JSR303是一个接口，相当于定义了一套规范（类似JDBC） hibernate校验器实现了JSR303这个接口，是它的实现类（类似mysql驱动实现JDBC） 12345678910&lt;!--1.导入JSR303规范--&gt;&lt;dependency&gt; &lt;groupId&gt;javax.validation&lt;/groupId&gt; &lt;artifactId&gt;validation-api&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--使用hibernate框架提供的校验器做实现--&gt;&lt;dependency&gt; &lt;groupId&gt;org.hibernate.validator&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt;&lt;/dependency&gt; 步骤②：在需要开启校验功能的类上使用注解@Validated开启校验功能 1234567@Component@Data@ConfigurationProperties(prefix = &quot;servers&quot;)//开启对当前bean的属性注入校验@Validatedpublic class ServerConfig &#123;&#125; 步骤③：对具体的字段设置校验规则 1234567891011@Component@Data@ConfigurationProperties(prefix = &quot;servers&quot;)//开启对当前bean的属性注入校验@Validatedpublic class ServerConfig &#123; //设置具体的规则 @Max(value = 8888,message = &quot;最大值不能超过8888&quot;) @Min(value = 202,message = &quot;最小值不能低于202&quot;) private int port;&#125; ​ 通过设置数据格式校验，就可以有效避免非法数据加载，其实使用起来还是挺轻松的，基本上就是一个格式。 5）数据转换问题​ 先把问题描述一下，连接数据库正常操作，但是运行程序后显示的信息是密码错误。 1java.sql.SQLException: Access denied for user &#x27;root&#x27;@&#x27;localhost&#x27; (using password: YES) ​ 其配置是这样写的： 123456spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=UTC username: root password: 0127 //密码是对的，但是没用&quot;&quot;包裹 ​ 在整数相关知识中有这么一句话，支持二进制，八进制，十六进制 ​ 0（0-7）：8进制 ​ 0x（0-9，a-f）16进制 0127在开发者眼中是一个字符串“0127”，但是在springboot看来，这就是一个数字，而且是一个八进制的数字。当后台使用String类型接收数据时，如果配置文件中配置了一个整数值，他是先安装整数进行处理，读取后再转换成字符串。0127撞上了八进制的格式，所以最终以十进制数字87的结果存在了。 注意： 字符串标准书写加上引号包裹，养成习惯 遇到0开头的数据多注意 7.测试1）临时属性​ 测试过程本身并不是一个复杂的过程，但是很多情况下测试时需要模拟一些线上情况，或者模拟一些特殊情况。如果当前环境按照线上环境已经设定好了，例如是下面的配置 123env: maxMemory: 32GB minMemory: 16GB ​ 但是你现在想测试对应的兼容性，需要测试如下配置 123env: maxMemory: 16GB minMemory: 8GB ​ 这个时候我们不能每次测试的时候都去修改源码application.yml中的配置进行测试，每次测试前改过来，每次测试后改回去，这太麻烦了。这时候我们需要在测试环境中创建一组临时属性，去覆盖我们源码中设定的属性，这样测试用例就相当于是一个独立的环境，能够独立测试。 ①properties临时属性 ​ springboot已经为我们开发者早就想好了这种问题该如何解决，并且提供了对应的功能入口。在测试用例程序中，可以通过对注解@SpringBootTest添加属性来模拟临时属性，具体如下： 123456789101112//properties属性可以为当前测试用例添加临时的属性配置@SpringBootTest(properties = &#123;&quot;test.prop=testValue1&quot;&#125;)public class PropertiesAndArgsTest &#123; @Value(&quot;$&#123;test.prop&#125;&quot;) private String msg; @Test void testProperties()&#123; System.out.println(msg); &#125;&#125; ​ 使用注解@SpringBootTest的properties属性就可以为当前测试用例添加临时的属性，覆盖源码配置文件中对应的属性值进行测试。 ②args临时参数 ​ 除了上述这种情况，在前面讲解使用命令行启动springboot程序时讲过，通过命令行参数也可以设置属性值。而且线上启动程序时，通常都会添加一些专用的配置信息。作为运维人员他们才不懂java，更不懂这些配置的信息具体格式该怎么写，作为开发者提供了对应的书写内容后，需要提前测试一下这些配置信息是否有效呢，通过注解@SpringBootTest的另一个属性args来进行设定。 123456789101112//args属性可以为当前测试用例添加临时的命令行参数@SpringBootTest(args=&#123;&quot;--test.prop=testValue2&quot;&#125;)public class PropertiesAndArgsTest &#123; @Value(&quot;$&#123;test.prop&#125;&quot;) private String msg; @Test void testProperties()&#123; System.out.println(msg); &#125;&#125; ​ 使用注解@SpringBootTest的args属性就可以为当前测试用例模拟命令行参数并进行测试。（idea中也可以添加） 加载顺序 原来的配置文件-&gt;properties属性-&gt;args属性（后面覆盖前面） 2）加载测试专用配置​ 学习过Spring的知识，我们都知道，其实一个spring环境中可以设置若干个配置文件或配置类，若干个配置信息可以同时生效。现在我们的需求就是在测试环境中再添加一个配置类，然后启动测试环境时，生效此配置就行了。其实做法和spring环境中加载多个配置信息的方式完全一样。具体操作步骤如下： 步骤①：在测试包test中创建config下专用的测试环境配置类 1234567@Configurationpublic class MsgConfig &#123; @Bean public String msg()&#123; return &quot;bean msg&quot;; &#125;&#125; ​ 上述配置仅用于演示当前实验效果，实际开发可不能这么注入String类型的数据 步骤②：在启动测试环境时，导入测试环境专用的配置类，使用@Import注解即可实现 123456789101112@SpringBootTest@Import(&#123;MsgConfig.class&#125;) //通过import注解导入专门配置public class ConfigurationTest &#123; @Autowired private String msg; @Test void testConfiguration()&#123; System.out.println(msg); &#125;&#125; ​ 到这里就通过@Import属性实现了基于开发环境的配置基础上，对配置进行测试环境的追加操作，实现了1+1的配置环境效果。这样我们就可以实现每一个不同的测试用例加载不同的bean的效果，丰富测试用例的编写，同时不影响开发环境的配置。 3）Web环境模拟测试 如何在测试类中启动web测试 如何在测试类中发送web请求 ①测试类中启动web环境​ 每一个springboot的测试类上方都会标准@SpringBootTest注解，而注解带有一个属性，叫做webEnvironment。通过该属性就可以设置在测试用例中启动web环境，具体如下： 123@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)public class WebTest &#123; &#125; ​ 测试类中启动web环境时，可以指定启动的Web环境对应的端口，springboot提供了4种设置值，分别如下： MOCK：根据当前设置确认是否启动web环境，例如使用了Servlet的API就启动web环境，属于适配性的配置 DEFINED_PORT：使用自定义的端口作为web服务器端口 RANDOM_PORT：使用随机端口作为web服务器端口 NONE：不启动web环境（默认值） ​ 通过上述配置，现在启动测试程序时就可以正常启用web环境了，建议测试时使用RANDOM_PORT，避免代码中因为写死设定引发线上功能打包测试时由于端口冲突导致意外现象的出现。就是说你程序中写了用8080端口，结果线上环境8080端口被占用了，结果你代码中所有写的东西都要改，这就是写死代码的代价。现在用随机端口就可以测试出来有没有这种问题的隐患了。 ​ ②测试类中发送请求对于测试类中发送请求，使用@AutoConfigureMockMvc定义的操作来发送请求： 步骤①：在测试类中开启web虚拟调用功能，通过注解@AutoConfigureMockMvc实现此功能的开启 12345@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)//开启虚拟MVC调用@AutoConfigureMockMvcpublic class WebTest &#123;&#125; 步骤②：定义发起虚拟调用的对象MockMVC，通过自动装配的形式初始化对象 123456789101112@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)//开启虚拟MVC调用@AutoConfigureMockMvcpublic class WebTest &#123; //1.第一种方式注入 @Autowired private MockMvc mvc; @Test void testWeb(@Autowired MockMvc mvc) &#123;//第二种方式注入 &#125;&#125; 步骤③：使用工具类MockMvcRequestBuilders创建一个虚拟请求对象MockHttpServletRequestBuilder，封装请求的路径，并使用MockMVC对象发送对应请求 12345678910111213141516@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)//开启虚拟MVC调用@AutoConfigureMockMvcpublic class WebTest &#123; @Test void testWeb(@Autowired MockMvc mvc) throws Exception &#123; //http://localhost:8080/books //创建虚拟请求，当前访问/books //1.通过工具类获得builder MockHttpServletRequestBuilder builder = MockMvcRequestBuilders.get(&quot;/books&quot;); //2.mvc发送请求需要传入一个builder mvc.perform(builder); &#125;&#125; ​ 执行测试程序，现在就可以正常的发送&#x2F;books对应的请求了，注意访问路径不要写http://localhost:8080/books，因为前面的服务器IP地址和端口使用的是当前虚拟的web环境，无需指定，仅指定请求的具体路径即可。 ③web环境响应结果比对​ 发送完web请求后我们应该验证比对响应结果是否使我们想要的结果： 响应状态匹配 123456789101112@Testvoid testStatus(@Autowired MockMvc mvc) throws Exception &#123; MockHttpServletRequestBuilder builder = MockMvcRequestBuilders.get(&quot;/books&quot;); ResultActions action = mvc.perform(builder); //设定预期值 与真实值进行比较，成功测试通过，失败测试失败 //定义本次调用的预期值 StatusResultMatchers status = MockMvcResultMatchers.status(); //预计本次调用时成功的：状态200 ResultMatcher ok = status.isOk(); //添加预计值到本次调用过程中进行匹配 action.andExpect(ok);&#125; 响应体匹配（非json数据格式） 1234567891011@Testvoid testBody(@Autowired MockMvc mvc) throws Exception &#123; MockHttpServletRequestBuilder builder = MockMvcRequestBuilders.get(&quot;/books&quot;); ResultActions action = mvc.perform(builder); //设定预期值 与真实值进行比较，成功测试通过，失败测试失败 //定义本次调用的预期值 ContentResultMatchers content = MockMvcResultMatchers.content(); ResultMatcher result = content.string(&quot;springboot2&quot;); //添加预计值到本次调用过程中进行匹配 action.andExpect(result);&#125; 响应体匹配（json数据格式，开发中的主流使用方式） 1234567891011@Testvoid testJson(@Autowired MockMvc mvc) throws Exception &#123; MockHttpServletRequestBuilder builder = MockMvcRequestBuilders.get(&quot;/books&quot;); ResultActions action = mvc.perform(builder); //设定预期值 与真实值进行比较，成功测试通过，失败测试失败 //定义本次调用的预期值 ContentResultMatchers content = MockMvcResultMatchers.content(); ResultMatcher result = content.json(&quot;&#123;\\&quot;id\\&quot;:1,\\&quot;name\\&quot;:\\&quot;springboot2\\&quot;,\\&quot;type\\&quot;:\\&quot;springboot\\&quot;&#125;&quot;); //添加预计值到本次调用过程中进行匹配 action.andExpect(result);&#125; 响应头信息匹配 1234567891011@Testvoid testContentType(@Autowired MockMvc mvc) throws Exception &#123; MockHttpServletRequestBuilder builder = MockMvcRequestBuilders.get(&quot;/books&quot;); ResultActions action = mvc.perform(builder); //设定预期值 与真实值进行比较，成功测试通过，失败测试失败 //定义本次调用的预期值 HeaderResultMatchers header = MockMvcResultMatchers.header(); ResultMatcher contentType = header.string(&quot;Content-Type&quot;, &quot;application/json&quot;); //添加预计值到本次调用过程中进行匹配 action.andExpect(contentType);&#125; 多种信息匹配eg 1234567891011121314151617@Testvoid testGetById(@Autowired MockMvc mvc) throws Exception &#123; MockHttpServletRequestBuilder builder = MockMvcRequestBuilders.get(&quot;/books&quot;); ResultActions action = mvc.perform(builder); StatusResultMatchers status = MockMvcResultMatchers.status(); ResultMatcher ok = status.isOk(); action.andExpect(ok); HeaderResultMatchers header = MockMvcResultMatchers.header(); ResultMatcher contentType = header.string(&quot;Content-Type&quot;, &quot;application/json&quot;); action.andExpect(contentType); ContentResultMatchers content = MockMvcResultMatchers.content(); ResultMatcher result = content.json(&quot;&#123;\\&quot;id\\&quot;:1,\\&quot;name\\&quot;:\\&quot;springboot\\&quot;,\\&quot;type\\&quot;:\\&quot;springboot\\&quot;&#125;&quot;); action.andExpect(result);&#125; 4）数据层测试回滚​ 测试程序可以完美的进行表现层、业务层、数据层接口对应的功能测试，但是测试用例开发完成后，在打包的阶段由于test生命周期属于必须被运行的生命周期，如果跳过会给系统带来极高的安全隐患，所以测试用例必须执行。但是新的问题就呈现了，测试用例如果测试时产生了事务提交就会在测试过程中对数据库数据产生影响，进而产生垃圾数据。这个过程不是我们希望发生的，作为开发者测试用例该运行运行，但是过程中产生的数据不要在我的系统中留痕。 ​ springboot给出了最简解决方案：在原始测试用例中添加注解@Transactional即可实现当前测试用例的事务不提交。当程序运行后，只要注解@Transactional出现的位置存在注解@SpringBootTest，springboot就会认为这是一个测试程序，无需提交事务，所以也就可以避免事务的提交。 1234567891011121314151617@SpringBootTest@Transactional@Rollback(true) //对于test来说，springBoot默认回滚数据public class DaoTest &#123; @Autowired private BookService bookService; @Test void testSave()&#123; Book book = new Book(); book.setName(&quot;springboot3&quot;); book.setType(&quot;springboot3&quot;); book.setDescription(&quot;springboot3&quot;); bookService.save(book); &#125;&#125; ​ 如果开发者想提交事务，也可以，再添加一个@RollBack的注解，设置回滚状态为false即可正常提交事务。 ​ @Transactional是spring的声明式事务，我们也可以在service层使用 ​ 5）测试用例数据设定​ 对于测试用例的数据写固定值肯定是不合理的，springboot提供了在配置中使用随机值的机制，确保每次运行程序加载的数据都是随机的。具体如下： 12345678testcase: book: id: $&#123;random.int&#125; id2: $&#123;random.int(10)&#125; type: $&#123;random.int!5,10!&#125; name: $&#123;random.value&#125; uuid: $&#123;random.uuid&#125; publishTime: $&#123;random.long&#125; ​ 当前配置就可以在每次运行程序时创建一组随机数据，避免每次运行时数据都是固定值的尴尬现象发生，有助于测试功能的进行。数据的加载按照之前加载数据的形式，使用@ConfigurationProperties注解即可 123456789101112//test.domain下的bean数据@Component@Data@ConfigurationProperties(prefix = &quot;testcase.book&quot;)public class BookCase &#123; private int id; private int id2; private int type; private String name; private String uuid; private long publishTime;&#125; ​ 对于随机值的产生，还有一些小的限定规则，比如产生的数值性数据可以设置范围等，具体如下： ${random.int}表示随机整数 ${random.int(10)}表示10以内的随机数 ${random.int(10,20)}表示10到20的随机数 其中()可以是任意字符，例如[]，!!均可 8.数据层方案1）sql①dataSourcespringboot提供了3款内嵌数据源技术，分别如下： HikariCP Tomcat提供DataSource Commons DBCP druid配置： 1234567spring: datasource: druid: url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=UTC driver-class-name: com.mysql.cj.jdbc.Driver username: root password: root druid删掉就是默认的hikari： 123456spring: datasource: url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=UTC driver-class-name: com.mysql.cj.jdbc.Driver username: root password: root 也可以写上是对hikari做的配置，但是url地址要单独配置，如下： 1234567spring: datasource: url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=UTC #hikari的url是写在外面的 hikari: driver-class-name: com.mysql.cj.jdbc.Driver username: root password: root 可以对hikari做进一步的配置，可以继续配置其独立的属性。例如： 12345678spring: datasource: url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=UTC hikari: driver-class-name: com.mysql.cj.jdbc.Driver username: root password: root maximum-pool-size: 50 ​ ②template步骤①：导入jdbc对应的坐标，记得是starter 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency 步骤②：自动装配JdbcTemplate对象 123456@SpringBootTestclass Springboot15SqlApplicationTests &#123; @Test void testJdbcTemplate(@Autowired JdbcTemplate jdbcTemplate)&#123; &#125;&#125; 步骤③：使用JdbcTemplate实现查询操作（非实体类封装数据的查询操作） 123456@Testvoid testJdbcTemplate(@Autowired JdbcTemplate jdbcTemplate)&#123; String sql = &quot;select * from tbl_book&quot;; List&lt;Map&lt;String, Object&gt;&gt; maps = jdbcTemplate.queryForList(sql); System.out.println(maps);&#125; 步骤④：使用JdbcTemplate实现查询操作（实体类封装数据的查询操作） 123456789101112131415161718@Testvoid testJdbcTemplate(@Autowired JdbcTemplate jdbcTemplate)&#123; String sql = &quot;select * from tbl_book&quot;; RowMapper&lt;Book&gt; rm = new RowMapper&lt;Book&gt;() &#123; @Override public Book mapRow(ResultSet rs, int rowNum) throws SQLException &#123; Book temp = new Book(); temp.setId(rs.getInt(&quot;id&quot;)); temp.setName(rs.getString(&quot;name&quot;)); temp.setType(rs.getString(&quot;type&quot;)); temp.setDescription(rs.getString(&quot;description&quot;)); return temp; &#125; &#125;; List&lt;Book&gt; list = jdbcTemplate.query(sql, rm); System.out.println(list);&#125; 步骤⑤：使用JdbcTemplate实现增删改操作 12345@Testvoid testJdbcTemplateSave(@Autowired JdbcTemplate jdbcTemplate)&#123; String sql = &quot;insert into tbl_book values(3,&#x27;springboot1&#x27;,&#x27;springboot2&#x27;,&#x27;springboot3&#x27;)&quot;; jdbcTemplate.update(sql);&#125; 如果想对JdbcTemplate对象进行相关配置，可以在yml文件中进行设定，具体如下： 123456spring: jdbc: template: query-timeout: -1 # 查询超时时间 max-rows: 500 # 最大行数 fetch-size: -1 # 缓存行数 2）nosql①redisTemplate步骤①：导入springboot整合redis的starter坐标 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; ​ 上述坐标可以在创建模块的时候通过勾选的形式进行选择，归属NoSQL分类中 步骤②：进行基础配置 1234spring: redis: host: localhost port: 6379 ​ 步骤③：使用springboot整合redis的专用客户端接口操作，此处使用的是RedisTemplate 12345678910111213141516171819202122232425262728@SpringBootTestclass Springboot16RedisApplicationTests &#123; @Autowired private RedisTemplate redisTemplate; @Test void set() &#123; ValueOperations ops = redisTemplate.opsForValue(); ops.set(&quot;age&quot;,41); &#125; @Test void get() &#123; ValueOperations ops = redisTemplate.opsForValue(); Object age = ops.get(&quot;name&quot;); System.out.println(age); &#125; @Test void hset() &#123; HashOperations ops = redisTemplate.opsForHash(); ops.put(&quot;info&quot;,&quot;b&quot;,&quot;bb&quot;); &#125; @Test void hget() &#123; HashOperations ops = redisTemplate.opsForHash(); Object val = ops.get(&quot;info&quot;, &quot;b&quot;); System.out.println(val); &#125;&#125; ​ 在操作redis时，需要先确认操作何种数据，根据数据种类得到操作接口。例如使用opsForValue()获取string类型的数据操作接口，使用opsForHash()获取hash类型的数据操作接口，剩下的就是调用对应api操作了。各种类型的数据操作接口如下： ②StringRedisTemplate​ 有这样一个问题，当我们在java程序中进行如下set，然后再在cmd中get(age)，发现存储的并不是41 12345@Test void set() &#123; ValueOperations ops = redisTemplate.opsForValue(); ops.set(&quot;age&quot;,41); &#125; ​ 这是由于redis内部不提供java对象的存储格式，因此当操作的数据以对象的形式存在时，会转换成序列化的字符串格式后进行操作。 所以这里的41会经过转码成一串string，这就和原来的string不一致了 ​ springboot整合redis时提供了专用的API接口StringRedisTemplate，我们查看RedisTemplate，可以看到他可以接收一个泛型&lt;k,v&gt;的，当我们没有设置泛型，其默认就是&lt;Object,Object&gt;，而我们要正确操作redis就需要&lt;String,String&gt;，而StringRedisTemplate就实现了这个泛型 1234567891011@SpringBootTestpublic class StringRedisTemplateTest &#123; @Autowired private StringRedisTemplate stringRedisTemplate; @Test void get()&#123; ValueOperations&lt;String, String&gt; ops = stringRedisTemplate.opsForValue(); String name = ops.get(&quot;name&quot;); System.out.println(name); &#125;&#125; ③redis客户端选择​ springboot整合redis技术提供了多种客户端兼容模式，默认提供的是lettucs客户端技术，也可以根据需要切换成指定客户端技术，例如jedis客户端技术，切换成jedis客户端技术操作步骤如下： 步骤①：导入jedis坐标 1234&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt;&lt;/dependency&gt; jedis坐标受springboot管理，无需提供版本号 步骤②：配置客户端技术类型，设置为jedis 12345spring: redis: host: localhost port: 6379 client-type: jedis //将操作redis的客户端换成jedis 步骤③：根据需要设置对应的配置 1234567891011spring: redis: host: localhost port: 6379 client-type: lettuce lettuce: pool: max-active: 16 jedis: pool: max-active: 16 lettcus与jedis区别 jedis连接Redis服务器是直连模式，当多线程模式下使用jedis会存在线程安全问题，解决方案可以通过配置连接池使每个连接专用，这样整体性能就大受影响（即每个线程单独使用一个连接） lettcus基于Netty框架进行与Redis服务器连接，底层设计中采用StatefulRedisConnection。 StatefulRedisConnection自身是线程安全的，可以保障并发访问安全问题，所以一个连接可以被多线程复用。当然lettcus也支持多连接实例一起工作 https://www.zhihu.com/question/53124685 9.缓存整合​ spring boot定义了一个缓存的规范，并对一些缓存做了内部整合，而有一些并没有被boot整合，需要我们自己来整合。以下所有的整合方式都用模拟手机验证码的存储和校验来作为例子。 输入手机号获取验证码，组织文档以短信形式发送给用户（页面模拟） 输入手机号和验证码验证结果 ①定义验证码对应的实体类，封装手机号与验证码两个属性，验证码pojo 12345@Datapublic class SMSCode &#123; private String tele; private String code;&#125; ②定义验证码功能的业务层接口与实现类 service 和 serviceImple，此处缓存不需要dao来和数据库交互 1234567891011121314151617181920212223public interface SMSCodeService &#123; public String sendCodeToSMS(String tele); public boolean checkCode(SMSCode smsCode);&#125;@Servicepublic class SMSCodeServiceImpl implements SMSCodeService &#123; @Autowired private CodeUtils codeUtils; @CachePut(value = &quot;smsCode&quot;, key = &quot;#tele&quot;) public String sendCodeToSMS(String tele) &#123; String code = codeUtils.generator(tele); return code; &#125; public boolean checkCode(SMSCode smsCode) &#123; //取出内存中的验证码与传递过来的验证码比对，如果相同，返回true String code = smsCode.getCode(); String cacheCode = codeUtils.get(smsCode.getTele()); return code.equals(cacheCode); &#125;&#125; 1）simple缓存simple是boot内置的默认缓存 步骤①：导入springboot提供的缓存技术对应的starter 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;&lt;/dependency&gt; 步骤②：启用缓存，在引导类上方标注注解@EnableCaching配置springboot程序中可以使用缓存 12345678@SpringBootApplication//开启缓存功能@EnableCachingpublic class Springboot19CacheApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(Springboot19CacheApplication.class, args); &#125;&#125; 步骤③：设置操作的数据是否使用缓存 12345678910@Servicepublic class BookServiceImpl implements BookService &#123; @Autowired private BookDao bookDao; @Cacheable(value=&quot;cacheSpace&quot;,key=&quot;#id&quot;) public Book getById(Integer id) &#123; return bookDao.selectById(id); &#125;&#125; ​ 在业务方法上面使用注解@Cacheable声明当前方法的返回值放入缓存中，其中要指定缓存的存储位置，以及缓存中保存当前方法返回值对应的名称。上例中value属性描述缓存的存储位置，可以理解为是一个存储空间名，key属性描述了缓存中保存数据的名称，使用#id读取形参中的id值作为缓存名称。 ​ 使用@Cacheable注解后，执行当前操作，如果发现对应名称在缓存中没有数据，就正常读取数据，然后放入缓存；如果对应名称在缓存中有数据，就终止当前业务方法执行，直接返回缓存中的数据。 步骤④：定义验证码功能的业务层接口与实现类 1234567891011121314151617181920212223public interface SMSCodeService &#123; public String sendCodeToSMS(String tele); public boolean checkCode(SMSCode smsCode);&#125;@Servicepublic class SMSCodeServiceImpl implements SMSCodeService &#123; @Autowired private CodeUtils codeUtils; @CachePut(value = &quot;smsCode&quot;, key = &quot;#tele&quot;)//该注解仅仅是在缓存中放入值 public String sendCodeToSMS(String tele) &#123; String code = codeUtils.generator(tele); return code; &#125; public boolean checkCode(SMSCode smsCode) &#123; //取出内存中的验证码与传递过来的验证码比对，如果相同，返回true String code = smsCode.getCode(); String cacheCode = codeUtils.get(smsCode.getTele()); return code.equals(cacheCode); &#125;&#125; ​ 获取验证码后，当验证码失效时必须重新获取验证码，因此在获取验证码的功能上不能使用@Cacheable注解，@Cacheable注解是缓存中没有值则放入值，缓存中有值则取值。此处的功能仅仅是生成验证码并放入缓存，并不具有从缓存中取值的功能，因此不能使用@Cacheable注解，应该使用仅具有向缓存中保存数据的功能，使用@CachePut注解即可。 @Cacheable(value,key)：value指的是缓存空间的名字，key则是某条缓存的key（key的值和参数对应）。执行该方法的时候首先会根据key查找缓存，没查到则把该方法的return作为key对应的value存入 @CachePut(value,key)：并不会去查找有没有对应的key缓存，而是每次都put（相同则覆盖） 更多：https://www.cnblogs.com/fashflying/p/6908028.html ​ 注意：以下验证方法的写法是错误的 1234567891011121314151617181920212223@Servicepublic class SMSCodeServiceImpl implements SMSCodeService &#123; @Autowired private CodeUtils codeUtils; @CachePut(value = &quot;smsCode&quot;, key = &quot;#tele&quot;)//该注解仅仅是在缓存中放入值，key的值对应方法参数的值 public String sendCodeToSMS(String tele) &#123; String code = codeUtils.generator(tele); return code; &#125; public boolean checkCode(SMSCode smsCode) &#123; //取出内存中的验证码与传递过来的验证码比对，如果相同，返回true String code = smsCode.getCode(); String cacheCode = get(smsCode.getTele());//在这里调用下面的get方法 return code.equals(cacheCode); &#125; @Cacheable(value = &quot;smsCode&quot;, key = &quot;#tele&quot;) public String get(String tele)&#123; return null; &#125;&#125; ​ 这样写是错误的，把get方法写在controller中后，当checkCode在调用get的时候，get并不会去执行@Cacheable相应的操作，因为springboot在这时并没有管理该方法。正确的方式应该是将get方法写在CodeUtils中，将CodeUtils作为一个bean来交给spring管理，那么调用其方法的时候，方法上的注解也会被加载，如下面的步骤⑤ 步骤⑤：定义验证码的生成策略与根据手机号读取验证码的功能 1234567891011121314@Componentpublic class CodeUtils &#123; private String [] patch = &#123;&quot;000000&quot;,&quot;00000&quot;,&quot;0000&quot;,&quot;000&quot;,&quot;00&quot;,&quot;0&quot;,&quot;&quot;&#125;; //生成验证码 public String generator(String tele)&#123; ...... &#125; @Cacheable(value = &quot;smsCode&quot;,key=&quot;#tele&quot;) public String get(String tele)&#123; return null; &#125;&#125; get的时候去寻找key&#x3D;tele的缓存，如果找到则返回该缓存的value。 return null的问题 https://blog.csdn.net/difffate/article/details/64124272 根据设定是否可以缓存null 步骤⑥：定义验证码功能的web层接口，一个方法用于提供手机号获取验证码，一个方法用于提供手机号和验证码进行校验 1234567891011121314151617@RestController@RequestMapping(&quot;/sms&quot;)public class SMSCodeController &#123; @Autowired private SMSCodeService smsCodeService; @GetMapping public String getCode(String tele)&#123; String code = smsCodeService.sendCodeToSMS(tele); return code; &#125; @PostMapping public boolean checkCode(SMSCode smsCode)&#123; return smsCodeService.checkCode(smsCode); &#125;&#125; 2）Ehcache缓存步骤①：导入Ehcache的坐标 1234&lt;dependency&gt; &lt;groupId&gt;net.sf.ehcache&lt;/groupId&gt; &lt;artifactId&gt;ehcache&lt;/artifactId&gt;&lt;/dependency&gt; ​ 此处为什么不是导入Ehcache的starter，而是导入技术坐标呢？其实springboot整合缓存技术做的是通用格式，不管你整合哪种缓存技术，只是实现变化了，操作方式一样。这也体现出springboot技术的优点，统一同类技术的整合方式。 步骤②：配置缓存技术实现使用Ehcache 12345spring: cache: type: ehcache ehcache: config: ehcache.xml ​ 配置缓存的类型type为ehcache，此处需要说明一下，当前springboot可以整合的缓存技术中包含有ehcach（向memcache就没有，需要自己整合），所以可以这样书写。其实这个type不可以随便写的，不是随便写一个名称就可以整合的。 ​ 由于ehcache的配置有独立的配置文件格式，因此还需要指定ehcache的配置文件，以便于读取相应配置 12345678910111213141516171819202122232425262728293031323334&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;ehcache xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;http://ehcache.org/ehcache.xsd&quot; updateCheck=&quot;false&quot;&gt; &lt;diskStore path=&quot;D:\\ehcache&quot; /&gt; &lt;!--默认缓存策略 --&gt; &lt;!-- external：是否永久存在，设置为true则不会被清除，此时与timeout冲突，通常设置为false--&gt; &lt;!-- diskPersistent：是否启用磁盘持久化--&gt; &lt;!-- maxElementsInMemory：最大缓存数量--&gt; &lt;!-- overflowToDisk：超过最大缓存数量是否持久化到磁盘--&gt; &lt;!-- timeToIdleSeconds：最大不活动间隔，设置过长缓存容易溢出，设置过短无效果，可用于记录时效性数据，例如验证码--&gt; &lt;!-- timeToLiveSeconds：最大存活时间--&gt; &lt;!-- memoryStoreEvictionPolicy：缓存清除策略--&gt; &lt;defaultCache eternal=&quot;false&quot; diskPersistent=&quot;false&quot; maxElementsInMemory=&quot;1000&quot; overflowToDisk=&quot;false&quot; timeToIdleSeconds=&quot;60&quot; timeToLiveSeconds=&quot;60&quot; memoryStoreEvictionPolicy=&quot;LRU&quot; /&gt; &lt;!--注意这里要定义保存的空间 --&gt; &lt;cache name=&quot;smsCode&quot; eternal=&quot;false&quot; diskPersistent=&quot;false&quot; maxElementsInMemory=&quot;1000&quot; overflowToDisk=&quot;false&quot; timeToIdleSeconds=&quot;10&quot; timeToLiveSeconds=&quot;10&quot; memoryStoreEvictionPolicy=&quot;LRU&quot; /&gt;&lt;/ehcache&gt; ​ 注意前面的案例中，设置了数据保存的位置是smsCode 12345@CachePut(value = &quot;smsCode&quot;, key = &quot;#tele&quot;)public String sendCodeToSMS(String tele) &#123; String code = codeUtils.generator(tele); return code;&#125; ​ 这个设定需要保障ehcache中有一个缓存空间名称叫做smsCode的配置，所以Ehcahce的配置中也要配置该缓存空间。 ​ 可以看出换了缓存后并没有影响缓存造作@Cacheable和@CachePut 3）redis缓存​ 具体操作基本和Ehcache一致，加坐标，改缓存实现类型为redis，做redis的配置。差别之处只有一点，redis的配置可以在yml文件中直接进行配置，无需制作独立的配置文件。 步骤①：导入redis的坐标 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 步骤②：配置缓存技术实现使用redis 123456spring: redis: host: localhost port: 6379 cache: type: redis ​ 如果需要对redis作为缓存进行配置，注意不是对原始的redis进行配置，而是配置redis作为缓存使用相关的配置，隶属于spring.cache.redis节点下，注意不要写错位置了。 1234567891011spring: redis: host: localhost port: 6379 cache: type: redis redis: use-key-prefix: false key-prefix: sms_ cache-null-values: false # 默认配置不能缓存null值 time-to-live: 10s 总结 springboot使用redis作为缓存实现需要导入redis的坐标 修改设置，配置缓存供应商为redis，并提供对应的缓存配置 4）Memcached缓存变更缓存为Memcached ​ 由于memcached未被springboot收录为缓存解决方案，因此使用memcached需要通过手工硬编码的方式来使用（即@Cacheable和@CachePut没用了） ​ memcached目前提供有三种客户端技术，分别是Memcached Client for Java、SpyMemcached和Xmemcached，其中性能指标各方面最好的客户端是Xmemcached，本次整合就使用这个作为客户端实现技术了。下面开始使用Xmemcached： 步骤①：导入xmemcached的坐标 12345&lt;dependency&gt; &lt;groupId&gt;com.googlecode.xmemcached&lt;/groupId&gt; &lt;artifactId&gt;xmemcached&lt;/artifactId&gt; &lt;version&gt;2.4.7&lt;/version&gt;&lt;/dependency&gt; 步骤②：配置memcached，制作memcached的配置类并返回Xmemcached 123456789@Configurationpublic class XMemcachedConfig &#123; @Bean public MemcachedClient getMemcachedClient() throws IOException &#123; MemcachedClientBuilder memcachedClientBuilder = new XMemcachedClientBuilder(&quot;localhost:11211&quot;); MemcachedClient memcachedClient = memcachedClientBuilder.build(); return memcachedClient; &#125;&#125; ​ memcached默认对外服务端口11211。 ​ 配置属性的注入 定义配置类，加载必要的配置属性，读取配置文件中memcached节点信息 12345678@Component@ConfigurationProperties(prefix = &quot;memcached&quot;)@Datapublic class XMemcachedProperties &#123; private String servers; private int poolSize; private long opTimeout;&#125; 定义memcached节点信息 1234memcached: servers: localhost:11211 poolSize: 10 opTimeout: 3000 在memcached配置类中加载信息 12345678910111213@Configurationpublic class XMemcachedConfig &#123; @Autowired private XMemcachedProperties props; @Bean public MemcachedClient getMemcachedClient() throws IOException &#123; MemcachedClientBuilder memcachedClientBuilder = new XMemcachedClientBuilder(props.getServers()); memcachedClientBuilder.setConnectionPoolSize(props.getPoolSize()); memcachedClientBuilder.setOpTimeout(props.getOpTimeout()); MemcachedClient memcachedClient = memcachedClientBuilder.build(); return memcachedClient; &#125;&#125; 步骤③：使用xmemcached客户端操作缓存，注入MemcachedClient对象 123456789101112131415161718192021222324252627@Servicepublic class SMSCodeServiceImpl implements SMSCodeService &#123; @Autowired private CodeUtils codeUtils; @Autowired private MemcachedClient memcachedClient; public String sendCodeToSMS(String tele) &#123; String code = codeUtils.generator(tele); try &#123; memcachedClient.set(tele,10,code); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return code; &#125; public boolean checkCode(SMSCode smsCode) &#123; String code = null; try &#123; code = memcachedClient.get(smsCode.getTele()).toString(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return smsCode.getCode().equals(code); &#125;&#125; ​ 总结： memcached安装后需要启动对应服务才可以对外提供缓存功能，安装memcached服务需要基于windows系统管理员权限 由于springboot没有提供对memcached的缓存整合方案，需要采用手工编码的形式创建xmemcached客户端操作缓存 导入xmemcached坐标后，创建memcached配置类，注册MemcachedClient对应的bean，用于操作缓存 初始化MemcachedClient对象所需要使用的属性可以通过自定义配置属性类的形式加载 思考 ​ redis需要安装独立的服务器，连接时需要输入对应的服务器地址，这种是远程缓存。Ehcache是一个典型的内存级缓存，因为它什么也不用安装，启动后导入jar包就有缓存功能了。考虑是否能够同时使用者两种类型的缓存，j2cache就可以做到。 10.定时任务整合1）Quartz​ Quartz技术是一个比较成熟的定时任务框架，有点繁琐，配置略微复杂。springboot对其进行整合后，简化了一系列的配置，将很多配置采用默认设置，整体变得较简单。 工作（Job）：用于定义具体执行的工作 工作明细（JobDetail）：用于描述定时工作相关的信息 触发器（Trigger）：描述了工作明细与调度器的对应关系 调度器（Scheduler）：用于描述触发工作的执行规则，通常使用cron表达式定义规则 ​ 简单说就是你定时干什么事情，这就是工作，工作不可能就是一个简单的方法，还要设置一些明细信息。工作啥时候执行，设置一个调度器，可以简单理解成设置一个工作执行的时间。工作和调度都是独立定义的，它们两个怎么配合到一起呢？用触发器。完了，就这么多。下面开始springboot整合Quartz。 步骤①：导入springboot整合Quartz的starter 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-quartz&lt;/artifactId&gt;&lt;/dependency&gt; 步骤②：定义任务Bean，按照Quartz的开发规范制作，继承QuartzJobBean，这就是Job 123456public class MyJob extends QuartzJobBean &#123; @Override protected void executeInternal(JobExecutionContext context) throws JobExecutionException &#123; System.out.println(&quot;quartz task run...&quot;); &#125;&#125; 步骤③：创建Quartz配置类，定义工作明细（JobDetail）与触发器的（Trigger）bean（包含调度器（Scheduler）） 1234567891011121314151617181920212223242526@Configurationpublic class QuartzConfig &#123; //这是工作对应的工作明细 @Bean public JobDetail printJobDetail()&#123; //绑定具体的工作 return JobBuilder. newJob(MyJob.class).//这里还有很多其他参数，如取别名 storeDurably(). build(); &#125; //这是对应工作明细绑定的触发器 @Bean public Trigger printJobTrigger()&#123; //Cron表达式，也就是scheduler ScheduleBuilder schedBuilder = CronScheduleBuilder.cronSchedule(&quot;0/5 * * * * ?&quot;);//每5s执行一次 //绑定对应的工作明细 return TriggerBuilder. newTrigger(). forJob(printJobDetail()).//传入工作明细 withSchedule(schedBuilder).//传入调度器 build(); &#125;&#125; ​ 工作明细中要设置对应的具体工作，使用newJob()操作传入对应的工作任务类型即可。 ​ 触发器需要绑定任务，使用forJob()操作传入绑定的工作明细对象。此处可以为工作明细设置名称然后使用名称绑定，也可以直接调用对应方法绑定。触发器中最核心的规则是执行时间，此处使用调度器定义执行时间，执行时间描述方式使用的是cron表达式。 总结 springboot整合Quartz就是将Quartz对应的核心对象交给spring容器管理，包含两个对象，JobDetail和Trigger对象 JobDetail对象描述的是工作的执行信息，需要绑定一个QuartzJobBean类型的对象 Trigger对象定义了一个触发器，需要为其指定绑定的JobDetail是哪个，同时要设置执行周期调度器 2）Task​ spring根据定时任务的特征，将定时任务的开发简化到了极致，Task是Quartz的一个轻量级实现。 步骤①：开启定时任务功能，在引导类上开启定时任务功能的开关，使用注解@EnableScheduling 12345678@SpringBootApplication//开启定时任务功能@EnableSchedulingpublic class Springboot22TaskApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(Springboot22TaskApplication.class, args); &#125;&#125; 步骤②：定义Bean，在对应要定时执行的操作上方，使用注解@Scheduled定义执行的时间，执行时间的描述方式还是cron表达式 1234567@Componentpublic class MyBean &#123; @Scheduled(cron = &quot;0/1 * * * * ?&quot;) public void print()&#123; System.out.println(Thread.currentThread().getName()+&quot; :spring task run...&quot;); &#125;&#125; ​ ​ 如何想对定时任务进行相关配置，可以通过配置文件进行 123456789spring: task: scheduling: pool: size: 1 # 任务调度线程池大小 默认 1 thread-name-prefix: ssm_ # 调度线程名称前缀 默认 scheduling- shutdown: await-termination: false # 线程池关闭时等待所有任务完成 await-termination-period: 10s # 调度线程关闭前最大等待时间，确保最后一定关闭 总结 spring task需要使用注解@EnableScheduling开启定时任务功能 为定时执行的的任务设置执行周期，描述方式cron表达式 task相关：http://www.blogjava.net/bolo/archive/2015/03/12/423408.html 11.邮件文件发送协议（计网知识）： SMTP（Simple Mail Transfer Protocol）：简单邮件传输协议，用于发送电子邮件的传输协议 POP3（Post Office Protocol - Version 3）：用于接收电子邮件的标准协议 IMAP（Internet Mail Access Protocol）：互联网消息协议，是POP3的替代协议 1）简单邮件即使用JavaMailSender 步骤①：导入springboot整合javamail的starter 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt;&lt;/dependency&gt; 步骤②：配置邮箱的登录信息 12345spring: mail: host: smtp.163.com username: test@163.com password: test ​ java程序仅用于发送邮件，邮件的功能还是邮件供应商提供的，所以这里是用别人的邮件服务，要配置对应信息。 ​ host配置的是提供邮件服务的主机协议，当前程序仅用于发送邮件，因此配置的是smtp的协议。 ​ password并不是邮箱账号的登录密码，是邮件供应商提供的一个加密后的密码，也是为了保障系统安全性。不然外部人员通过地址访问下载了配置文件，直接获取到了邮件密码就会有极大的安全隐患。有关该密码的获取每个邮件供应商提供的方式都不一样，此处略过。可以到邮件供应商的设置页面找POP3或IMAP这些关键词找到对应的获取位置。下例仅供参考： 步骤③：发送邮件 1234567891011121314151617181920212223242526272829public interface IMailService &#123; void sendMail();&#125;@Servicepublic class SendMailServiceImpl implements SendMailService &#123; @Autowired private JavaMailSender javaMailSender; //发送人 private String from = &quot;test@qq.com&quot;; //接收人 private String to = &quot;test@126.com&quot;; //标题 private String subject = &quot;测试邮件&quot;; //正文 private String context = &quot;测试邮件正文内容&quot;; @Override public void sendMail() &#123; SimpleMailMessage message = new SimpleMailMessage(); message.setFrom(from+&quot;(摩西)&quot;);//若from后面加字&quot;(xx)&quot;，收件人邮箱from就是xx message.setTo(to); message.setSubject(subject); message.setText(context); javaMailSender.send(message); &#125;&#125; ​ 将发送邮件的必要信息（发件人、收件人、标题、正文）封装到SimpleMailMessage对象中，可以根据规则设置发送人昵称等。 2）发送多组件邮件​ 邮件携带附件、复杂正文（html） ​ 发送简单邮件仅需要提供对应的4个基本信息就可以了，如果想发送复杂的邮件，需要更换邮件对象。使用MimeMessage可以发送特殊的邮件。 发送网页正文邮件 1234567891011121314151617181920212223242526272829@Servicepublic class SendMailServiceImpl2 implements SendMailService &#123; @Autowired private JavaMailSender javaMailSender; //发送人 private String from = &quot;test@qq.com&quot;; //接收人 private String to = &quot;test@126.com&quot;; //标题 private String subject = &quot;测试邮件&quot;; //正文 private String context = &quot;&lt;img src=&#x27;ABC.JPG&#x27;/&gt;&lt;a href=&#x27;https://www.itcast.cn&#x27;&gt;点开有惊喜&lt;/a&gt;&quot;; public void sendMail() &#123; try &#123; MimeMessage message = javaMailSender.createMimeMessage(); MimeMessageHelper helper = new MimeMessageHelper(message,true);//第二个boolean代表支持多组件：附件等 helper.setFrom(to+&quot;(小甜甜)&quot;); helper.setTo(from); helper.setSubject(subject); helper.setText(context,true); //此处设置正文支持html解析 javaMailSender.send(message); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; helper.setText(context,true);这里的第二个参数为true代表正文支持html解析 发送带有附件的邮件 123456789101112131415161718192021222324252627282930313233343536@Servicepublic class SendMailServiceImpl2 implements SendMailService &#123; @Autowired private JavaMailSender javaMailSender; //发送人 private String from = &quot;test@qq.com&quot;; //接收人 private String to = &quot;test@126.com&quot;; //标题 private String subject = &quot;测试邮件&quot;; //正文 private String context = &quot;测试邮件正文&quot;; public void sendMail() &#123; try &#123; MimeMessage message = javaMailSender.createMimeMessage(); MimeMessageHelper helper = new MimeMessageHelper(message,true); //第二个boolean代表支持多组件：附件等 helper.setFrom(to+&quot;(摩西)&quot;); helper.setTo(from); helper.setSubject(subject); helper.setText(context); //添加附件 File f1 = new File(&quot;springboot_23_mail-0.0.1-SNAPSHOT.jar&quot;); File f2 = new File(&quot;resources\\\\logo.png&quot;); helper.addAttachment(f1.getName(),f1); helper.addAttachment(&quot;kamenlaida.png&quot;,f2); //注意这里要加后缀.png才能预览 javaMailSender.send(message); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; MimeMessageHelper helper &#x3D; new MimeMessageHelper(message,true);这里第二个boolean代表支持多组件：附件等 总结： MimeMsg需要MimeMsgHelper来设置属性，但最后send的任然是javaMailSender.send(mimeMsg) 发送html解析正文需要：helper.setText(context,true); &#x2F;&#x2F;此处设置正文支持html解析 发送附件需要：MimeMessageHelper helper &#x3D; new MimeMessageHelper(message,true); &#x2F;&#x2F;第二个boolean代表支持多组件：附件等 12.监控现在有3个服务支撑着一个程序的运行，每个服务都有自己的运行状态。 ​ 此时被监控的信息就要在三个不同的程序中去查询并展示，但是三个服务是服务于一个程序的运行的，如果不能合并到一个平台上展示，监控工作量巨大，而且信息对称性差，要不停的在三个监控端查看数据。如果将业务放大成30个，300个，3000个呢？看来必须有一个单独的平台，将多个被监控的服务对应的监控指标信息汇总在一起，这样更利于监控工作的开展。 ​ 新的程序专门用来监控，新的问题就出现了，是被监控程序主动上报信息还是监控程序主动获取信息？如果监控程序不能主动获取信息，这就意味着监控程序有可能看到的是很久之前被监控程序上报的信息，万一被监控程序宕机了，监控程序就无法区分究竟是好久没发信息了，还是已经下线了。所以监控程序必须具有主动发起请求获取被监控服务信息的能力。 ​ 如果监控程序要监控服务时，主动获取对方的信息。那监控程序如何知道哪些程序被自己监控呢？不可能在监控程序中设置我监控谁，这样互联网上的所有程序岂不是都可以被监控到，这样的话信息安全将无法得到保障。合理的做法只能是在被监控程序启动时上报监控程序，告诉监控程序你可以监控我了。看来需要在被监控程序端做主动上报的操作，这就要求被监控程序中配置对应的监控程序是谁。 ​ 被监控程序可以提供各种各样的指标数据给监控程序看，但是每一个指标都代表着公司的机密信息，并不是所有的指标都可以给任何人看的，所以被监控指标的是否开放出来给监控系统看，也需要做详细的设定。 1）Spring Boot Admin​ Spring Boot Admin是一个开源的web程序，它通过请求获得actuator的相关端点信息，在web上进行呈现、 ①监控端监控端也就是服务端开发 步骤①：导入springboot admin对应的starter，版本与当前使用的springboot版本保持一致，并将其配置成web工程 12345678910&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; ​ 上述过程可以通过创建项目时使用勾选的形式完成。 步骤②：在引导类上添加注解@EnableAdminServer，声明当前应用启动后作为SpringBootAdmin的服务器使用 1234567@SpringBootApplication@EnableAdminServerpublic class Springboot25AdminServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(Springboot25AdminServerApplication.class, args); &#125;&#125; ​ ②被监控端被监控端也就是客户端开发，客户端程序开发其实和服务端开发思路基本相似，多了一些配置而已。 步骤①：导入springboot admin对应的starter，版本与当前使用的springboot版本保持一致，并将其配置成web工程 12345678910&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; ​ 上述过程也可以通过创建项目时使用勾选的形式完成，不过一定要小心，端口配置成不一样的，否则会冲突。 步骤②：设置当前客户端将信息上传到哪个服务器上（监控端），通过yml文件配置 12345spring: boot: admin: client: url: http://localhost:8080 # 这里的port是监控端的port ​ 步骤③开放指定信息给服务器看 配置如下： 123456789server: port: 80spring: boot: admin: client: url: http://localhost:8080 //这里定义了作为客户端，应将数据发送给哪个服务器 ​ springbootadmin的客户端默认开放了13组信息给服务器，但是这些信息除了一个之外，其他的信息都不让通过HTTP请求查看。所以你看到的信息基本上就没什么内容了，只能看到一个内容，就是下面的健康信息。 ​ 但是即便如此我们看到健康信息中也没什么内容，原因在于健康信息中有一些信息描述了你当前应用使用了什么技术等信息，如果无脑的对外暴露功能会有安全隐患。通过配置就可以开放所有的健康信息明细查看了。 12345678910111213server: port: 80spring: boot: admin: client: url: http://localhost:8080 //这里定义了作为客户端，应将数据发送给哪个服务器management: endpoint: health: show-details: always # 在没开启之前这里的默认值是never ​ 这样我们就可以查看所有的健康信息了，但目前除了健康信息，其他信息都查阅不了。原因在于其他12种信息是默认不提供给服务器通过HTTP请求查阅的，所以需要开启查阅的内容项，使用*表示查阅全部。 12345678910111213141516171819server: port: 80spring: boot: admin: client: url: http://localhost:8080 //这里定义了作为客户端，应将数据发送给哪个服务器management: endpoint: health: show-details: always # 在没开启之前这里的默认值是never endpoints: web: exposure: include: &quot;*&quot; # include: health 默认只开启了health ​ 这样就可以在web端看到这些信息了 ③配置多个客户端​ 可以通过配置客户端的方式在其他的springboot程序中添加客户端坐标，这样当前服务器就可以监控多个客户端程序了。每个客户端展示不同的监控信息。 类加载面板中可以查阅到开发者自定义的类，如左图 ​ 映射中可以查阅到当前应用配置的所有请求 ​ 性能指标中可以查阅当前应用独有的请求路径统计数据 ​ 总结 开发监控服务端需要导入坐标，然后在引导类上添加注解@EnableAdminServer，并将其配置成web程序即可 开发被监控的客户端需要导入坐标，然后配置服务端服务器地址，并做开放指标的设定即可 在监控平台中可以查阅到各种各样被监控的指标，前提是客户端开放了被监控的指标 2）监控原理​ 监控平台中显示的信息实际上是通过对被监控的应用发送请求得到的。打开被监控应用的pom文件，其中导入了springboot admin的对应的client，在这个资源中导入了一个名称叫做actuator的包。被监控的应用之所以可以对外提供&#x2F;actuator&#x2F;…请求路径，就是因为添加了这个包。 ​ Actuator，可以称为端点，描述了一组监控信息，SpringBootAdmin提供了多个内置端点，通过访问端点就可以获取对应的监控信息，也可以根据需要自定义端点信息。通过发送请求路径**&#x2F;actuator可以访问应用所有端点信息，如果端点中还有明细信息可以发送请求&#x2F;actuator&#x2F;端点名称**来获取详细信息。以下列出了所有端点信息说明： ID 描述 默认启用 auditevents 暴露当前应用程序的审计事件信息。 是 beans 显示应用程序中所有 Spring bean 的完整列表。 是 caches 暴露可用的缓存。 是 conditions 显示在配置和自动配置类上评估的条件以及它们匹配或不匹配的原因。 是 configprops 显示所有 @ConfigurationProperties 的校对清单。 是 env 暴露 Spring ConfigurableEnvironment 中的属性。 是 flyway 显示已应用的 Flyway 数据库迁移。 是 health 显示应用程序健康信息 是 httptrace 显示 HTTP 追踪信息（默认情况下，最后 100 个 HTTP 请求&#x2F;响应交换）。 是 info 显示应用程序信息。 是 integrationgraph 显示 Spring Integration 图。 是 loggers 显示和修改应用程序中日志记录器的配置。 是 liquibase 显示已应用的 Liquibase 数据库迁移。 是 metrics 显示当前应用程序的指标度量信息。 是 mappings 显示所有 @RequestMapping 路径的整理清单。 是 scheduledtasks 显示应用程序中的调度任务。 是 sessions 允许从 Spring Session 支持的会话存储中检索和删除用户会话。当使用 Spring Session 的响应式 Web 应用程序支持时不可用。 是 shutdown 正常关闭应用程序。 否 threaddump 执行线程 dump。 是 heapdump 返回一个 hprof 堆 dump 文件。 是 jolokia 通过 HTTP 暴露 JMX bean（当 Jolokia 在 classpath 上时，不适用于 WebFlux）。 是 logfile 返回日志文件的内容（如果已设置 logging.file 或 logging.path 属性）。支持使用 HTTP Range 头来检索部分日志文件的内容。 是 prometheus 以可以由 Prometheus 服务器抓取的格式暴露指标。 是 ​ 上述端点每一项代表被监控的指标，如果对外开放则监控平台可以查询到对应的端点信息，如果未开放则无法查询对应的端点信息。通过配置可以设置端点是否对外开放功能。使用enable属性控制端点是否对外开放。其中health端点为默认端点，不能关闭。 123456management: endpoint: health: # 端点名称 show-details: always info: # 端点名称 enabled: true # 是否开放 ​ 为了方便开发者快速配置端点，springboot admin设置了13个较为常用的端点作为默认开放的端点，如果需要控制默认开放的端点的开放状态，可以通过配置设置，如下： 123management: endpoints: enabled-by-default: true # 是否开启默认端点，默认值true ​ 上述端点开启后，就可以通过端点对应的路径查看对应的信息了。但是此时还不能通过HTTP请求查询此信息，还需要开启通过HTTP请求查询的端点名称，使用“*”可以简化配置成开放所有端点的WEB端HTTP请求权限。 12345management: endpoints: web: exposure: include: &quot;*&quot; ​ 整体上来说，对于端点的配置有两组信息，一组是endpoints开头的，对所有端点进行配置，一组是endpoint开头的，对具体端点进行配置。 12345678910111213management: endpoint: # 具体端点的配置 health: show-details: always info: enabled: true endpoints: # 全部端点的配置 web: exposure: include: &quot;*&quot; enabled-by-default: true #开启springboot admin设置了13个较为常用的端点作为默认开放的端点 enabled-by-default只是在说客户端开启了这13个端点，并不代表web端有权限查看 因为除了web端，java还可以通过以jconsole的形式进行监控查看，jconsle并不是通过http技术来获得数据的，而是通过jmx技术获得数据的，所以jconsle拥有查看这些开发端点的所有权限 而web并没有查看这些开发端点所有权限，需要单独配置 3）自定义端点信息​ 端点描述了被监控的信息，除了系统默认的指标，还可以自行添加显示的指标，下面就通过3种不同的端点的指标自定义方式来学习端点信息的二次开发。 ①INFO端点​ info端点描述了当前应用的基本信息，没有配置的时候里面没有信息，可以通过两种形式快速配置info端点的信息 配置形式 在yml文件中通过设置info节点的信息就可以快速配置端点信息 1234info: appName: @project.artifactId@ # 从pom中获取数据 version: @project.version@ author: fla 配置完毕后，对应信息显示在监控平台上 也可以通过请求端点信息路径获取对应json信息 编程形式 通过配置的形式只能添加固定的数据，如果需要动态数据还可以通过配置bean的方式为info端点添加信息，此信息与配置信息共存 注：需要实现InfoContributor接口，方法需要传入Info.Builder builder（自动装配） 1234567891011@Componentpublic class InfoConfig implements InfoContributor &#123; @Override public void contribute(Info.Builder builder) &#123; builder.withDetail(&quot;runTime&quot;,System.currentTimeMillis()); //添加单个信息 Map infoMap = new HashMap(); infoMap.put(&quot;buildTime&quot;,&quot;2006&quot;); builder.withDetails(infoMap); //添加一组信息 &#125;&#125; ②Health端点​ health端点描述当前应用的运行健康指标，即程序中各个组件的运行情况（mysql、redis等），即应用的运行是否成功。通过编程的形式可以扩展指标信息。 注：需要继承AbstractHealthIndicator，方法需要传入Health.Builder builder（自动装配） 1234567891011121314151617@Componentpublic class HealthConfig extends AbstractHealthIndicator &#123; @Override protected void doHealthCheck(Health.Builder builder) throws Exception &#123; boolean condition = true; if(condition) &#123; builder.status(Status.UP); //设置运行状态为启动状态 builder.withDetail(&quot;runTime&quot;, System.currentTimeMillis()); Map infoMap = new HashMap(); infoMap.put(&quot;buildTime&quot;, &quot;2006&quot;); builder.withDetails(infoMap); &#125;else&#123; builder.status(Status.OUT_OF_SERVICE); //设置运行状态为不在服务状态 builder.withDetail(&quot;上线了吗？&quot;,&quot;你做梦&quot;); &#125; &#125;&#125; ​ 当任意一个组件状态不为UP时，整体应用对外服务状态为非UP状态。 ③Metrics端点​ metrics端点描述了性能指标，除了系统自带的监控性能指标，还可以自定义性能指标。 这里是在某个service中new了一个构造方法，并加了参数，在加载这个bean的时候就会加载MeterRegistry meterRegistry 注意： counter &#x3D; meterRegistry.counter(“用户付费操作次数：”);里面添加了key值，counter则是value 1234567891011121314151617@Servicepublic class BookServiceImpl extends ServiceImpl&lt;BookDao, Book&gt; implements IBookService &#123; @Autowired private BookDao bookDao; private Counter counter; public BookServiceImpl(MeterRegistry meterRegistry)&#123; counter = meterRegistry.counter(&quot;用户付费操作次数：&quot;); &#125; @Override public boolean spend(Integer id) &#123; counter.increment(); return bookDao.spend(id) &gt; 0; &#125;&#125; ​ 在性能指标中就出现了自定义的性能指标监控项 ④自定义端点​ 可以根据业务需要自定义端点，方便业务监控 @Endpoint(id&#x3D;”pay”,enableByDefault &#x3D; true) id是&#x2F;actuators&#x2F;xx中的xx enableByDefault &#x3D; true 代表默认开启，否则就需要在配置中开启了 &#96;&#96;&#96;ymlmanagement: endpoint: # 具体端点的配置health: show-details: alwaysinfo: enabled: truepay: enabled: true 1234567891011121314151617* 必须@ReadOperation 定义一个方法，方法名随便，这个方法是在请求/actuators/pay后执行的操作 * 可以通过map来返回jason数据```JAVA@Component@Endpoint(id=&quot;pay&quot;,enableByDefault = true)public class PayEndpoint &#123; @ReadOperation public Object getPay()&#123; Map payMap = new HashMap(); payMap.put(&quot;level 1&quot;,&quot;300&quot;); payMap.put(&quot;level 2&quot;,&quot;291&quot;); payMap.put(&quot;level 3&quot;,&quot;666&quot;); return payMap; &#125;&#125; ​ 由于此端点数据spirng boot admin无法预知该如何展示，所以通过admin界面无法看到此数据，通过HTTP请求路径可以获取到当前端点的信息，但是需要先开启当前端点对外功能，或者设置当前端点为默认开发的端点。","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://example.com/categories/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://example.com/tags/Spring-Boot/"}]},{"title":"Spring Boot基本使用","slug":"spring Boot基本使用","date":"2022-04-11T04:06:12.000Z","updated":"2022-06-23T10:31:16.369Z","comments":true,"path":"2022/04/11/spring Boot基本使用/","link":"","permalink":"http://example.com/2022/04/11/spring%20Boot%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/","excerpt":"一些Spring Boot的基本使用—_—","text":"一些Spring Boot的基本使用—_— 1.简化操作1）parent①spring initializr ​ ①boot继承了②starter-parent，而②starter-parent中又继承了③boot-dependencies，在③中定义了一系列**properties用于版本管理，又定义了dependencyManagement**用于坐标管理，所以我们可以很方便的定义使用依赖而不用在意版本。 ②阿里云 阿里云则是直接import过来了，效果是一样的（继承只能是一次） 2）starter①使用当我们使用某一种技术的时候，导入的往往是一系列组合，所以我们可以将这一类组合进行一个整合做成一个starter，如starter-web web-starter的version则是在parent中定义的 注意： ​ SpringBoot官方给出了好多个starter的定义，方便我们使用，而且名称都是如下格式 1命名规则：spring-boot-starter-技术名称 所以我们在使用某种技术的时候，首先去找该技术的starter，如果没有则自己写 如druid： ②starter与parent的区别 starter：是一个坐标中定了若干个坐标，以前写多个的，现在写一个，是用来减少依赖配置的书写量的 parent：是定义了几百个依赖版本号，以前写依赖需要自己手工控制版本，现在由SpringBoot统一管理，这样就不存在版本冲突了，是用来减少依赖冲突的 3）引导类当前这个类运行后就会产生一个Spring容器对象，并且可以将这个对象保存起来，通过容器对象直接操作Bean。 123456789@SpringBootApplicationpublic class Springboot0101QuickstartApplication &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext ctx = SpringApplication.run(Springboot0101QuickstartApplication.class, args); BookController bean = ctx.getBean(BookController.class); System.out.println(&quot;bean======&gt;&quot; + bean); &#125;&#125; ​ 通过上述操作不难看出，其实SpringBoot程序启动还是创建了一个Spring容器对象。这个类在SpringBoot程序中是所有功能的入口，称这个类为引导类。 ​ 作为一个引导类最典型的特征就是当前类上方声明了一个注解**@SpringBootApplication**，注意默认扫描的路径是当前package及子包 4）内嵌tomcat①基本​ tomcat运行起来也是对象，如果是对象，那Spring容器是用来管理对象的，tomcat服务器运行其实就是以对象的形式在Spring容器中运行的。 ②内置服务器SpringBoot提供了3款内置的服务器： tomcat(默认)：apache出品，粉丝多，应用面广，负载了若干较重的组件 jetty：更轻量级，负载性能远不及tomcat undertow：负载性能勉强跑赢tomcat 2.基础配置1）三种格式 application.properties（properties格式） 12server.port=80spring.main.banner-mode=off application.yml（yml格式，主流） 12345server: port: 81logging: level: root: debug application.yaml（yaml格式） 12server: port: 82 ​ 最终端口为80，同时其他两条配置也生效了。即每个配置文件中的项都会生效，只不过如果多个配置文件中有相同类型的配置会优先级高的文件覆盖优先级的文件中的配置。如果配置项不同的话，那所有的配置项都会生效。 总结 配置文件间的加载优先级 properties（最高）&gt; yml &gt; yaml（最低） 不同配置文件中相同配置按照加载优先级相互覆盖，不同配置文件中不同配置全部保留 ：12,13,14，最终1234都会加载 2）yml的书写①基本语法12345678boolean: TRUE #TRUE,true,True,FALSE,false，False均可float: 3.14 #6.8523015e+5 #支持科学计数法int: 123 #0b1010_0111_0100_1010_1110 #支持二进制、八进制、十六进制null: ~ #使用~表示nullstring: HelloWorld #字符串可以直接书写string2: &quot;Hello World&quot; #可以使用双引号包裹特殊字符date: 2018-02-17 #日期必须使用yyyy-MM-dd格式datetime: 2018-02-17T15:02:31+08:00 #时间和日期之间使用T连接，最后使用+代表时区 12345678910111213141516171819202122232425262728enterprise: name: itcast age: 16 subject: - Java - 前端 - 大数据subject: - Java - 前端 - 大数据 #数组书写缩略格式1likes: [Java,前端,大数据] #数组书写缩略格式2users: #对象数组格式1 - name: Tom age: 4 - name: Jerry age: 5users: #对象数组格式2 - name: Tom age: 4 - name: Jerry age: 5 users2: [ &#123; name:Tom , age:4 &#125; , &#123; name:Jerry , age:5 &#125; ] #对象数组缩略格式 总结： yaml语法规则 大小写敏感 属性层级关系使用多行描述，每行结尾使用冒号结束 使用缩进表示层级关系，同层级左侧对齐，只允许使用空格（不允许使用Tab键） 属性值前面添加空格（属性名与属性值之间使用冒号+空格作为分隔） #号 表示注释 注意属性名冒号后面与数据之间有一个空格 字面值、对象数据格式、数组数据格式 ②yml内部的数据引用在书写yaml数据时，经常出现如下现象，比如很多个文件都具有相同的目录前缀 12345center: dataDir: /usr/local/fire/data tmpDir: /usr/local/fire/tmp logDir: /usr/local/fire/log msgDir: /usr/local/fire/msgDir 或者 12345center: dataDir: D:/usr/local/fire/data tmpDir: D:/usr/local/fire/tmp logDir: D:/usr/local/fire/log msgDir: D:/usr/local/fire/msgDir ​ 这个时候可以使用引用格式来定义数据，其实就是搞了个变量名，然后引用变量了，格式如下： 1234567baseDir: /usr/local/firecenter: dataDir: $&#123;baseDir&#125;/data tmpDir: $&#123;baseDir&#125;/tmp logDir: $&#123;baseDir&#125;/log msgDir: $&#123;baseDir&#125;/msgDir ​ ③转义问题还有一个注意事项，在书写字符串时，如果需要使用转义字符，需要将数据字符串使用双引号包裹起来 lession: Spring**\\tboot\\n**lesson 这是不会解析的，会将整体看成一个字符串 lesson: “Spring**\\tboot\\n**lesson” 当加上””，其中的的转义内容就会被解析 3）yml数据的读取①读取单一数据 ②读取全部数据​ SpringBoot提供了一个对象，能够把所有的数据都封装到这一个对象中，这个对象叫做Environment，使用自动装配注解可以将所有的yaml数据封装到这个对象中 ​ 数据封装到了Environment对象中，获取属性时，通过Environment的接口操作进行，具体方法时getProperties（String），参数填写属性名即可： 使用Environment对象封装全部配置信息 使用@Autowired自动装配数据到Environment对象中 ③读取对象数据 ①yml中信息要封装到一个对象中，那么这个对象就需要交给spring管理 ②要找到该信息需要一个前缀，这个注解就是配置这个前缀的 3.第三方技术整合整合过程很简单： ①导入对应starter ②修改相应配置 ③直接使用 1）Junit①spring整合123456789101112131415//1.加载spring整合junit专用的类运行器@RunWith(SpringJUnit4ClassRunner.class)//2.指定对应的配置信息@ContextConfiguration(classes = SpringConfig.class)public class AccountServiceTestCase &#123; //3.注入你要测试的对象 @Autowired private AccountService accountService; @Test public void testGetById()&#123; //执行要测试的对象对应的方法 System.out.println(accountService.findById(2)); &#125;&#125; ②boot整合12345678910111213//1.表示该类为test类@SpringBootTestclass Springboot04JunitApplicationTests &#123; //2.注入你要测试的对象 @Autowired private BookDao bookDao; @Test void contextLoads() &#123; //执行要测试的对象对应的方法 bookDao.save(); System.out.println(&quot;two...&quot;); &#125;&#125; 注意： ​ 如果test类的包名和引导类的包名不同（不在一个包下），那么引导类就无法扫描到该test类，有两种配置可以解决 在@SpringBootTest指明 12345//指明引导类@SpringBootTest(classes = Springboot04JunitApplication.class)class Springboot04JunitApplicationTests &#123;&#125; 沿用spring的老方法 12345@SpringBootTest@ContextConfiguration(classes = Springboot04JunitApplication.class)class Springboot04JunitApplicationTests &#123;&#125; ②原理​ 运行test类的时候，test类会在自己的包下找响应的带了@SpringBootConfiguration的配置类，而@SpringBootApplication就含有该注解： 2）整合MyBatis①spring整合a）springConfig Spring核心配置： 123456@Configuration@ComponentScan(&quot;com.itheima&quot;)@PropertySource(&quot;jdbc.properties&quot;)@Import(&#123;dbcconfig.class, Mybatisconfig.class&#125;)public class SpringConfig &#123;&#125; b）jdbcConfig（druid） 123456789101112131415161718192021@Configurationpublic class JdbcConfig &#123; @Value(&quot;$&#123;jdbc.driver&#125;&quot;) private String driver; @Value(&quot;$&#123;jdbc.url&#125;&quot;) private String url; @Value(&quot;$&#123;jdbc.username&#125;&quot;) private String userName; @Value(&quot;$&#123;jdbc.password&#125;&quot;) private String password; @Bean(&quot;dataSource&quot;) public DataSource dataSource()&#123; DruidDataSource ds = new DruidDataSource(); ds.setDriverClassName(driver); ds.setUrl(url); ds.setUsername(userName); ds.setPassword(password); return ds; &#125;&#125; 数据库连接信息（properties格式） 1234jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/spring_db?useSSL=falsejdbc.username=rootjdbc.password=root c）MybatisConfig MyBatis要交给Spring接管的bean： 123456789101112131415161718192021222324//定义mybatis专用的配置类@Configurationpublic class MyBatisConfig &#123; //定义创建SqlSessionFactory对应的bean @Bean public SqlSessionFactoryBean sqlSessionFactory(DataSource dataSource)&#123;//自动注入dataSource //SqlSessionFactoryBean是由mybatis-spring包提供的，专用于整合用的对象 SqlSessionFactoryBean sfb = new SqlSessionFactoryBean(); //设置数据源替代原始配置中的environments的配置 sfb.setDataSource(dataSource); //设置类型别名替代原始配置中的typeAliases的配置 sfb.setTypeAliasesPackage(&quot;com.itheima.domain&quot;); return sfb; &#125; //定义加载所有的映射配置：告诉mapper类在哪儿 @Bean public MapperScannerConfigurer mapperScannerConfigurer()&#123; MapperScannerConfigurer msc = new MapperScannerConfigurer(); msc.setBasePackage(&quot;com.itheima.dao&quot;); return msc; &#125;&#125; ②boot整合步骤①：创建模块时勾选要使用的技术，MyBatis，由于要操作数据库，还要勾选对应数据库 步骤②：配置数据源相关信息（这个格式是boot定义的） 1234567#配置dataSource相关信息spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db username: root password: root 步骤③：配置mapper 实体类 123456public class Book &#123; private Integer id; private String type; private String name; private String description;&#125; 映射接口（Dao） 12345@Mapperpublic interface BookDao &#123; @Select(&quot;select * from tbl_book where id = #&#123;id&#125;&quot;) public Book getById(Integer id);&#125; 注意dao接口需要加@Mapper： https://blog.csdn.net/z828849eser/article/details/87561407 ③两个小问题问题1：mysql8.0的时区问题 ​ 当前使用的SpringBoot版本是2.5.4，对应的坐标设置中Mysql驱动使用的是8x版本。当SpringBoot2.4.3（不含）版本之前会出现一个小BUG，就是MySQL驱动升级到8以后要求强制配置时区，如果不设置会出问题。解决方案很简单，驱动url上面添加上对应设置就行了 1234567#2.配置相关信息spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=UTC #在这里设置时区的信息 username: root password: root ​ 这里设置的UTC是全球标准时间，是英国时间，中国处在东八区，需要在这个基础上加上8小时，这样才能和中国地区的时间对应的，也可以修改配置不写UTC，写Asia&#x2F;Shanghai也可以解决这个问题。 1234567#2.配置相关信息spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=Asia/Shanghai #在这里设置时区的信息 username: root password: root ​ 永久解决的办法是可以去修改mysql中的配置文件mysql.ini，在mysqld项中添加default-time-zone&#x3D;+8:00也可以解决这个问题 问题2：com.mysql.jdbc.Driver过时问题 数据库驱动过时的警告，根据提示修改配置即可，弃用**com.mysql.jdbc.Driver，换用com.mysql.cj.jdbc.Driver** 12Loading class `com.mysql.jdbc.Driver&#x27;. This is deprecated. The new driver class is`com.mysql.cj.jdbc.Driver&#x27;. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary. 3）整合MyBatis-plus①boot整合步骤①：导入对应的starter 12345&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.4.3&lt;/version&gt;&lt;/dependency&gt; starter命名规则： starter所属 命名规则 示例 官方提供 spring-boot-starter-技术名称 spring-boot-starter-web spring-boot-starter-test 第三方提供 第三方技术名称-spring-boot-starter druid-spring-boot-starter 第三方提供 第三方技术名称-boot-starter（第三方技术名称过长，简化命名） mybatis-plus-boot-starter 注意： ​ 目前spring boot并未收录该技术，所以需要我们手动去maven.repository中找 步骤②：配置数据源相关信息 123456spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db username: root password: root 步骤③：配置mapper 映射接口（Dao） 123@Mapperpublic interface BookDao extends BaseMapper&lt;Book&gt; &#123;&#125; ②表前缀名问题目前数据库的表名定义规则是tbl_模块名称，为了能和实体类相对应，需要配置application.yml文件 添加如下配置即可，设置所有表名的通用前缀名： 1234mybatis-plus: global-config: db-config: table-prefix: tbl_ #设置所有表的通用前缀名称为tbl_ ③主键自增问题​ MP技术默认的主键生成策略为雪花算法，生成的主键ID长度较大，和mysql的自增设定不相符，需要配置一下使MP使用数据库的主键生成策略， 在application.yml中添加对应配置即可，具体如下： 12345678910111213141516server: port: 80spring: datasource: druid: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=UTC username: root password: rootmybatis-plus: global-config: db-config: table-prefix: tbl_ #设置表名通用前缀 id-type: auto #设置主键id字段的生成策略为参照数据库设定的策略，当前数据库设置id生成策略为自增 ④log配置查看MP运行日志 ​ 在进行数据层测试的时候，因为基础的CRUD操作均由MP给我们提供了，所以就出现了一个局面，开发者不需要书写SQL语句了，一切的一切都是黑盒的，我们需要一种方式查看执行过程。 ​ SpringBoot整合MP的时候充分考虑到了这点，通过配置的形式就可以查阅执行期SQL语句，配置如下 1234567mybatis-plus: global-config: db-config: table-prefix: tbl_ id-type: auto #主键自增方式 configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl #打印输出到控制台 ​ 再来看运行结果，此时就显示了运行期执行SQL的情况。 12345678910111213141516171819202122Creating a new SqlSessionSqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@2c9a6717] was not registered for synchronization because synchronization is not activeJDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@6ca30b8a] will not be managed by Spring==&gt; Preparing: SELECT id,type,name,description FROM tbl_book==&gt; Parameters: &lt;== Columns: id, type, name, description&lt;== Row: 1, 计算机理论, Spring实战 第5版, Spring入门经典教程，深入理解Spring原理技术内幕&lt;== Row: 2, 计算机理论, Spring 5核心原理与30个类手写实战, 十年沉淀之作，手写Spring精华思想&lt;== Row: 3, 计算机理论, Spring 5 设计模式, 深入Spring源码剖析Spring源码中蕴含的10大设计模式&lt;== Row: 4, 计算机理论, Spring MVC+MyBatis开发从入门到项目实战, 全方位解析面向Web应用的轻量级框架，带你成为Spring MVC开发高手&lt;== Row: 5, 计算机理论, 轻量级Java Web企业应用实战, 源码级剖析Spring框架，适合已掌握Java基础的读者&lt;== Row: 6, 计算机理论, Java核心技术 卷I 基础知识（原书第11版）, Core Java 第11版，Jolt大奖获奖作品，针对Java SE9、10、11全面更新&lt;== Row: 7, 计算机理论, 深入理解Java虚拟机, 5个维度全面剖析JVM，大厂面试知识点全覆盖&lt;== Row: 8, 计算机理论, Java编程思想（第4版）, Java学习必读经典,殿堂级著作！赢得了全球程序员的广泛赞誉&lt;== Row: 9, 计算机理论, 零基础学Java（全彩版）, 零基础自学编程的入门图书，由浅入深，详解Java语言的编程思想和核心技术&lt;== Row: 10, 市场营销, 直播就该这么做：主播高效沟通实战指南, 李子柒、李佳琦、薇娅成长为网红的秘密都在书中&lt;== Row: 11, 市场营销, 直播销讲实战一本通, 和秋叶一起学系列网络营销书籍&lt;== Row: 12, 市场营销, 直播带货：淘宝、天猫直播从新手到高手, 一本教你如何玩转直播的书，10堂课轻松实现带货月入3W+&lt;== Row: 13, 测试类型, 测试数据, 测试描述数据&lt;== Row: 14, 测试数据update, 测试数据update, 测试数据update&lt;== Row: 15, -----------------, 测试数据123, 测试数据123&lt;== Total: 15 ​ 其中清晰的标注了当前执行的SQL语句是什么，携带了什么参数，对应的执行结果是什么，所有信息应有尽有。 ​ 此处设置的是日志的显示形式，当前配置的是控制台输出，当然还可以由更多的选择，根据需求切换即可 4）整合druid①默认的dataPool​ 在没有指定数据源时，我们的配置如下： 123456spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=Asia/Shanghai username: root password: root ​ 此时虽然没有指定数据源，但是SpringBoot选了一个它认为最好的数据源对象，这就是HiKari，通过启动日志可以查看到对应的身影。 1232021-11-29 09:39:15.202 INFO 12260 --- [ main] com.zaxxer.hikari.HikariDataSource : HikariPool-1 - Starting...2021-11-29 09:39:15.208 WARN 12260 --- [ main] com.zaxxer.hikari.util.DriverDataSource : Registered driver with driverClassName=com.mysql.jdbc.Driver was not found, trying direct instantiation.2021-11-29 09:39:15.551 INFO 12260 --- [ main] com.zaxxer.hikari.HikariDataSource : HikariPool-1 - Start completed. 上述信息中每一行都有HiKari的身影，如果需要更换数据源，其实只需要两步即可。 注： Hikari的故事：https://cloud.tencent.com/developer/news/561800 druid和Hikari的对比：https://juejin.cn/post/6885974851949953031 ②boot整合通用步骤①：导入对应的坐标（注意，是坐标，此处不是starter） 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 步骤②：修改配置，在数据源配置中有一个type属性，专用于指定数据源类型 1234567spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=UTC username: root password: root type: com.alibaba.druid.pool.DruidDataSource ​ 这里其实要提出一个问题的，目前的数据源配置格式是一个通用格式，不管你换什么数据源都可以用这种形式进行配置。 ​ 但是新的问题又来了，如果对数据源进行个性化的配置，例如配置数据源对应的连接数量，这个时候就有新的问题了。 ③boot整合专门步骤①：导入对应的starter 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.6&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 步骤②：修改配置 1234567spring: datasource: druid: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm_db?serverTimezone=UTC username: root password: root ​ 配置项中，在datasource下面并不是直接配置url这些属性的，而是先配置了一个druid节点，然后再配置的url这些东西。即druid下面含有url这个属性。 除了这4个常规配置外，还有druid专用的其他配置。通过提示功能可以打开druid相关的配置查阅： 4.MybatisPlus的使用1）dao的快速开发①分页MP提供的分页操作API如下 12345678910@Testvoid testGetPage()&#123; IPage page = new Page(2,5);//Ipage是接口 Page是实现类 bookDao.selectPage(page, null);//返回的仍然是Ipage page，实际上就是对从传入的page进行数据添加 System.out.println(page.getCurrent()); System.out.println(page.getSize()); System.out.println(page.getTotal()); System.out.println(page.getPages()); System.out.println(page.getRecords());&#125; ​ 其中selectPage方法需要传入一个封装分页数据的对象，可以通过new的形式创建这个对象，当然这个对象也是MP提供的，别选错包了。创建此对象时就需要指定分页的两个基本数据 当前显示第几页 每页显示几条数据 ​ 可以通过创建Page对象时利用构造方法初始化这两个数据 1IPage page = new Page(2,5); ​ 将该对象传入到查询方法selectPage后，可以得到查询结果，但是我们会发现当前操作查询结果返回值仍然是一个IPage对象 1IPage page = bookDao.selectPage(page, null); ​ 原来这个IPage对象中封装了若干个数据，而查询的结果作为IPage对象封装的一个数据存在的，可以理解为查询结果得到后，又塞到了这个IPage对象中，其实还是为了高度的封装，一个IPage描述了分页所有的信息。下面5个操作就是IPage对象中封装的所有信息了 12345678910@Testvoid testGetPage()&#123; IPage page = new Page(2,5); bookDao.selectPage(page, null); System.out.println(page.getCurrent()); //当前页码值 System.out.println(page.getSize()); //每页显示数 System.out.println(page.getTotal()); //数据总量 System.out.println(page.getPages()); //总页数 System.out.println(page.getRecords()); //详细数据&#125; 但是当你执行这个操作时，这个分页当前是无效的： ​ 对于MySQL的分页操作使用limit关键字进行，而并不是所有的数据库都使用limit关键字实现的，这个时候MP为了制作的兼容性强，将分页操作设置为基础查询操作的升级版，你可以理解为IPhone6与IPhone6S-PLUS的关系。 ​ 基础操作中有查询全部的功能，而在这个基础上只需要升级一下（PLUS）就可以得到分页操作。所以MP将分页操作做成了一个开关，你用分页功能就把开关开启，不用就不需要开启这个开关。而我们现在没有开启这个开关，所以分页操作是没有的。这个开关是通过MP的拦截器的形式存在的，具体设置方式如下 定义MP拦截器并将其设置为Spring管控的bean 123456789@Configurationpublic class MPConfig &#123; @Bean public MybatisPlusInterceptor mybatisPlusInterceptor()&#123; MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor();//制造了一个空的拦截器栈 interceptor.addInnerInterceptor(new PaginationInnerInterceptor());//添加了一个分页拦截器，打开了开关 return interceptor; &#125;&#125; ​ 上述代码第一行是创建MP的拦截器栈，这个时候拦截器栈中没有具体的拦截器，第二行是初始化了分页拦截器，并添加到拦截器栈中。如果后期开发其他功能，需要添加全新的拦截器，按照第二行的格式继续add进去新的拦截器就可以了。 ②条件查询​ 下面的操作就是执行一个模糊匹配对应的操作，由like条件书写变为了like方法的调用 123456@Testvoid testGetBy()&#123; QueryWrapper&lt;Book&gt; qw = new QueryWrapper&lt;&gt;(); qw.like(&quot;name&quot;,&quot;Spring&quot;); bookDao.selectList(qw);&#125; ​ 其中第一句QueryWrapper对象是一个用于封装查询条件的对象，该对象可以动态使用API调用的方法添加条件，最终转化成对应SQL语句。第二句就是一个条件了，需要什么条件，使用QueryWapper对象直接调用对应操作即可。比如做大于小于关系，就可以使用lt或gt方法，等于使用eq方法，等等，此处不做更多的解释了。 ​ 这组API使用还是比较简单的，但是关于属性字段名的书写存在着安全隐患，比如查询字段name，当前是以字符串的形态书写的，万一写错，编译器还没有办法发现，只能将问题抛到运行器通过异常堆栈告诉开发者，不太友好。 ​ MP针对字段检查进行了功能升级，全面支持Lambda表达式，就有了下面这组API。由QueryWrapper对象升级为LambdaQueryWrapper对象，这样在编写的时候就会报错 1234567@Testvoid testGetBy2()&#123; String name = &quot;1&quot;; LambdaQueryWrapper&lt;Book&gt; lqw = new LambdaQueryWrapper&lt;Book&gt;(); lqw.like(Book::getName,name); bookDao.selectList(lqw);&#125; ​ 为了便于开发者动态拼写SQL，防止将null数据作为条件使用，MP还提供了动态拼装SQL的快捷书写方式 12345678@Testvoid testGetBy2()&#123; String name = &quot;1&quot;; LambdaQueryWrapper&lt;Book&gt; lqw = new LambdaQueryWrapper&lt;Book&gt;(); //if(name != null) lqw.like(Book::getName,name); //方式一：JAVA代码控制 lqw.like(name != null,Book::getName,name); //方式二：API接口提供控制开关 bookDao.selectList(lqw);&#125; ​ 该语句在执行的时候会首先判断name!&#x3D;null，结果为真才会执行selectList 2）service快速开发123public interface IBookService extends IService&lt;Book&gt; &#123; //添加非通用操作API接口&#125; ​ 业务层接口实现类快速开发，关注继承的类需要传入两个泛型，前者是数据层接口，后者是实体类 123456@Servicepublic class BookServiceImpl extends ServiceImpl&lt;BookDao, Book&gt; implements IBookService &#123; @Autowired private BookDao bookDao; //添加非通用操作API&#125; ​ 当所提供的方法不满足需求的时候，我们需要自己写方法实现，注意不要override原来的方法，原方法使用remove，我们就使用delete","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://example.com/categories/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://example.com/tags/Spring-Boot/"}]},{"title":"mysql基本语法","slug":"mysql基本语法","date":"2022-04-04T07:29:48.000Z","updated":"2022-06-23T10:30:54.918Z","comments":true,"path":"2022/04/04/mysql基本语法/","link":"","permalink":"http://example.com/2022/04/04/mysql%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/","excerpt":"一些Mysql的基本语法^ ^","text":"一些Mysql的基本语法^ ^ 一、通用语法及分类 DDL: 数据定义语言，用来定义数据库对象（数据库、表、字段） DML: 数据操作语言，用来对数据库表中的数据进行增删改 DQL: 数据查询语言，用来查询数据库中表的记录 DCL: 数据控制语言，用来创建数据库用户、控制数据库的控制权限 1.DDL（数据定义语言）数据定义语言 1）数据库操作查询所有数据库：SHOW DATABASES;查询当前数据库：SELECT DATABASE();创建数据库：CREATE DATABASE [ IF NOT EXISTS ] 数据库名 [ DEFAULT CHARSET 字符集] [COLLATE 排序规则 ];删除数据库：DROP DATABASE [ IF EXISTS ] 数据库名;使用数据库：USE 数据库名; 注意事项 UTF8字符集长度为3字节，有些符号占4字节，所以推荐用utf8mb4字符集 2）表操作查询当前数据库所有表：SHOW TABLES;查询表结构：DESC 表名;查询指定表的建表语句：SHOW CREATE TABLE 表名; 创建表： 1234567CREATE TABLE 表名( 字段1 字段1类型 [COMMENT 字段1注释], 字段2 字段2类型 [COMMENT 字段2注释], 字段3 字段3类型 [COMMENT 字段3注释], ... 字段n 字段n类型 [COMMENT 字段n注释])[ COMMENT 表注释 ]; 最后一个字段后面没有逗号 添加字段：ALTER TABLE 表名 ADD 字段名 类型(长度) [COMMENT 注释] [约束];例：ALTER TABLE emp ADD nickname varchar(20) COMMENT &#39;昵称&#39;; 修改数据类型：ALTER TABLE 表名 MODIFY 字段名 新数据类型(长度);修改字段名和字段类型：ALTER TABLE 表名 CHANGE 旧字段名 新字段名 类型(长度) [COMMENT 注释] [约束];例：将emp表的nickname字段修改为username，类型为varchar(30)ALTER TABLE emp CHANGE nickname username varchar(30) COMMENT &#39;昵称&#39;; 删除字段：ALTER TABLE 表名 DROP 字段名; 修改表名：ALTER TABLE 表名 RENAME TO 新表名 删除表：DROP TABLE [IF EXISTS] 表名;删除表，并重新创建该表：TRUNCATE TABLE 表名; 2.DML（数据操作语言）1）添加数据指定字段：INSERT INTO 表名 (字段名1, 字段名2, ...) VALUES (值1, 值2, ...);全部字段：INSERT INTO 表名 VALUES (值1, 值2, ...); 批量添加数据：INSERT INTO 表名 (字段名1, 字段名2, ...) VALUES (值1, 值2, ...), (值1, 值2, ...), (值1, 值2, ...);INSERT INTO 表名 VALUES (值1, 值2, ...), (值1, 值2, ...), (值1, 值2, ...); 注意事项 字符串和日期类型数据应该包含在引号中 插入的数据大小应该在字段的规定范围内 2）更新和删除数据修改数据：UPDATE 表名 SET 字段名1 = 值1, 字段名2 = 值2, ... [ WHERE 条件 ];例：UPDATE emp SET name = &#39;Jack&#39; WHERE id = 1; 删除数据：DELETE FROM 表名 [ WHERE 条件 ]; 3.DQL（数据查询语言）语法： 1234567891011121314SELECT 字段列表FROM 表名字段WHERE 条件列表GROUP BY 分组字段列表HAVING 分组后的条件列表ORDER BY 排序字段列表LIMIT 分页参数 1）基础查询查询多个字段：SELECT 字段1, 字段2, 字段3, ... FROM 表名;SELECT * FROM 表名; 设置别名：SELECT 字段1 [ AS 别名1 ], 字段2 [ AS 别名2 ], 字段3 [ AS 别名3 ], ... FROM 表名;SELECT 字段1 [ 别名1 ], 字段2 [ 别名2 ], 字段3 [ 别名3 ], ... FROM 表名; 去除重复记录：SELECT DISTINCT 字段列表 FROM 表名; 转义：SELECT * FROM 表名 WHERE name LIKE &#39;/_张三&#39; ESCAPE &#39;/&#39;&#x2F; 之后的_不作为通配符 2）条件查询语法：SELECT 字段列表 FROM 表名 WHERE 条件列表; 条件： 比较运算符 功能 &gt; 大于 &gt;&#x3D; 大于等于 &lt; 小于 &lt;&#x3D; 小于等于 &#x3D; 等于 &lt;&gt; 或 !&#x3D; 不等于 BETWEEN … AND … 在某个范围内（含最小、最大值） IN(…) 在in之后的列表中的值，多选一 LIKE 占位符 模糊匹配（_匹配单个字符，%匹配任意个字符） IS NULL 是NULL 逻辑运算符 功能 AND 或 &amp;&amp; 并且（多个条件同时成立） OR 或 &amp;#124;&amp;#124; 或者（多个条件任意一个成立） NOT 或 ! 非，不是 例子： 123456789101112131415161718192021222324252627-- 年龄等于30select * from employee where age = 30;-- 年龄小于30select * from employee where age &lt; 30;-- 小于等于select * from employee where age &lt;= 30;-- 没有身份证select * from employee where idcard is null or idcard = &#x27;&#x27;;-- 有身份证select * from employee where idcard;select * from employee where idcard is not null;-- 不等于select * from employee where age != 30;-- 年龄在20到30之间select * from employee where age between 20 and 30;select * from employee where age &gt;= 20 and age &lt;= 30;-- 下面语句不报错，但查不到任何信息select * from employee where age between 30 and 20;-- 性别为女且年龄小于30select * from employee where age &lt; 30 and gender = &#x27;女&#x27;;-- 年龄等于25或30或35select * from employee where age = 25 or age = 30 or age = 35;select * from employee where age in (25, 30, 35);-- 姓名为两个字select * from employee where name like &#x27;__&#x27;;-- 身份证最后为Xselect * from employee where idcard like &#x27;%X&#x27;; 3）聚合查询（聚合函数）常见聚合函数： 函数 功能 count 统计数量 max 最大值 min 最小值 avg 平均值 sum 求和 语法：SELECT 聚合函数(字段列表) FROM 表名;例：SELECT count(id) from employee where workaddress = &quot;广东省&quot;; 4）分组查询语法：SELECT 字段列表 FROM 表名 [ WHERE 条件 ] GROUP BY 分组字段名 [ HAVING 分组后的过滤条件 ]; where 和 having 的区别： 执行时机不同：where是分组之前进行过滤，不满足where条件不参与分组；having是分组后对结果进行过滤。 判断条件不同：where不能对聚合函数进行判断，而having可以。 例子： 12345678910-- 根据性别分组，统计男性和女性数量（只显示分组数量，不显示哪个是男哪个是女）select count(*) from employee group by gender;-- 根据性别分组，统计男性和女性数量select gender, count(*) from employee group by gender;-- 根据性别分组，统计男性和女性的平均年龄select gender, avg(age) from employee group by gender;-- 年龄小于45，并根据工作地址分组select workaddress, count(*) from employee where age &lt; 45 group by workaddress;-- 年龄小于45，并根据工作地址分组，获取员工数量大于等于3的工作地址select workaddress, count(*) address_count from employee where age &lt; 45 group by workaddress having address_count &gt;= 3; 注意事项 执行顺序：where &gt; 聚合函数 &gt; having 分组之后，查询的字段一般为聚合函数和分组字段，查询其他字段无任何意义 5）排序查询语法：SELECT 字段列表 FROM 表名 ORDER BY 字段1 排序方式1, 字段2 排序方式2; 排序方式： ASC: 升序（默认） DESC: 降序 例子： 12345-- 根据年龄升序排序SELECT * FROM employee ORDER BY age ASC;SELECT * FROM employee ORDER BY age;-- 两字段排序，根据年龄升序排序，入职时间降序排序SELECT * FROM employee ORDER BY age ASC, entrydate DESC; 注意事项 如果是多字段排序，当第一个字段值相同时，才会根据第二个字段进行排序 6）分页查询语法：SELECT 字段列表 FROM 表名 LIMIT 起始索引, 查询记录数; 例子： 1234-- 查询第一页数据，展示10条SELECT * FROM employee LIMIT 0, 10;-- 查询第二页SELECT * FROM employee LIMIT 10, 10; 注意事项 起始索引从0开始，起始索引 &#x3D; （查询页码 - 1） * 每页显示记录数 分页查询是数据库的方言，不同数据库有不同实现，MySQL是LIMIT 如果查询的是第一页数据，起始索引可以省略，直接简写 LIMIT 10 7）DQL执行顺序 FROM -&gt; WHERE -&gt; GROUP BY -&gt; SELECT -&gt; ORDER BY -&gt; LIMIT ①先确定查询的是那些表 from ②根据查询条件来进行查询 where ③根据条件查询完的结果进行分组查询，分组查询完以后再通过having条件筛选 group by having ④将结果最终需要展示的列进行筛选 select ⑤将结果排序 order by ⑥最后确认显示数据的条数 limit 4.DCL1）管理用户查询用户： 12USER mysql;SELECT * FROM user; 创建用户:CREATE USER &#39;用户名&#39;@&#39;主机名&#39; IDENTIFIED BY &#39;密码&#39;; 修改用户密码：ALTER USER &#39;用户名&#39;@&#39;主机名&#39; IDENTIFIED WITH mysql_native_password BY &#39;新密码&#39;; 删除用户：DROP USER &#39;用户名&#39;@&#39;主机名&#39;; 例子： 123456789-- 创建用户test，只能在当前主机localhost访问create user &#x27;test&#x27;@&#x27;localhost&#x27; identified by &#x27;123456&#x27;;-- 创建用户test，能在任意主机访问create user &#x27;test&#x27;@&#x27;%&#x27; identified by &#x27;123456&#x27;;create user &#x27;test&#x27; identified by &#x27;123456&#x27;;-- 修改密码alter user &#x27;test&#x27;@&#x27;localhost&#x27; identified with mysql_native_password by &#x27;1234&#x27;;-- 删除用户drop user &#x27;test&#x27;@&#x27;localhost&#x27;; 注意事项 主机名可以使用 % 通配 2）权限控制常用权限： 权限 说明 ALL, ALL PRIVILEGES 所有权限 SELECT 查询数据 INSERT 插入数据 UPDATE 修改数据 DELETE 删除数据 ALTER 修改表 DROP 删除数据库&#x2F;表&#x2F;视图 CREATE 创建数据库&#x2F;表 更多权限请看权限一览表 查询权限：SHOW GRANTS FOR &#39;用户名&#39;@&#39;主机名&#39;; 授予权限：GRANT 权限列表 ON 数据库名.表名 TO &#39;用户名&#39;@&#39;主机名&#39;; 撤销权限：REVOKE 权限列表 ON 数据库名.表名 FROM &#39;用户名&#39;@&#39;主机名&#39;; 注意事项 多个权限用逗号分隔 授权时，数据库名和表名可以用 * 进行通配，代表所有 5.函数 字符串函数 数值函数 日期函数 流程函数 1）字符串函数常用函数： 函数 功能 CONCAT(s1, s2, …, sn) 字符串拼接，将s1, s2, …, sn拼接成一个字符串 LOWER(str) 将字符串全部转为小写 UPPER(str) 将字符串全部转为大写 LPAD(str, n, pad) 左填充，用字符串pad对str的左边进行填充，达到n个字符串长度 RPAD(str, n, pad) 右填充，用字符串pad对str的右边进行填充，达到n个字符串长度 TRIM(str) 去掉字符串头部和尾部的空格 SUBSTRING(str, start, len) 返回从字符串str从start位置起的len个长度的字符串 使用示例： 1234567891011121314-- 拼接SELECT CONCAT(&#x27;Hello&#x27;, &#x27;World&#x27;);-- 小写SELECT LOWER(&#x27;Hello&#x27;);-- 大写SELECT UPPER(&#x27;Hello&#x27;);-- 左填充SELECT LPAD(&#x27;01&#x27;, 5, &#x27;-&#x27;);-- 右填充SELECT RPAD(&#x27;01&#x27;, 5, &#x27;-&#x27;);-- 去除空格SELECT TRIM(&#x27; Hello World &#x27;);-- 切片（起始索引为1）SELECT SUBSTRING(&#x27;Hello World&#x27;, 1, 5); 2）数值函数常见函数： 函数 功能 CEIL(x) 向上取整 FLOOR(x) 向下取整 MOD(x, y) 返回x&#x2F;y的模 RAND() 返回0~1内的随机数 ROUND(x, y) 求参数x的四舍五入值，保留y位小数 3）日期函数常用函数： 函数 功能 CURDATE() 返回当前日期 CURTIME() 返回当前时间 NOW() 返回当前日期和时间 YEAR(date) 获取指定date的年份 MONTH(date) 获取指定date的月份 DAY(date) 获取指定date的日期 DATE_ADD(date, INTERVAL expr type) 返回一个日期&#x2F;时间值加上一个时间间隔expr后的时间值 DATEDIFF(date1, date2) 返回起始时间date1和结束时间date2之间的天数 例子： 123-- DATE_ADDSELECT DATE_ADD(NOW(), INTERVAL 70 YEAR);-- 这样求出来就是now的日期+时间，往后推70年的结果，往前推就是-70 4）流程函数常用函数： 函数 功能 IF(value, t, f) 如果value为true，则返回t，否则返回f IFNULL(value1, value2) 如果value1不为空，返回value1，否则返回value2 CASE WHEN [ val1 ] THEN [ res1 ] … ELSE [ default ] END 如果val1为true，返回res1，… 否则返回default默认值 CASE [ expr ] WHEN [ val1 ] THEN [ res1 ] … ELSE [ default ] END 如果expr的值等于val1，返回res1，… 否则返回default默认值 例子： 12345678select name, (case when age &gt; 30 then &#x27;中年&#x27; else &#x27;青年&#x27; end)from employee;select name, (case workaddress when &#x27;北京市&#x27; then &#x27;一线城市&#x27; when &#x27;上海市&#x27; then &#x27;一线城市&#x27; else &#x27;二线城市&#x27; end) as &#x27;工作地址&#x27;from employee; 6.约束分类： 约束 描述 关键字 非空约束 限制该字段的数据不能为null NOT NULL 唯一约束 保证该字段的所有数据都是唯一、不重复的 UNIQUE 主键约束 主键是一行数据的唯一标识，要求非空且唯一 PRIMARY KEY 默认约束 保存数据时，如果未指定该字段的值，则采用默认值 DEFAULT 检查约束（8.0.1版本后） 保证字段值满足某一个条件 CHECK 外键约束 用来让两张图的数据之间建立连接，保证数据的一致性和完整性 FOREIGN KEY 约束是作用于表中字段上的，可以再创建表&#x2F;修改表的时候添加约束。 1）常用约束 约束条件 关键字 主键 PRIMARY KEY 自动增长 AUTO_INCREMENT 不为空 NOT NULL 唯一 UNIQUE 逻辑条件 CHECK 默认值 DEFAULT 例子： 1234567create table user( id int primary key auto_increment, name varchar(10) not null unique, age int check(age &gt; 0 and age &lt; 120), status char(1) default &#x27;1&#x27;, gender char(1)); 2）外键约束添加外键： 123456789CREATE TABLE 表名( 字段名 字段类型, ... [CONSTRAINT] [外键名称] FOREIGN KEY(外键字段名) REFERENCES 主表(主表列名));ALTER TABLE 表名 ADD CONSTRAINT 外键名称 FOREIGN KEY (外键字段名) REFERENCES 主表(主表列名);-- 例子alter table emp add constraint fk_emp_dept_id foreign key(dept_id) references dept(id); 删除外键：ALTER TABLE 表名 DROP FOREIGN KEY 外键名; 删除&#x2F;更新行为 行为 说明 NO ACTION 当在父表中删除&#x2F;更新对应记录时，首先检查该记录是否有对应外键，如果有则不允许删除&#x2F;更新（与RESTRICT一致） RESTRICT 当在父表中删除&#x2F;更新对应记录时，首先检查该记录是否有对应外键，如果有则不允许删除&#x2F;更新（与NO ACTION一致） CASCADE 当在父表中删除&#x2F;更新对应记录时，首先检查该记录是否有对应外键，如果有则也删除&#x2F;更新外键在子表中的记录 SET NULL 当在父表中删除&#x2F;更新对应记录时，首先检查该记录是否有对应外键，如果有则设置子表中该外键值为null（要求该外键允许为null） SET DEFAULT 父表有变更时，子表将外键设为一个默认值（Innodb不支持） 更改删除&#x2F;更新行为：ALTER TABLE 表名 ADD CONSTRAINT 外键名称 FOREIGN KEY (外键字段) REFERENCES 主表名(主表字段名) ON UPDATE 行为 ON DELETE 行为; 7.多表查询1）多表关系 一对多（多对一） 多对多 一对一 一对多 案例：部门与员工关系：一个部门对应多个员工，一个员工对应一个部门实现：在多的一方建立外键，指向一的一方的主键 多对多 案例：学生与课程关系：一个学生可以选多门课程，一门课程也可以供多个学生选修实现：建立第三张中间表，中间表至少包含两个外键，分别关联两方主键 一对一 案例：用户与用户详情关系：一对一关系，多用于单表拆分，将一张表的基础字段放在一张表中，其他详情字段放在另一张表中，以提升操作效率实现：在任意一方加入外键，关联另外一方的主键，并且设置外键为唯一的（UNIQUE） 2）查询合并查询（笛卡尔积，会展示所有组合结果）：select * from employee, dept; 笛卡尔积：两个集合A集合和B集合的所有组合情况（在多表查询时，需要消除无效的笛卡尔积） 消除无效笛卡尔积：select * from employee, dept where employee.dept = dept.id; 3）内连接查询内连接查询的是两张表交集的部分 隐式内连接：SELECT 字段列表 FROM 表1, 表2 WHERE 条件 ...; 显式内连接：SELECT 字段列表 FROM 表1 [ INNER ] JOIN 表2 ON 连接条件 ...; 显式性能比隐式高 例子： 12345-- 查询员工姓名，及关联的部门的名称-- 隐式select e.name, d.name from employee as e, dept as d where e.dept = d.id;-- 显式select e.name, d.name from employee as e inner join dept as d on e.dept = d.id; 4）外连接查询左外连接：查询左表所有数据，以及两张表交集部分数据SELECT 字段列表 FROM 表1 LEFT [ OUTER ] JOIN 表2 ON 条件 ...;相当于查询表1的所有数据，包含表1和表2交集部分数据 右外连接：查询右表所有数据，以及两张表交集部分数据SELECT 字段列表 FROM 表1 RIGHT [ OUTER ] JOIN 表2 ON 条件 ...; 例子： 12345-- 左select e.*, d.name from employee as e left outer join dept as d on e.dept = d.id;select d.name, e.* from dept d left outer join emp e on e.dept = d.id; -- 这条语句与下面的语句效果一样-- 右select d.name, e.* from employee as e right outer join dept as d on e.dept = d.id; 左连接可以查询到没有dept的employee，右连接可以查询到没有employee的dept 5）自连接查询当前表与自身的连接查询，自连接必须使用表别名 语法：SELECT 字段列表 FROM 表A 别名A JOIN 表A 别名B ON 条件 ...; 自连接查询，可以是内连接查询，也可以是外连接查询 例子： 1234-- 查询员工及其所属领导的名字select a.name, b.name from employee a, employee b where a.manager = b.id;-- 没有领导的也查询出来select a.name, b.name from employee a left join employee b on a.manager = b.id; 6）联合查询 union, union all把多次查询的结果合并，形成一个新的查询集 语法： 123SELECT 字段列表 FROM 表A ...UNION [ALL]SELECT 字段列表 FROM 表B ... 注意事项 UNION ALL 会有重复结果，UNION 不会 联合查询比使用or效率高，不会使索引失效 7）子查询SQL语句中嵌套SELECT语句，称谓嵌套查询，又称子查询。SELECT * FROM t1 WHERE column1 = ( SELECT column1 FROM t2);子查询外部的语句可以是 INSERT &#x2F; UPDATE &#x2F; DELETE &#x2F; SELECT 的任何一个 根据子查询结果可以分为： 标量子查询（子查询结果为单个值） 列子查询（子查询结果为一列） 行子查询（子查询结果为一行） 表子查询（子查询结果为多行多列） 根据子查询位置可分为： WHERE 之后 FROM 之后 SELECT 之后 ①标量子查询子查询返回的结果是单个值（数字、字符串、日期等）。常用操作符：- &lt; &gt; &gt; &gt;&#x3D; &lt; &lt;&#x3D; 例子： 123456789-- 查询销售部所有员工select id from dept where name = &#x27;销售部&#x27;;-- 根据销售部部门ID，查询员工信息select * from employee where dept = 4;-- 合并（子查询）select * from employee where dept = (select id from dept where name = &#x27;销售部&#x27;);-- 查询xxx入职之后的员工信息select * from employee where entrydate &gt; (select entrydate from employee where name = &#x27;xxx&#x27;); ②列子查询返回的结果是一列（可以是多行）。 常用操作符： 操作符 描述 IN 在指定的集合范围内，多选一 NOT IN 不在指定的集合范围内 ANY 子查询返回列表中，有任意一个满足即可 SOME 与ANY等同，使用SOME的地方都可以使用ANY ALL 子查询返回列表的所有值都必须满足 例子： 123456-- 查询销售部和市场部的所有员工信息select * from employee where dept in (select id from dept where name = &#x27;销售部&#x27; or name = &#x27;市场部&#x27;);-- 查询比财务部所有人工资都高的员工信息select * from employee where salary &gt; all(select salary from employee where dept = (select id from dept where name = &#x27;财务部&#x27;));-- 查询比研发部任意一人工资高的员工信息select * from employee where salary &gt; any (select salary from employee where dept = (select id from dept where name = &#x27;研发部&#x27;)); ③行子查询返回的结果是一行（可以是多列）。常用操作符：&#x3D;, &lt;, &gt;, IN, NOT IN 例子： 123-- 查询与xxx的薪资及直属领导相同的员工信息select * from employee where (salary, manager) = (12500, 1);select * from employee where (salary, manager) = (select salary, manager from employee where name = &#x27;xxx&#x27;); ④表子查询返回的结果是多行多列常用操作符：IN 例子： 1234-- 查询与xxx1，xxx2的职位和薪资相同的员工select * from employee where (job, salary) in (select job, salary from employee where name = &#x27;xxx1&#x27; or name = &#x27;xxx2&#x27;);-- 查询入职日期是2006-01-01之后的员工，及其部门信息select e.*, d.* from (select * from employee where entrydate &gt; &#x27;2006-01-01&#x27;) as e left join dept as d on e.dept = d.id; 二、数据类型1）整型 类型名称 取值范围 大小 TINYINT -128〜127 1个字节 SMALLINT -32768〜32767 2个宇节 MEDIUMINT -8388608〜8388607 3个字节 INT (INTEGHR) -2147483648〜2147483647 4个字节 BIGINT -9223372036854775808〜9223372036854775807 8个字节 无符号在数据类型后加 unsigned 关键字。 2）浮点型 类型名称 说明 存储需求 FLOAT 单精度浮点数 4 个字节 DOUBLE 双精度浮点数 8 个字节 DECIMAL (M, D)，DEC 压缩的“严格”定点数 M+2 个字节 3）日期和时间 类型名称 日期格式 日期范围 存储需求 YEAR YYYY 1901 ~ 2155 1 个字节 TIME HH:MM:SS -838:59:59 ~ 838:59:59 3 个字节 DATE YYYY-MM-DD 1000-01-01 ~ 9999-12-3 3 个字节 DATETIME YYYY-MM-DD HH:MM:SS 1000-01-01 00:00:00 ~ 9999-12-31 23:59:59 8 个字节 TIMESTAMP YYYY-MM-DD HH:MM:SS 1980-01-01 00:00:01 UTC ~ 2040-01-19 03:14:07 UTC 4 个字节 4）字符串 类型名称 说明 存储需求 CHAR(M) 固定长度非二进制字符串 M 字节，1&lt;&#x3D;M&lt;&#x3D;255 VARCHAR(M) 变长非二进制字符串 L+1字节，在此，L&lt; &#x3D; M和 1&lt;&#x3D;M&lt;&#x3D;255 TINYTEXT 非常小的非二进制字符串 L+1字节，在此，L&lt;2^8 TEXT 小的非二进制字符串 L+2字节，在此，L&lt;2^16 MEDIUMTEXT 中等大小的非二进制字符串 L+3字节，在此，L&lt;2^24 LONGTEXT 大的非二进制字符串 L+4字节，在此，L&lt;2^32 ENUM 枚举类型，只能有一个枚举字符串值 1或2个字节，取决于枚举值的数目 (最大值为65535) SET 一个设置，字符串对象可以有零个或 多个SET成员 1、2、3、4或8个字节，取决于集合 成员的数量（最多64个成员） 5）二进制类型 类型名称 说明 存储需求 BIT(M) 位字段类型 大约 (M+7)&#x2F;8 字节 BINARY(M) 固定长度二进制字符串 M 字节 VARBINARY (M) 可变长度二进制字符串 M+1 字节 TINYBLOB (M) 非常小的BLOB L+1 字节，在此，L&lt;2^8 BLOB (M) 小 BLOB L+2 字节，在此，L&lt;2^16 MEDIUMBLOB (M) 中等大小的BLOB L+3 字节，在此，L&lt;2^24 LONGBLOB (M) 非常大的BLOB L+4 字节，在此，L&lt;2^32 三、权限一览表 具体权限的作用详见官方文档 GRANT 和 REVOKE 允许的静态权限 Privilege Grant Table Column Context ALL [PRIVILEGES] Synonym for “all privileges” Server administration ALTER Alter_priv Tables ALTER ROUTINE Alter_routine_priv Stored routines CREATE Create_priv Databases, tables, or indexes CREATE ROLE Create_role_priv Server administration CREATE ROUTINE Create_routine_priv Stored routines CREATE TABLESPACE Create_tablespace_priv Server administration CREATE TEMPORARY TABLES Create_tmp_table_priv Tables CREATE USER Create_user_priv Server administration CREATE VIEW Create_view_priv Views DELETE Delete_priv Tables DROP Drop_priv Databases, tables, or views DROP ROLE Drop_role_priv Server administration EVENT Event_priv Databases EXECUTE Execute_priv Stored routines FILE File_priv File access on server host GRANT OPTION Grant_priv Databases, tables, or stored routines INDEX Index_priv Tables INSERT Insert_priv Tables or columns LOCK TABLES Lock_tables_priv Databases PROCESS Process_priv Server administration PROXY See proxies_priv table Server administration REFERENCES References_priv Databases or tables RELOAD Reload_priv Server administration REPLICATION CLIENT Repl_client_priv Server administration REPLICATION SLAVE Repl_slave_priv Server administration SELECT Select_priv Tables or columns SHOW DATABASES Show_db_priv Server administration SHOW VIEW Show_view_priv Views SHUTDOWN Shutdown_priv Server administration SUPER Super_priv Server administration TRIGGER Trigger_priv Tables UPDATE Update_priv Tables or columns USAGE Synonym for “no privileges” Server administration GRANT 和 REVOKE 允许的动态权限 Privilege Context APPLICATION_PASSWORD_ADMIN Dual password administration AUDIT_ABORT_EXEMPT Allow queries blocked by audit log filter AUDIT_ADMIN Audit log administration AUTHENTICATION_POLICY_ADMIN Authentication administration BACKUP_ADMIN Backup administration BINLOG_ADMIN Backup and Replication administration BINLOG_ENCRYPTION_ADMIN Backup and Replication administration CLONE_ADMIN Clone administration CONNECTION_ADMIN Server administration ENCRYPTION_KEY_ADMIN Server administration FIREWALL_ADMIN Firewall administration FIREWALL_EXEMPT Firewall administration FIREWALL_USER Firewall administration FLUSH_OPTIMIZER_COSTS Server administration FLUSH_STATUS Server administration FLUSH_TABLES Server administration FLUSH_USER_RESOURCES Server administration GROUP_REPLICATION_ADMIN Replication administration GROUP_REPLICATION_STREAM Replication administration INNODB_REDO_LOG_ARCHIVE Redo log archiving administration NDB_STORED_USER NDB Cluster PASSWORDLESS_USER_ADMIN Authentication administration PERSIST_RO_VARIABLES_ADMIN Server administration REPLICATION_APPLIER PRIVILEGE_CHECKS_USER for a replication channel REPLICATION_SLAVE_ADMIN Replication administration RESOURCE_GROUP_ADMIN Resource group administration RESOURCE_GROUP_USER Resource group administration ROLE_ADMIN Server administration SESSION_VARIABLES_ADMIN Server administration SET_USER_ID Server administration SHOW_ROUTINE Server administration SYSTEM_USER Server administration SYSTEM_VARIABLES_ADMIN Server administration TABLE_ENCRYPTION_ADMIN Server administration VERSION_TOKEN_ADMIN Server administration XA_RECOVER_ADMIN Server administration 四、test","categories":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"}]},{"title":"mysql深入","slug":"mysql深入","date":"2022-04-04T07:29:48.000Z","updated":"2022-06-23T10:31:00.973Z","comments":true,"path":"2022/04/04/mysql深入/","link":"","permalink":"http://example.com/2022/04/04/mysql%E6%B7%B1%E5%85%A5/","excerpt":"一些Mysql的深入0.0","text":"一些Mysql的深入0.0 一、事务事务是一组操作的集合，事务会把所有操作作为一个整体一起向系统提交或撤销操作请求，即这些操作要么同时成功，要么同时失败。 基本操作： 1234567891011121314151617181920212223-- 1. 查询张三账户余额select * from account where name = &#x27;张三&#x27;;-- 2. 将张三账户余额-1000update account set money = money - 1000 where name = &#x27;张三&#x27;;-- 此语句出错后张三钱减少但是李四钱没有增加模拟sql语句错误-- 3. 将李四账户余额+1000update account set money = money + 1000 where name = &#x27;李四&#x27;;-- 查看事务提交方式SELECT @@AUTOCOMMIT;-- 设置事务提交方式，1为自动提交，0为手动提交，该设置只对当前会话有效SET @@AUTOCOMMIT = 0;-- 提交事务COMMIT;-- 回滚事务ROLLBACK;-- 设置手动提交后上面代码改为：select * from account where name = &#x27;张三&#x27;;update account set money = money - 1000 where name = &#x27;张三&#x27;;update account set money = money + 1000 where name = &#x27;李四&#x27;;commit; 操作方式二： 开启事务：START TRANSACTION 或 BEGIN TRANSACTION;提交事务：COMMIT;回滚事务：ROLLBACK; 操作实例： 12345start transaction;select * from account where name = &#x27;张三&#x27;;update account set money = money - 1000 where name = &#x27;张三&#x27;;update account set money = money + 1000 where name = &#x27;李四&#x27;;commit; 1.四大特性ACID 原子性(Atomicity)：事务是不可分割的最小操作但愿，要么全部成功，要么全部失败 一致性(Consistency)：事务完成时，必须使所有数据都保持一致状态 隔离性(Isolation)：数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行 持久性(Durability)：事务一旦提交或回滚，它对数据库中的数据的改变就是永久的 2.并发事务 问题 描述 脏读 一个事务读到另一个事务还没提交的数据 不可重复读 一个事务先后读取同一条记录，但两次读取的数据不同 幻读 一个事务按照条件查询数据时，没有对应的数据行，但是再插入数据时，又发现这行数据已经存在 ①脏读（Dirty read）： ​ 数据库中A&#x3D;200，事务1中修改了A&#x3D;100，但是这时候事务1还没有commit，而此时事务2要读取A的值，事务2读取A&#x3D;100，这是事务A修改了但是还没有commit的数据，这种数据就称为’脏数据’，此时就发生了脏读。 ②不可重复读（Unrepeatable read） ​ 数据库中id&#x3D;1的数据有一个值为A&#x3D;200，事务A第一次selectid=1的数据查询出A&#x3D;200，此时事务2修改updateid=1的数据使A&#x3D;100并且commit了，此时数据库中的id=1的数据A&#x3D;100，然后事务1第二次读取selectid=1的数据查询出A&#x3D;100和第一次查询出的A&#x3D;200不一致，此时就发生了不可重复读现象。 ③幻读（Phantom read） ​ 幻读与不可重复读类似，事务1第一步select查询id&#x3D;1的数据，此时数据库为空没有查到，刚好此时事务2向数据库中插入了id&#x3D;1的数据，此时事务1第二步要插入id&#x3D;1的数据的时候就会报错，当事务1再次查询数据库的时候发现id为1的数据还是没有（因为已经解决了不可重复读的问题，两次查询的结果一致），这时候就发生了’幻读’。因为在插入数据的时候会因为事务2插入的数据失败，事务1会发现已经有了插入的数据，但是查询的时候又看见，就像幻觉一样Phantom。 ④丢失更新（Lost to modify） 事务1想要修改A&#x3D;20并且读取到了A&#x3D;20数据（此时事务2页读取到了A&#x3D;20），使A&#x3D;A-1，修改的结果为19；事务2读取到A&#x3D;20数据后也要进行修改，使A&#x3D;A-3，得到的结果为17；最终结果为17，看起来就是事务1的结果丢失了。 注： 不可重复读和幻读类似，不可重复读是发生在事务A因为事务B的修改导致两次read的数据不一致，幻读是因为事务A因为事务B的插入数据导致自身插入数据失败，但是两次查询（特别是第二次）发现没有数据（解决了不可重复度的基础上），好像出现了幻觉。 这三个问题的详细演示：https://www.bilibili.com/video/BV1Kr4y1i7ru?p=55cd 丢失更新相关博客：https://blog.csdn.net/sun8112133/article/details/89853755 并发事务隔离级别： 隔离级别 脏读 不可重复读 幻读 Read uncommitted √ √ √ Read committed × √ √ Repeatable Read(默认) × × √ Serializable × × × √表示在当前隔离级别下该问题会出现 Serializable 性能最低；Read uncommitted 性能最高，数据安全性最差 查看事务隔离级别：SELECT @@TRANSACTION_ISOLATION;设置事务隔离级别：SET [ SESSION | GLOBAL ] TRANSACTION ISOLATION LEVEL &#123;READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE &#125;;SESSION 是会话级别，表示只针对当前会话有效，GLOBAL 表示对所有会话有效 二、存储引擎1. MySQL体系结构 Mysql结构（4层）： ①连接层 ​ 处理来自各个客户端的连接（验证密码等），授权认证及相关安全信息 ②服务层 ​ 最核心的一层，mysql在这一层中完成各类服务，执行sql、sql分析和优化，过程函数都在这一层实行 ③引擎层 ​ mysql实现的是可插拔存储引擎，想用哪个插哪个，默认为InnoDB。同时索引(index)也在这一层，所以各个存储引擎实现索引的方式可能不一样。存储引擎是数据库存储数据、建立索引、更新&#x2F;查询等技术的实现方式，存储引擎是基于表的 ④存储层 ​ 主要是将存储的数据存入系统硬盘上，完成与存储引擎的交互 存储引擎就是存储数据、建立索引、更新&#x2F;查询数据等技术的实现方式。存储引擎是基于表而不是基于库的，所以存储引擎也可以被称为表引擎。默认存储引擎是InnoDB。 相关操作： 12345678-- 查询建表语句show create table account;-- 建表时指定存储引擎CREATE TABLE 表名( ...) ENGINE=INNODB;-- 查看当前数据库支持的存储引擎show engines; 2. 常见引擎1）InnoDBInnoDB 是一种兼顾高可靠性和高性能的通用存储引擎，在 MySQL 5.5 之后，InnoDB 是默认的 MySQL 引擎。 特点： DML 操作遵循 ACID 模型，支持事务 行级锁，提高并发访问性能 支持外键约束，保证数据的完整性和正确性 文件： xxx.ibd: xxx代表表名，InnoDB 引擎的每张表都会对应这样一个表空间文件，存储该表的表结构（frm、sdi）、数据和索引。 参数：innodb_file_per_table，决定多张表共享一个表空间还是每张表对应一个表空间 知识点： 查看 Mysql 变量：show variables like &#39;innodb_file_per_table&#39;; 从idb文件提取表结构数据：（在cmd运行）ibd2sdi xxx.ibd InnoDB 逻辑存储结构： 2）MyISAMMyISAM 是 MySQL 早期的默认存储引擎。 特点： 不支持事务，不支持外键 支持表锁，不支持行锁 访问速度快 文件： xxx.sdi: 存储表结构信息 xxx.MYD: 存储数据 xxx.MYI: 存储索引 3）MemoryMemory 引擎的表数据是存储在内存中的，受硬件问题、断电问题的影响，只能将这些表作为临时表或缓存使用。 特点： 存放在内存中，速度快 hash索引（默认） 文件： xxx.sdi: 存储表结构信息 3. 存储引擎特点比较 特点 InnoDB MyISAM Memory 存储限制 64TB 有 有 事务安全 支持 - - 锁机制 行锁 表锁 表锁 B+tree索引 支持 支持 支持 Hash索引 - - 支持 全文索引 支持（5.6版本之后） 支持 - 空间使用 高 低 N&#x2F;A 内存使用 高 低 中等 批量插入速度 低 高 高 支持外键 支持 - - 4. 存储引擎的选择在选择存储引擎时，应该根据应用系统的特点选择合适的存储引擎。对于复杂的应用系统，还可以根据实际情况选择多种存储引擎进行组合。 InnoDB: 如果应用对事物的完整性有比较高的要求，在并发条件下要求数据的一致性，数据操作除了插入和查询之外，还包含很多的更新、删除操作，则 InnoDB 是比较合适的选择 MyISAM: 如果应用是以读操作和插入操作为主，只有很少的更新和删除操作，并且对事务的完整性、并发性要求不高，那这个存储引擎是非常合适的。 Memory: 将所有数据保存在内存中，访问速度快，通常用于临时表及缓存。Memory 的缺陷是对表的大小有限制，太大的表无法缓存在内存中，而且无法保障数据的安全性 电商中的足迹和评论适合使用 MyISAM 引擎，缓存适合使用 Memory 引擎。 三、 索引1. 索引结构 索引结构 描述 B+Tree 最常见的索引类型，大部分引擎都支持B+树索引 Hash 底层数据结构是用哈希表实现，只有精确匹配索引列的查询才有效，不支持范围查询 R-Tree(空间索引) 空间索引是 MyISAM 引擎的一个特殊索引类型，主要用于地理空间数据类型，通常使用较少 Full-Text(全文索引) 是一种通过建立倒排索引，快速匹配文档的方式，类似于 Lucene, Solr, ES 索引 InnoDB MyISAM Memory B+Tree索引 支持 支持 支持 Hash索引 不支持 不支持 支持 R-Tree索引 不支持 支持 不支持 Full-text 5.6版本后支持 支持 不支持 1）二叉搜索树 二叉树的缺点可以用红黑树来解决：红黑树也存在大数据量情况下，层级较深，检索速度慢的问题。 2）B TreeB Tree相较于二叉搜索树维护了自平衡（左右高度差距不会过大）并且增加了一个节点的字节点数量，eg： 如下图degree&#x3D;5（子节点个数），一共可存4个key（值），x&lt;20，20&lt;&#x3D;x&lt;30，…，…，89&#x3D;&lt;x 为了解决上述问题，可以使用 B-Tree 结构： ​ B-Tree (多路平衡查找树) 以一棵最大度数（max-degree，指一个节点的子节点个数）为5（5阶）的 b-tree 为例（每个节点最多存储4个key，5个指针） B-Tree 的数据插入过程动画参照：https://www.bilibili.com/video/BV1Kr4y1i7ru?p=68演示地址：https://www.cs.usfca.edu/~galles/visualization/BTree.html 3）B+TreeB+ Tree 相较于B Tree就是将数据全部存储在了叶子节点，如下图左下角x&lt;16，16&lt;&#x3D;x&lt;29，29&lt;&#x3D;x 这样key&#x3D;16的数据就存储在了第二个叶子节点 结构图： 演示地址：https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html 与 B Tree 的区别： 所有的数据都会出现在叶子节点 叶子节点形成一个单向链表 4）InooDB的改进B+ TreeMySQL 索引数据结构对经典的 B+Tree 进行了优化。在原 B+Tree 的基础上，增加一个指向相邻叶子节点的链表指针，就形成了带有顺序指针的 B+Tree，提高区间访问的性能。 ​ mysql中的B+树对经典的B+树做了优化，1.在叶子相邻叶子节点间添加了一个向前的指针使其成为了双向链表（首尾也是双向指针），这是便于范围搜索和排序 5）Hash索引哈希索引就是采用一定的hash算法，将键值换算成新的hash值，映射到对应的槽位上，然后存储在hash表中。如果两个（或多个）键值，映射到一个相同的槽位上，他们就产生了hash冲突（也称为hash碰撞），可以通过链表来解决。 特点： Hash索引只能用于对等比较（&#x3D;、in），不支持范围查询（betwwn、&gt;、&lt;、…） 无法利用索引完成排序操作 查询效率高，通常只需要一次检索就可以了，效率通常要高于 B+Tree 索引 存储引擎支持： Memory InnoDB: 具有自适应hash功能，hash索引是存储引擎根据 B+Tree 索引在指定条件下自动构建的 6）面试题 为什么 InnoDB 存储引擎选择使用 B+Tree 索引结构？ 相对于二叉树，层级更少，搜索效率高 对于 B-Tree，无论是叶子节点还是非叶子节点，都会保存数据，这样导致一页中存储的键值减少，指针也跟着减少，要同样保存大量数据，只能增加树的高度，导致性能降低 相对于 Hash 索引，B+Tree 支持范围匹配及排序操作 mine： 二叉搜索树在顺序插入的时候会形成一个链表，查询的过程就变成线性的一条一条查询；如果数据量较大，层级变深，搜索效率变慢 B Tree 无论节点还是非叶子节点都会保存数据，而每一个节点都是存储在一页中的，如果非叶子节点要保存value，那么这一页存储的keys就会减少，指针也变少了，要存储更多的数据，只能增加树的高度，导致性能降低了 同时因为改进后的B+树在叶子节点间添加了双向指针，便于范围匹配和排序，而Hash索引不能 2. 索引分类 分类 含义 特点 关键字 主键索引 针对于表中主键创建的索引 默认自动创建，只能有一个 PRIMARY 唯一索引 避免同一个表中某数据列中的值重复 可以有多个 UNIQUE 常规索引 快速定位特定数据 可以有多个 全文索引 全文索引查找的是文本中的关键词，而不是比较索引中的值 可以有多个 FULLTEXT 在 InnoDB 存储引擎中，根据索引的存储形式，又可以分为以下两种： 分类 含义 特点 聚集索引(Clustered Index) 将数据存储与索引放一块，索引结构的叶子节点保存了行数据 必须有，而且只有一个 二级索引(Secondary Index) 将数据与索引分开存储，索引结构的叶子节点关联的是对应的主键 可以存在多个 演示图： 聚集索引选取规则： 如果存在主键，主键索引就是聚集索引 如果不存在主键，将使用第一个唯一(UNIQUE)列作为聚集索引 如果表没有主键或没有合适的唯一索引，则 InnoDB 会自动生成一个 rowid 作为隐藏的聚集索引 思考题 1. 以下 SQL 语句，哪个执行效率高？为什么？ 123select * from user where id = 10;select * from user where name = &#x27;Arm&#x27;;-- 备注：id为主键，name字段创建的有索引 答：第一条语句，因为第二条需要回表查询，相当于两个步骤。 2. InnoDB 主键索引的 B+Tree 高度为多少？ 答：假设一行数据大小为1k，一页中可以存储16行这样的数据。InnoDB 的指针占用6个字节的空间，主键假设为bigint，占用字节数为8.可得公式：n * 8 + (n + 1) * 6 = 16 * 1024，其中 8 表示 bigint 占用的字节数，n 表示当前节点存储的key的数量，(n + 1) 表示指针数量（比key多一个）。算出n约为1170。 如果树的高度为2，那么他能存储的数据量大概为：1171 * 16 = 18736；如果树的高度为3，那么他能存储的数据量大概为：1171 * 1171 * 16 = 21939856。 另外，如果有成千上万的数据，那么就要考虑分表，涉及运维篇知识。 3. 索引语法创建索引：CREATE [ UNIQUE | FULLTEXT ] INDEX index_name ON table_name (index_col_name, ...);如果不加 CREATE 后面不加索引类型参数，则创建的是常规索引 查看索引：SHOW INDEX FROM table_name; 删除索引：DROP INDEX index_name ON table_name; 案例： 1234567891011-- name字段为姓名字段，该字段的值可能会重复，为该字段创建索引create index idx_user_name on tb_user(name);-- phone手机号字段的值非空，且唯一，为该字段创建唯一索引create unique index idx_user_phone on tb_user (phone);-- 为profession, age, status创建联合索引create index idx_user_pro_age_stat on tb_user(profession, age, status);-- 为email建立合适的索引来提升查询效率create index idx_user_email on tb_user(email);-- 删除索引drop index idx_user_email on tb_user; 4. sql性能分析①首先查看执行频次来分析当前数据库，是增删改语句执行的多，还是select语句执行的多 ②通过慢查询日志可以定位哪台主机通过哪个user执行了哪条sql语句，执行效率较低 ③慢查询日志只会记录超过设定时间的sql，如果要查看没有超过时限的sql则需要通过profiles来查询 ④explain会查看sql具体的执行信息 1）查看执行频次查看当前数据库的 INSERT, UPDATE, DELETE, SELECT 访问频次：全局：SHOW GLOBAL STATUS LIKE &#39;Com_______&#39;; 会话：SHOW SESSION STATUS LIKE &#39;Com_______&#39;; 例：show global status like &#39;Com_______&#39; 2）慢查询日志慢查询日志记录了所有执行时间超过指定参数（long_query_time，单位：秒，默认10秒）的所有SQL语句的日志。MySQL的慢查询日志默认没有开启，需要在MySQL的配置文件（&#x2F;etc&#x2F;my.cnf）中配置如下信息： #开启慢查询日志开关 slow_query_log=1 #设置慢查询日志的时间为2秒，SQL语句执行时间超过2秒，就会视为慢查询，记录慢查询日志： long_query_time=2 更改后重启MySQL服务，日志文件位置：&#x2F;var&#x2F;lib&#x2F;mysql&#x2F;localhost-slow.log systemctl restart mysqld 查看慢查询日志开关状态： show variables like &#39;slow_query_log&#39;; 3）profileshow profile 能在做SQL优化时帮我们了解时间都耗费在哪里。通过 have_profiling 参数，能看到当前 MySQL 是否支持 profile 操作： SELECT @@have_profiling; profiling 默认关闭，可查询其开启情况（0是关闭） select @@profiling; 可以通过set语句在session&#x2F;global级别开启 profiling： SET profiling = 1; 查看所有语句的耗时： show profiles; 查看指定query_id的SQL语句各个阶段的耗时： show profile for query query_id; 查看指定query_id的SQL语句CPU的使用情况 show profile cpu for query query_id; 4）explainEXPLAIN 或者 DESC 命令获取 MySQL 如何执行 SELECT 语句的信息，包括在 SELECT 语句执行过程中表如何连接和连接的顺序。语法： # 直接在select语句之前加上关键字 explain &#x2F; desc EXPLAIN SELECT 字段列表 FROM 表名 HWERE 条件; EXPLAIN 各字段含义： id*：select 查询的序列号，表示查询中执行 select 子句或者操作表的顺序（id相同，执行顺序从上到下；id不同，值越大越先执行） select_type： 表示 SELECT 的类型，常见取值有 SIMPLE（简单表，即不适用表连接或者子查询）、PRIMARY（主查询，即外层的查询）、UNION（UNION中的第二个或者后面的查询语句）、SUBQUERY（SELECT&#x2F;WHERE之后包含了子查询）等 type*： 表示连接类型，性能由好到差的连接类型为 NULL、system、const、eq_ref、ref、range、index、all 用主键索引或者唯一索引查询，const 用普通索引，ref select ‘A’，NULL possible_key*： 可能应用在这张表上的索引，一个或多个 Key*： 实际使用的索引，如果为 NULL，则没有使用索引 Key_len*： 表示索引中使用的字节数，该值为索引字段最大可能长度，并非实际使用长度，在不损失精确性的前提下，长度越短越好 rows： MySQL认为必须要执行的行数，在InnoDB引擎的表中，是一个估计值，可能并不总是准确的 filtered： 表示返回结果的行数占需读取行数的百分比，filtered的值越大越好 5. 使用规则1）最左前缀法则（联合索引）如果索引关联了多列（联合索引），要遵守最左前缀法则，最左前缀法则指的是查询从索引的最左列开始，并且不跳过索引中的列。如果跳跃某一列，索引将部分失效（后面的字段索引失效）。 联合索引中，出现范围查询（&lt;, &gt;），范围查询右侧的列索引失效。可以用&gt;&#x3D;或者&lt;&#x3D;来规避索引失效问题。 ​ 在这样一条联合索引中，索引的顺序分别是：profession（47），age（2），status（5）， profession列一定存在，但在where中的顺序不影响 这样两条sql都会走该联合索引，只是索引长度可能不一致，第一条会按顺序查询 pro，age，status三条索引（54） 下面一条没有status，只会顺序查询pro，age两条索引（49） 中间跳过某一列后，后面的索引就会失效 这样两条sql都会走联合查询，因为有pro在（最左边的列在）（where后and的顺序不重要） 但是只会查询pro索引，因为跳过了中间的age索引（没有），那么age后status索引也不会查询（47） 可以这样说：age单说是没有索引的，因为如果只根据age去查，没有pro的话，age的索引也不会用到 注：如果select字段中包含了该联合查询的字段而不需要回表查询也会使用联合查询 ​ 因为select字段在pro_age_sta的联合索引中都含有，而id则是联合索引的叶子节点值，所以通过索引能将这些值全部查询出来，这样就会使用索引，虽然不满足最左前缀原则，之前不使用是因为select * ，不能直接通过该联合索引获取所有值，需要回表查询 联合索引失效tips： 跳过联合索引中的某一列，该列右边的所有索引都会失效 若在索引上使用了&gt;，&lt; 等范围查询会让该索引右边的列索引失效（自身不会失效） 上面这条查询会查询pro，age，但是age使用了范围查询&gt;，所以age不会失效，status索引会失效（49） 解决办法：在业务允许的情况下，尽量使用&gt;&#x3D;和&lt;&#x3D; 这样查询就会查询pro，age，status三条索引 ​ 2）普通索引失效情况 在索引列上进行运算操作（如函数运算），索引将失效。 如：查询手机号后两位是15的用户 explain select * from tb_user where substring(phone, 10, 2) = &#39;15&#39;; 这样不会走phone索引，因为在phone索引上进行了函数运算 字符串类型字段使用时，不加引号，索引将失效。 如：explain select * from tb_user where phone = 17799990015;，此处phone的值没有加引号 虽然可以查询出来，但是并不会走phone的索引 模糊查询中，如果仅仅是尾部模糊匹配，索引不会是失效；如果是头部模糊匹配，索引失效。 如：explain select * from tb_user where profession like &#39;%工程&#39;; 前面有%会失效 ​ explain select * from tb_user where profession like &#39;工程%&#39;;后面有%不会失效 注：’_’ 和 ‘%’ 的情况是一样的 用 or 分割开的条件，如果 or 其中一个条件的列没有索引，那么涉及的索引都不会被用到。 如该条数据，可能会走主键索引，但是最后没走索引，因为age没有索引，解决办法就是为age添加上索引 如果 MySQL 评估使用索引比全表更慢，则不使用索引。 如：explain select * from tb_user where profession is null; pro字段只有少部分是null，所以会走索引 ​ explain select * from tb_user where profession is not null; pro字段大部分都不是null，这样还不如扫描all，所以不会走索引 3）SQL 提示​ 是优化数据库的一个重要手段，简单来说，就是在SQL语句中加入一些人为的提示来达到优化操作的目的： 如用户告诉mysql在有多个索引的情况下，选择哪个索引而不是让mysql的优化选择器自己选择 例如： 在可能多个索引的情况下： 使用哪个索引： explain select * from tb_user use index(idx_user_pro) where profession=&quot;软件工程&quot;; 不使用哪个索引：explain select * from tb_user ignore index(idx_user_pro) where profession=&quot;软件工程&quot;;必须使用哪个索引：explain select * from tb_user force index(idx_user_pro) where profession=&quot;软件工程&quot;; use 是建议，实际使用哪个索引 MySQL 还会自己权衡运行速度去更改，force就是无论如何都强制使用该索引。 4）覆盖索引&amp;回表查询 覆盖索引：根据索引可以查询出所有数据 查询的数据中id值在该联合索引（二级索引）的叶子节点，所以只需要查一次联合索引就可以查询出所有值而不需要回表查询 回表查询：二级索引不能查询出所有值，需要通过查询出的主键id来查询聚集索引获取值 虽然使用了索引查询，但是因为查询的字段中的gender和email是无法通过该联合索引查询出来的，所以在通过二级索引获取了id，profession，age后，还需要通过id值查询聚集索引来获取剩下的gender和email，这就进行了回表查询 5）前缀索引当字段类型为字符串（varchar, text等）时，如果在这些字段上建立索引会导致建立的索引较大，查询时，也会浪费大量的磁盘IO，影响 查询效率，此时可以只降字符串的一部分前缀，建立索引，这样可以大大节约索引空间，从而提高索引效率。 比如要在email上建立索引，我们可以截取email的前几个char作为索引，这样就可以减小索引长度，可以根据一个比值选择性k来判断取值的合理性：不同的subString&#x2F;all，eg：当我们截取email字段前5个的时候，10个email中8个的前5个char都不一样，只有两个的前5个char是一样的，这时候k&#x3D;8&#x2F;10&#x3D;0.8，我就可以在k和长度之间做取舍 求选择性公式： 12select count(distinct email) / count(*) from tb_user;select count(distinct substring(email, 1, 5)) / count(*) from tb_user; 语法：create index idx_xxxx on table_name(columnn(n)); show index 里面的sub_part可以看到接取的长度 6）单列索引&amp;联合索引单列索引：即一个索引只包含单个列联合索引：即一个索引包含了多个列在业务场景中，如果存在多个查询条件，考虑针对于查询字段建立索引时，建议建立联合索引，而非单列索引。 单列索引情况：explain select id, phone, name from tb_user where phone = &#39;17799990010&#39; and name = &#39;韩信&#39;;这句只会用到phone索引字段，该sql会进行回表查询，因为phone的单列索引中并不包含name列 所以我们可以根据查询条件构建联合索引（注意顺序——最左前缀法则） create index idx_user_phone_name on tb_user(phone,name); 注意事项 多条件联合查询时，MySQL优化器会评估哪个字段的索引效率更高，会选择该索引完成本次查询 7）设计原则 针对于数据量较大，且查询比较频繁的表建立索引 针对于常作为查询条件（where）、排序（order by）、分组（group by）操作的字段建立索引 尽量选择区分度高的列作为索引，尽量建立唯一索引，区分度越高，使用索引的效率越高 如果是字符串类型的字段，字段长度较长，可以针对于字段的特点，建立前缀索引 尽量使用联合索引，减少单列索引，查询时，联合索引很多时候可以覆盖索引，节省存储空间，避免回表，提高查询效率 要控制索引的数量，索引并不是多多益善，索引越多，维护索引结构的代价就越大，会影响增删改的效率 如果索引列不能存储NULL值，请在创建表时使用NOT NULL约束它。当优化器知道每列是否包含NULL值时，它可以更好地确定哪个索引最有效地用于查询 四、 sql优化 1.插入数据（insert，load）普通插入： 采用批量插入（一次插入的数据不建议超过1000条） 手动提交事务（mysql默认自动提交事务，执行3条insert就会有三次事务，可以直接start transaction (3条insert) commit） 主键顺序插入 大批量插入（load本地文件）：如果一次性需要插入大批量数据，使用insert语句插入性能较低，此时可以使用MySQL数据库提供的load指令插入。 ①客户端连接服务端时，加上参数 –local-infile（这一行在bash&#x2F;cmd界面输入）mysql --local-infile -u root -p ②设置全局参数local_infile为1，开启从本地加载文件导入数据的开关 set global local_infile = 1;select @@local_infile; ③执行load指令将准备好的数据，加载到表结构中 load data local infile &#39;/root/sql1.log&#39; into table &#39;tb_user&#39; fields terminated by &#39;,&#39; lines terminated by &#39;\\n&#39;; 2.主键优化数据组织方式：在InnoDB存储引擎中，表数据都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表（Index organized table, IOT） a. 页分裂： 若不按顺序排列，在后面就会涉及到一个重新排序的页分裂动作 b. 页合并： 当删除一行记录时，实际上记录并没有被物理删除，只是记录被标记（flaged）为删除并且它的空间变得允许被其他记录声明使用。当页中删除的记录到达 MERGE_THRESHOLD（默认为页的50%），InnoDB会开始寻找最靠近的页（前后）看看是否可以将这两个页合并以优化空间使用。 如图中14，15，16三条数据已经被标记不被使用，如果此时page2的删除达到阈值，就会尝试将右边的17，18，19合并进一个page MERGE_THRESHOLD：合并页的阈值，可以自己设置，在创建表或创建索引时指定 文字说明不够清晰明了，具体可以看视频里的PPT演示过程：https://www.bilibili.com/video/BV1Kr4y1i7ru?p=90 个主键设计原则： 满足业务需求的情况下，尽量降低主键的长度 二级索引叶子节点挂的是主键，如果主键较长，二级索引较大会占用IO，效率变低 插入数据时，尽量选择顺序插入，选择使用 AUTO_INCREMENT 自增主键 尽量不要使用 UUID 做主键或者是其他的自然主键，如身份证号 因为这些是无序插入，会产生页分裂现象，并且长度可能较长 业务操作时，避免对主键的修改 3.order by优化 Using filesort：通过表的索引或全表扫描，读取满足条件的数据行，然后在排序缓冲区 sort buffer 中完成排序操作，所有不是通过索引直接返回排序结果的排序都叫 FileSort 排序 Using index：通过有序索引顺序扫描直接返回有序数据，这种情况即为 using index，不需要额外排序，操作效率高 如果order by字段全部使用升序排序或者降序排序，则都会走索引，但是如果一个字段升序排序，另一个字段降序排序，则不会走索引，explain的extra信息显示的是Using index, Using filesort，如果要优化掉Using filesort，则需要另外再创建一个索引，如：create index idx_user_age_phone_ad on tb_user(age asc, phone desc);，此时使用select id, age, phone from tb_user order by age asc, phone desc;会全部走索引 总结： 根据排序字段建立合适的索引，多字段排序时，也遵循最左前缀法则 order by phone，age; 在index&#x3D;age，phone的情况下是不会使用索引的，因为首先按phone排序，但是索引第一个是age 尽量使用覆盖索引 多字段排序，一个升序一个降序，此时需要注意联合索引在创建时的规则（ASC&#x2F;DESC） 如果不可避免出现filesort，大数据量排序时，可以适当增大排序缓冲区大小 sort_buffer_size（默认256k） 4.group by优化 在分组操作时，可以通过索引来提高效率 分组操作时，索引的使用也是满足最左前缀法则的 如索引为idx_user_pro_age_stat， select profession,age,coun(*) from tb_user group by profession select age where profession group by age （where 后有了profession，也算是最左） 以上两条都符合最左前缀法则 注意： explain select age,count(age) from tb_user group by age; 虽然也用到了索引，但是也用到了临时表，其实效率并不高 5.limit优化常见的问题如limit 2000000, 10，此时需要 MySQL 排序前2000000条记录，但仅仅返回2000000 - 2000010的记录，其他记录丢弃，查询排序的代价非常大。优化方案：一般分页查询时，通过创建覆盖索引能够比较好地提高性能，可以通过覆盖索引加子查询形式进行优化 例如： 12345678-- 此语句耗时很长select * from tb_sku limit 9000000, 10;-- 通过覆盖索引加快速度，直接通过主键索引进行排序及查询select id from tb_sku order by id limit 9000000, 10;-- 下面的语句是错误的，因为 MySQL 不支持 in 里面使用 limit-- select * from tb_sku where id in (select id from tb_sku order by id limit 9000000, 10);-- 通过连表查询即可实现第一句的效果，并且能达到第二句的速度select * from tb_sku as s, (select id from tb_sku order by id limit 9000000, 10) as a where s.id = a.id; 6.count优化MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高（前提是不适用where）；InnoDB 在执行 count(*) 时，需要把数据一行一行地从引擎里面读出来，然后累计计数。优化方案：自己计数，如创建key-value表存储在内存或硬盘，或者是用redis ​ 从上面可以看出，count(1)和count(*)是没有取值的过程，所以小 7.update优化（避免行锁升级为表锁）InnoDB 的行锁是针对索引加的锁，不是针对记录加的锁，并且该索引不能失效，否则会从行锁升级为表锁。 如以下两条语句：update student set no = &#39;123&#39; where id = 1;，这句由于id有主键索引，所以只会锁这一行；update student set no = &#39;123&#39; where name = &#39;test&#39;;，这句由于name没有索引，所以会把整张表都锁住进行数据更新，解决方法是给name字段添加索引 五、视图&#x2F;存储过程&#x2F;触发器 1. 视图①语法 1）with cascaded check option v1 通过 user基表建立，v2通过v1建立，v3通过v2建立 当v2表cascaded后，它在insert数据的时候也会检查其所依赖的v1条件；v3没有cascaded，虽然它依赖了cascaded的v2，但是insert的数据检查也只会检查v1，v2的条件，并不会检查v3 2）with local check option local就是会递归的去寻找，满足v2后会看v1的option，如果没有则不会管v1的条件 3）相关事项及实例 注意： 视图的增删改操作必须是视图中的一条数据对应基表的一条数据，若使用了聚合函数、group by、distinct、having、union(all)等，视图是无法更新的 视图的作用： 简单：方便用户对数据理解，可以将经常查询的数据定义成一张视图 安全：视图能让用户只浏览和修改到他们被允许的数据（mysql的表权限中不包含columns的权限） 数据独立：屏蔽真实表结构变化带来的影响 name -&gt; stuName ​ 三表联查： ​ 2. 存储过程1）变量1）系统变量（@@） ​ session：会话变量，在另外一个会话中则不存在，未指定默认是session ​ global：全局变量，在所有会话中都存在，但是在restart mysql后还是不会改变（持久改变需要在配置文件中配置） 2）用户自定义变量（@） 3）局部变量 ​ 只在存储过程中生效 2）存储过程中的语法①if ​ ②case ​ ③while ④repeat ⑤loop ⑥cursor 游标游标类似于一个集合、迭代器，每次从游标中取一行数据 ​ eg： ⑦handler 条件处理程序类似于异常处理，根据捕获的异常码来处理 eg： 这个对游标的改进就是在，游标抛出异常02000（not found）后关闭cursor 3）存储函数 3. 触发器触发器可以在insert&#x2F;update&#x2F;delete 语句执行之后，执行触发器中定义的sql，可以完成日志记录、数据校验等工作 触发器目前只支持 行级触发：如一条语句影响了5行数据，那么触发器会被执行5次 ​ 语句级触发：如一条语句影响了多行数据，但是触发器只会触发一次 1）语法 2）案例 eg1：insert案例 eg2：update案例 eg3：delete案例 六、锁 1. 全局锁​ 1）全局锁是对整个数据库加锁，加锁后可以查询DQL，但是DDL和DML语句都不能执行，主要用于备份： ​ 如在备份库存的过程中，用户下单后，库存扣减，但是备份后的库存还是扣减前的数据，然后开始备份订单表和订单日志表，下单后这些数据都会增加，这两个的备份库都会有新的用户下单的数据，这样就和备份的库存数据不一致了，丧失了数据一致性 2）使用过程 2. 表级锁1）表锁 读锁（表共享读锁）：读锁本会话可读不可写，其他会话也是可读不可写 写锁（表独占写锁）：写锁本会话可读可写，其他会话不可读不可写（会被阻塞，释放锁以后会继续执行） 2）元数据锁在事务中使用sql语句的时候，系统会自动添加 事务A在做select查询并且事务没结束，那么这时候通过alter改变表结构（元数据）是不被允许的 3）意向锁意向锁的作用，一个例子： ​ 当线程A中的事务中执行update语句的时候（根据id索引）会锁住这一行的数据，如果此时有另外一个线程要为该表加read&#x2F;write lock，那么这个线程有需要一条一条的检查看是否有行锁，这样效率太低了 ​ 为解决这一问题，在事务中执行sql语句的时候，mysql除了添加行锁，还会为整张表添加一个意向锁，当其他线程要为该表加锁的时候，就可以根据所加的意向锁判断是否能加锁，而不需要一条一条检查数据 select …. lock in share mode 会添加意向共享锁，可以与表共享读锁（read）兼容，与表独占写锁（write）互斥（会发生阻塞） 增删改、查询for update 会添加意向排他锁，与read和write都互斥 意向锁直接都是兼容的，意向共享锁和read锁兼容和write锁互斥，意向排他锁与read锁和write都互锁 3. 行级锁 1）行锁行锁有两种：s（共享锁）、x（排他锁） 总结： 增删改操作都是加排他锁 普通select不加锁 select语句后加lock in share mode 共享锁，加for update 加排他锁 注意： mysql的行级锁是针对索引的锁，锁住的是聚集索引叶子结点的一个数据，若在增删改的时候没有用到索引，那么行锁就会升级成为表锁 查询元数据锁和行锁的语句 select object_schema,object_name,index_name,lock_type,lock_mode,lock_data fromperformance_schema.data_locks; 2）间隙锁、临键锁 默认情况下，使用的是next-key临键锁来进行搜索和索引扫描，当某些情况下临键锁可以优化成间隙锁： 如当用主键查询不存在的数据的时候： 事务A我们想插入一条id&#x3D;4的数据，第一次查询id&#x3D;4发现没有数据，这时候临键锁优化为间隙锁，将3与5的间隙锁起来（B+树结构中，这两个row是相邻的），那么事务B就不能在3和5间插入id&#x3D;4的事务，那么事务A在插入id&#x3D;4的数据的时候就不会出现幻读的现象 七、InnoDB引擎1. 架构图1）逻辑结构 2）物理结构 逻辑结构： 2. 事务原理 ​ MVCC（无锁）+锁保证了事务的隔离性，redo log 保证了事务的持久性，undo log 保证了事务的原子性，redo log 和 undo log 一起保证了事务的一致性。 1）redo log​ redo log保证了事务的持久性 问题情境： ​ InnoDB内存结构中，主要的内存区就是缓冲池，缓冲池中缓冲了很多的数据页。当我们在一个事务中执行增删改操作的时候，InnoDB会先操作缓冲池中的数据，将缓冲池中的数据修改，在缓冲区中被修改过的数据页称为脏页。脏页会在一定的时机，通过后台线程刷新到磁盘中，从而保证缓冲区中数据和磁盘中的数据一致。因此缓冲区的脏页数据并不是实时刷新的，若过一段时间后在从缓冲区向磁盘刷新数据的过程中出错了，但提示给用户事务提交成功，但是数据却没持久化下来。 解决办法redo log： ​ 有了redo log 后，在对缓冲区的数据进行增删改操作后，会首先将数据页的变化记录在redo log buffer中，在事务提交时会将redo log buffer中的数据刷新到redo log磁盘文件中。如果脏页数据出错，此时就可以借助于redo log来进行数据恢复，以此来保护数据持久性。若 脏页数据已经成功刷新到磁盘 或 涉及到的数据已经落盘，那么redo log就没用了，可以删除了，所以存在的两个redo log文件是循环写的（一个没用了删掉用另一个） 总结： redo log 有两部分 内存：redo log buffer 在事务提交后马上刷新给磁盘中的redo log 磁盘：两个redo log 循环写 为什么不能直接将脏页数据实时刷新，而是刷新redo log buffer中的数据？ 因为操作的数据页地址是随机的，如果实时刷新脏数据，那么就是随机IO（随机读写磁盘），性能低 redo log的刷新是顺序IO（日志按顺序写的），数据效率高 2）undo log​ undo log 保证了事务的原子性 ​ undo log 主要是为了 回滚事务 和 MVCC，不同于redo log 是物理日志，undo log 是逻辑日志： ​ 当在事务中执行了一条insert语句后，undo log就会记录一条相反逻辑的delete语句，执行一条update语句后，undo log就会记录一条相反逻辑的update语句 undo log 的销毁： 在执行完事务后（commit 或 rollback后），并不会马上删除，因为MVCC还可能用到undo log undo log 的存储：undo log 通过段segment的方式存储，（segment有 数据段—B+树叶子节点，索引段—非叶子节点，回滚段—undo log） 两个作用： 回滚：回滚是在事务结束的时候（commit或rollback），如果选择回滚，那么mysql会执行undo log中的逻辑记录 MVCC：undo log 中记录了版本链，版本链配合readview来完成MVCC版本控制 3）MVCC MVCC是在快照读的时候通过事务id，undo log 版本链，ReadView来查找返回的历史版本数据。 MVCC就是通过表中的隐藏字段事务id，undo log 版本链，ReadView（事务确定）三者来实现的： 查询的时候会根据当前的事务活动情况和事务id来确定ReadView，然后再从undo log版本链头部开始通过查看事务id是否满足ReadView的匹配条件，满足条件则返回该版本 ①当前读和快照读a）当前读 当前读读取的是记录的最新版本，读取的需要保证其他并发事务，所以会对读取的数据加锁 eg： ​ 当A事务开启后，①的查询结果id&#x3D;2是PHP，此时开启B事务并执行修改id&#x3D;2为JSP数据操作，再次通过事务A的①查，查不出该次变化，因为当前隔离级别是可重复读，保证了两次读取事务的一致性；如果读取到当前事务的最新数据，可以使用select …. lock in share mode 来进行当前读，这样读取到的就是最新的数据id&#x3D;2是JSP。 b）快照读 ​ 快照读是根据一定规则MVCC读取记录数据的可见版本，有可能是历史数据，这个过程是不加锁的 * 读已提交：每次的select都是一个快照读 * 可重复读：开启事务后的第一个select是快照读，后续的select只是直接使用第一个快照读的数据（查询的实际上是第一个快照数据） * 串行化：快照读退化成当前读 ②隐藏字段 ​ 每一张表都会有两个隐藏字段：最近事务id、回滚指针，如果该表结构未指定主键，那么会生成隐藏字段row_id。 ③undo logundo log 是回滚日志，在insert、update、delete的时候会产生回滚数据来产生。 当insert的时候，数据只需要回滚的时候使用，所以commit后（证明没有rollback）可以直接删除 update、delete，数据不仅在回滚的时候需要使用，在快照读的时候也需要，所以不能删除 https://www.bilibili.com/video/BV1Kr4y1i7ru?p=143&amp;spm_id_from=pageDriver undo log 版本链： 每当要修改一条记录的时候，就会在undo log存储该版本（包括事务id，回滚指针指向上个版本），最新记录的回滚指针指向该版本 版本之间通过回滚指针连接，头部是最新记录，尾部是最旧记录 ④readview(读视图）readview是每个事务独有的，主要内容有两部分：有四个字段、定义了 快照读sql访问版本链的规则 a）字段 注意max_trx_id 并不是目前最大id，而是最大事务id+1（下一个分配的id） b）定义的访问undo log 版本链的规则 trx_id 代表的当前版本链中隐藏字段中的 事务id 注意：不同的隔离级别，会在不同的时机生成readview来进行快照读 读已提交 会在每次select时都生成一个readview来作为此次快照读的依据（读已提交每次select都是一个快照读） 可重复读 会在第一次select时生成一个readview来作为本次快照读的依据（可重复读只有第一次select是快照读，后序select都是复用该次数据） ⑤RC和RR的MVCCa）RC 隔离级别 PC的每次select都是一个快照读，所以事务5的两次select会有两个ReadView ​ MVCC就是在快照读的时候，根据该次select产生的readView，将undo log 的版本链中从头开始 通过每条数据中隐藏字段中的事务id与readView指定的规则做匹配，如果匹配了则返回该条版本记录。 b）RR 隔离级别 ​ 在RR隔离级别下，只有在第一个select快照读的时候会生成ReadView，后序的select都是复用该ReadView，所以可以保证多次select的数据是一致的。 八、数据库1. 基本表","categories":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"}]},{"title":"Spring笔记","slug":"Spring笔记","date":"2022-03-10T10:31:31.000Z","updated":"2022-06-23T10:32:54.066Z","comments":true,"path":"2022/03/10/Spring笔记/","link":"","permalink":"http://example.com/2022/03/10/Spring%E7%AC%94%E8%AE%B0/","excerpt":"一些Spring的笔记* . *","text":"一些Spring的笔记* . * 一.xml配置相关1. bean标签中的scope spring bean 线程安全问题： https://cloud.tencent.com/developer/article/1743283 https://blog.csdn.net/u012843361/article/details/84023869 2.bean的三种实例方式1）无参构造方法 ​ 这样就是通过无参的构造来完成的，并且方法如果是private也能够实例化，说明底层用的是反射（暴力反射） 反射及暴力反射：https://segmentfault.com/a/1190000037432381 2）静态工厂实例化 以上为静态工厂创建对象，以下为spring的静态工厂方式： 这样可以在new对象前进行一些必要操作，同时也是为了兼容一些老的系统： ​ spring bean 线程安全问题： https://cloud.tencent.com/developer/article/1743283 https://blog.csdn.net/u012843361/article/details/84023869 3）实例工厂实例化 可以看出，实例工厂中return对应对象的方法不是static，所以我们在使用的时候需要先new工厂类再使用其方法实例化bean 以下为spring的实例化工厂方式： 因为实例工厂类的方法并不是static的，所以我们需要先有一个工厂类，所以需要先配置一个userFactory 静态工厂和实例工厂对比： 静态工厂： 实例工厂： 这种方式有一个简化的配置方法： 首先实现BeanFactory接口，并实现两个方法，一个是return对应的bean，另一个是return对应的bean.class 3.bean的生存周期1）标签中配置init-method和destroy-method ①close方式关闭容器 ②钩子函数方式关闭容器 ​ close()后马上关闭容器，而使用钩子函数并不会立刻关闭容器，而是在JVM退出前调用destroy函数 2）implement接口来替代标签 eg： 4.依赖注入(set property)1）setter注入引用类型： 简单基本类型： 总结： 2）构造器注入引用类型： 简单基本类型： 除此之外还有两种方法： 3）自动注入 4）集合注入 5.spring加载properties1）优先加载环境变量问题 ​ &lt; context:property-placeholder&#x2F; &gt;标签会加载系统的环境变量，而且环境 变量的值会被优先加载 ​ 电脑中就有一个变量是username，prop中也有，这时候优先加载的就是电脑中的username ​ 解决方法： 2）加载多个properties classpath 是加载当前项目的根路径 classpath* 还会加载当前项目所依赖的所有项目的根路径 6.容器相关 ApplicationContext的延迟加载： bean相关标签： 依赖注入相关标签： 二、注解配置相关1.注解配置相关1）@componentScan 2）@Configuration和@ComponentScan ​ 3）@scope和@PostConstruct、@PreDestroy 4）@PropertySource和@Value PropertySource详解： https://blog.csdn.net/weixin_43849277/article/details/120728182 5）@AutoWired、@Qualifier 反射及暴力反射：https://segmentfault.com/a/1190000037432381 6）@Bean和@Import ①@ComponentScan方式 但是这种方法不能立刻知道引入的是哪一个，不推荐 ②@Import 7）注解方式注入第三方bean①简单数据类型注入 ②引用类型注入 引用类型注入只需要为bean定义方法设置形参即可，容器会根据类型自动装配对象。 这样dataSource在初始化的时候就会按照类型自动装入（类似AutoWired）。 8）XML和注解配置比较 2.spring整合mybatis1）xml配置方式①spring-mybatis.xml ②在xml中写sql 2）注解配置方式①springConfig ②jdbcConfig ③MybatisConfig 3.spring整合junit1）依赖 2）Test类 三、AOP1.相关标签 2.AOP基本知识1）工作流程 2）实现原理 bookDao已经被AOP增强，但是打印出来的还是同一个对象地址，这是因为AOP重写了toString方法，现在的对象实际上是代理对象 3.通知Advice1）通知类型 2）AOP获取切入点信息 ①非环绕通知：JoinPoint非环绕通知通过JoinPoint获得参数、返回值、异常 参数： ​ 环绕通知中也是一样的： 返回值： ​ 异常： ②环绕通知：ProceedingJoinPoint环绕通知通过ProceedingJoinPoint获得参数、返回值、异常 参数： 返回值 异常： ③注意Target： target方法的返回值类型是int，不是null MyAdvice类： 原始target方法select的返回值是一个int，说明在调用这个方法的时候，我们是需要返回值的 但是在advice中的around 修改： 4.AOP事务管理1）基本知识 eg： 如图，①执行完，1&#x2F;0报错，②就不会执行，这样transfer事务就失去了原子性 2）相关注解 3）实现①在需要被事务管理的方法上添加注解 ②在JdbcConfig类中配置事务管理器 这和xml配置类似，都是要在config中配置一个transactionManager的bean： ③开启事务注解 xml方式： 4）原理 事务管理员和事务协调员： 即spring事务管理的数据源和mybatis的数据源是同一个数据源！！！ 5）事务属性 注意： ​ spring并不会对所有异常都进行回滚，只会对RuntimeException和Error及其子类回滚，其它异常类型不会回滚 6）事务的传播属性①例子 log方法是在logService中开启了自己的事务的： 这是因为log事务加入了transfer事务中： 解决办法（修改log事务传播属性）： ​ 本例中logService.log作为事务协调员有一个自己的事务T2，transfer作为事务管理员有一个自己的事务T1，但是在配置事务传播属性propagation&#x3D;Propagation.REQUIRES_NEW后，T2不会加入T1事务，T1是否失败不会影响到T2。 ②事务传播属性可选值 REQUIRED： 当事务管理员开启一个事务T时，事务协调员不管是否有事务都加入T 事务管理员没有事务，事务协调员就会开启一个自己的事务T2 REQUIRES_NEW： 当事务管理员开启一个事务T时，事务协调员不会加入T，而是开启一个自己的事务T2 事务管理员没有事务，事务协调员就会开启一个自己的事务T2","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"操作系统-概述","slug":"1.操作系统-概述","date":"2022-03-06T11:17:48.000Z","updated":"2022-06-23T10:29:41.421Z","comments":true,"path":"2022/03/06/1.操作系统-概述/","link":"","permalink":"http://example.com/2022/03/06/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E6%A6%82%E8%BF%B0/","excerpt":"操作系统! * !","text":"操作系统! * ! 1.操作系统的特征 并发： ​ 宏观上是同时发生的，实际微观上是交替进行的 共享： ​ 互斥共享：摄像头资源一段时间只能供一个进程访问 ​ 同时共享：硬盘资源一段时间可供多个进程访问，实际微观上也是交替访问 虚拟： ​ 空分复用技术：运行的程序共需8G内存，实际上只有4G ​ 时分复用技术：单核CPU在一段时间内运行多段程序，看起来是由多个CPU在完成工作 异步： ​ 由于多个程序并发执行，程序间就有可能因获取资源而被堵塞，以不可预知的速度进行。 2.操作系统的发展 3.内核态和用户态 1）内核程序负责系统资源的管理，只有内核程序可以使用特权指令 2）应用程序只能使用非特权指令 3）内核由很多内核程序组成 4）内核态-&gt;用户态，内核程序执行一条修改PSW的特权指令 5）用户态-&gt;内核态，中断引起，硬件自动完成 3.中断1）中断分类 内中断：和CPU内部执行的指令有关 ​ 陷入：用户程序主动执行，是一条特殊的非特权指令，用去请求调用系统服务 ​ 故障：故障可能被修复，被修复后会继续执行 ​ 终止：如正数&#x2F;0，用户程序非法使用特权指令，终止后不会再执行该程序 外中断：与CPU内部无关，中断信号来自外部 ​ 时钟中断：时钟定时中断用户程序1，CPU处理中断信号让用户程序2执行 ​ I&#x2F;0中断：输入输出设备发出的中断信号 2）中断原理 CPU会根据中断信号查询 中断向量表 ，通过指针找到响应的中断处理程序（内核程序） 内中断：在每条指令执行的时候检查是否有异常发生 外中断：在每个指令周期末尾，CPU都会检查外中断 4.系统调用 调用创建文件的库函数后，需要使用 系统调用 ，这时候会传入一个参数（通过传入的参数找到对应的系统调用），执行trap函数进入内核态，执行系统调用（会执行特权指令），执行完以后返回 系统调用实际上就是由操作系统执行的底层的操作：如创建文件、删除文件等 5.操作系统体系结构 大内核和微内核其实的区别就是是否将 进程管理、存储管理、设备管理 纳入内核","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"操作系统笔记-内存","slug":"3.操作系统-内存","date":"2022-03-06T11:17:48.000Z","updated":"2022-06-23T10:29:55.956Z","comments":true,"path":"2022/03/06/3.操作系统-内存/","link":"","permalink":"http://example.com/2022/03/06/3.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%86%85%E5%AD%98/","excerpt":"操作系统! * !","text":"操作系统! * ! 三、内存1.内存基本知识 2.内存管理1）内存空间的分配与回收 2）内存空间的扩展 3）地址转换 4）内存保护上限寄存器： 重定位寄存器+界地址寄存器： 重定位寄存器记录了该段数据的起始地址，起始地址+逻辑地址&#x3D;物理地址 3.内存的覆盖和交换（扩存）1）覆盖 固定区内存是一直都在的，覆盖区内存可能被覆盖 2）交换 交换其实就是中级调度，调出部分进程到外存的挂起队列，缓解内存的压力 外存分为对换区和文件区，调出的进程会在对换区，对换区IO速度&gt;文件区 4.连续分配管理方式1）单一连续分配 所有的用户区只让一个进程使用，无外部碎片，有内部碎片 2）固定分区分配 分区大小相等和分区大小不等两种，无外部碎片，有内部碎片，若某进程超过最大分区需要覆盖 3）动态分区分配 数据结构： 动态分区分配算法 回收：相邻的空闲分区进行合并 5.基本内存分页管理（离散） 1）分页存储 ​ 分页存储实际就是将内存分成一个个的大小相等的 页框，然后再将进程根据页框大小分成一个个的 页面，最后将这些一个个的页面离散地存放在一个个的页框中。进程的最后一个页面可能并没有页框那么大，这样就有可能产生内部碎片。 ​ 内部碎片：进程在使用内存中分配的空间剩余的空间，如该进程6kb，分配了8kb内存，2kb就是内部碎片 ​ 外部碎片：内存中两个划分区域间难以利用的小空间 2）页表 页表记录了该进程各个页面与页框的映射信息，页表存储在PCB中：页号是隐含的分页顺序，块号是该页在内存中的页框号。 由于一个 页框大小&#x3D;页面大小&#x3D;4KB，所以4GB内存可以有2^32&#x2F;2^12&#x3D;2^20个内存块， 那么至少需要20位来表达页框的编号，由于计算机是B来存，那么就需要3B &#x3D; 24b来表示，2B &#x3D; 16b&lt;20 3）页号、页内偏移量 ​ 该进程逻辑大小200B，页面大小为50B，逻辑地址110B&#x2F;50B&#x3D;2，该逻辑地址在2号页表中，页内偏移量&#x3D;110%50&#x3D;10，说明该地址在从该页起始地址偏移了10B。 一个页面大小为4KB，那么一页的数据量就是2^12B 那么一个逻辑地址前 20位 表示页号，后12位表示这个逻辑地址相较于该页号对应的地址块首地址偏移了多少B 通过该逻辑地址可以推出 页号 和 偏移量 ，查询页表的页号可以找到块号，通过块号可以得到该块起始地址，起始地址+偏移量&#x3D;内存真实地址 4）页表寄存器 5）逻辑地址-&gt;物理地址过程 ​ 首先逻辑地址可以分割出 页号P 和 业内偏移量W，通过页号P 和 页表寄存器的页表长度M（存了共有多少页表项）对比看地址是否越界，越界则会发生内中断。 没越界的话，就会通过页号找到对应的内存块号b，内存块号b*页框大小 + 页内偏移量W &#x3D; 物理地址E eg： 6）页表项储存 页表项是存储在内存中的，一个页面大小&#x3D;页框大小&#x3D;2^12B&#x3D;4096B，页表中一个 页表项大小&#x3D;块号大小&#x3D;3B， 这样内存中一个页框存储页表项的时候会存4096&#x2F;3&#x3D;1365个，最后一个的index是1364，该页框还剩1B内存， 但是下一个index为1365页表项则需从下一个页框中存，则其内存地址为 X+3*1365+1&#x3D;X+4096 所以为了方便，会调整页表项大小（块号大小）使其能被一个页框大小整除，这比如说扩大到4，则一个页框刚好可存2^12&#x2F;2^2&#x3D;2^10个 7）快表页表（慢表）是存储在内存中的，快表（页表的副本）是存储在cache中的： 首先会查快表再查慢表；或者快慢表一起查 8）两级页表单级页表存在两个问题： 问题1：页表很大的时候需要连续占用多个页框 问题2：进程在运行的时候可能并不需要页表所有内容，只需要访问几个特定页面 问题1解决： 为此我们为 页表 设计一个 页目录表 来实现页表在页框的分散存储 ​ 页表大小为4KB&#x3D;2^12B，所以32位的后12位存业内偏移量，32位的前12位存 页号，则每个页框能存4K&#x2F;4B&#x3D;1K&#x3D;2^10个页表项， 存完所有页表项需要2^10个页框 若可以我们可以将整张页表分为1024个分组，每个分组有1024个页表项，最后制定一个 页目录表 记录叶分组和块号的对应关系 ​ 这样页表就可以分散存储了，这样的话本来需要1024个连续的页框（每个空间有1024个页表项），只需要多申请一个页框，就可以这张页面储存这1024个页框的位置，共1025个页框 问题2解决： 一级页表设置一个属性，说明该页面是否在内存中，如果不在就发生内中断从外存中调入 6.基本内存分段管理（离散）1）分段存储 逻辑地址&#x3D;段号+段内偏移量 过程： 段表寄存器中段表长度M（存了段表项的总数量），若段号&gt;&#x3D;段表长度则越界了 2）分段和分页的对比分段的每一段都是一个共同的逻辑，这样每段的功能相对独立，这样便于用户的管理 分段资源利于共享，因为某段的功能相对独立，而分页的话可能某页框中的一段能访问另一端不能访问 7.段页式管理 段页式实际上就是先进行分段，然后再将每一段进行分页 ​ 首先查段表，根据段号查到对应也变存放的块号，找到页表后，根据页号找到对应 页面数据 存放的块号， 块号*页框大小+页内偏移量&#x3D;物理地址 8.虚拟内存1）局部性原理 时间局部性：while指令被执行了可能还会继续执行，a变量在while指令中，所以短时间会多次访问a地址 空间局限性：指令执行后其前后的指令也有可能被执行，因为内存中大部分数据都是连续存放的 2）虚拟内存特点 实现虚拟内存的两个方向： 作业运行不需要一次性装入，可以将先要用到的先装入，然后多次调入内存 作业运行的时候不需要一直常驻内存，短时间不需要的先调入外存，用到的时候再换进来 虚拟内存在逻辑上扩充了内存的大小 3）实现 传统的非连续分配是将进程所有数据调入，虚拟内存的请求方式会灵活调出部分数据到外存，并在需要时从外存调入 9.请求分页管理相较于基本分页管理，请求分页最大的不同就是在快表没命中，慢表没有的时候，将相应页面调入内存，同时页表项修改对应数据 10.页面置换算法1）最佳置换算法 注意： 因为该算法需要知道后序将要访问到的页，所以无法实现 发生了缺页中断并不一定会发生页面置换，只有当内存满了以后才会发生调换，当页面有空闲的时候，缺页会直接调入空闲区域 2）先进先出 注意： 效率低 发生Belady异常：分配的物理块变多，效率反而越低 3）最近最久未使用 注意： 效率最接近最佳置换算法，但是需要硬件成本 4）时钟置换算法 为每个页表项添加一个访问位，当某页被访问置1，两轮扫描： 第一轮：扫描寻找访问位为0，并把1置0 第二轮：扫描寻找访问位为0（必有） 5）改进的时钟置换算法 每一个页表项设置&lt;访问位，修改位&gt;，1代表被访问或修改了，四轮扫描： 第一轮：寻找&lt;0,0&gt; 第二轮：寻找&lt;0,1&gt;，并把&lt;x,y&gt;中的x置0 第三轮：寻找&lt;0,0&gt; 第四轮：寻找&lt;0,1&gt;（必有） 11.页面(框)分配策略由于请求分页管理不是将进程所有页面一次性装入，而是装入部分后再根据实际情况调入，所以我们需要为其分配一定页框 1）分配策略、置换策略 驻留集：系统为进程分配的页框集合 固定分配：开始分配一定数量后大小不变 可变分配：开始分配一定数量，根据情况改变，驻留集大小可能改变 局部置换：置换只能是自己进程的页面 全局置换：除了自己进程，也可以置换其它进程 2）何时、何处调入页面 3）抖动和颠簸 驻留集分配不够，进程页面频繁调入调出 可以根据实际工作集大小调整驻留集","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"操作系统笔记-IO管理","slug":"5.操作系统-IO设备","date":"2022-03-06T11:17:48.000Z","updated":"2022-06-23T10:30:14.039Z","comments":true,"path":"2022/03/06/5.操作系统-IO设备/","link":"","permalink":"http://example.com/2022/03/06/5.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-IO%E8%AE%BE%E5%A4%87/","excerpt":"操作系统+ . +","text":"操作系统+ . + 1.I&#x2F;O控制器1）I&#x2F;O控制器各部分 ①CPU通过控制线发出相关命令，通过地址线来指明需要操作的IO设备， ②数据寄存器： ​ 当CPU可以在此处放入或接收一些数据的时候，IO逻辑可从这里取得数据取得或放入数据（如CPU需要IO输出一些数据时） ③控制寄存器： ​ CPU发出的IO指令会有一些参数，这些参数会放在这里，IO逻辑可从此处读入 ④状态寄存器： ​ IO设备可以将各个IO设备的状态放在此处，CPU可读入 ⑤数据：IO逻辑可以将要输入的数据在放在这里让IO设备输出，也可以从此处获得IO输入的数据 ​ 状态：IO逻辑可以从此处获得该IO设备的状态 ​ 控制：IO根据CPU发出的指令和对应参数，在这里指明IO设备执行对应操作 注意： 一个IO控制器可能对应多个IO设备 数据寄存器、控制寄存器、状态寄存器有多个 2）寄存器的编址 ①寄存器与内存同一编址： ​ 简化了指令，控制寄存器可以直接用内存相关指令 ②寄存器独立编址： 需要设置专门的指令来控制寄存器 2.IO控制方式 1）程序直接控制 ​ CPU在发出读指令后，设置状态寄存器为1（代表IO设备还未就绪），然后while访问状态寄存器直到其值为0（IO设备已经就绪）。IO设备在准备好后，会将数据和自身状态传给IO控制器，IO逻辑修改响应寄存器，CPU收到后再进行处理。 CPU需要等待IO设备的准备，并且每一次procedure只能读一个字的数据，效率太低 2）中断驱动方式 ​ 程序直接控制CPU在循环检查等待IO就绪会浪费大量时间，中断驱动会在CPU发出指令后将IO进程阻塞执行其它进程，当IO准备好并发送相关信息给IO控制器后，IO控制器会发出一个中断信号来提醒CPU，CPU会根据该中断信号进行处理。 该方式虽然能够让CPU和IO设备并行工作，但是中断处理恢复现场会浪费时间，并且每一次procedure还是只能读一个字的数据 3）DMA方式 ​ DMA也是一种IO控制器，当CPU发出指令（读入多少数据，数据存在内存什么位置，数据存在外存什么位置），DMA会完成这一些操作，在全部处理完以后才会发出中断信号让CPU来处理。 ​ 读写的块必须是连续的，同时读入内存后这些块也是连续的 ​ 注意：DMA一次完整过程的数据传输是以块为单位的，但是内部在读入的时候还是以一个字为单位 DMA结构： 4）通道控制方式 “通道”可以理解为一种更低级的CPU，只能执行一系列通道指令，并且通道可以对应多个IO控制器 CPU会将通道程序（一系列任务、任务清单），通道读入该通道程序后执行该任务清单，在执行完任务户在发出中断让CPU来处理 DMA和通道的区别： 1.DMA对数据的读取还是由CPU下达命令的，而通道执行的是CPU给出的通道程序 2.DMA可读写单块或连续的多块数据，通道能读写一组数据 3.IO软件层次结构 4.IO核心子系统实现功能 1）IO调度 IO作为一种资源，其调度算法等和进程、磁盘的调度类似 2）设备保护 ​ 设备可以看作是一种文件，其保护机制类似于文件保护的机制，当用户要访问某个IO设备的时候，系统会根据其FCB中记录的信息来判断该用户是否有相应的访问权限。 3）假脱机技术（SPOOLing技术） ①脱机技术和SPOOLing技术的对比 脱机技术： ​ CPU读入读出数据都是通过磁带这种高速的媒介，而用户真正提供或获得的输入输出还是依靠纸带机，但这时候输入输出已经脱离了CPU的控制，CPU在这时可以处理其它更多的请求。 假脱机技术： ​ 输入设备（纸带机）输入的数据会先慢速写入输入缓冲区，输入进程（外围控制机）将输入缓冲区数据写入输入井（输入磁带），输入井中的数据会被高速读入CPU ​ CPU会将输出的数据高速写入到输出井（输出磁带），输出井会通过输出进程（外围控制机）将数据写入输出缓冲区，输出设备（纸带机）会从输出缓冲区慢速读入数据 ②共享打印机例子 ​ 进程在打印数据时会先将数据写入输出井（输出磁带）中，这样在主机层面该进程就好像完成了打印任务，实际上打印的顺序还是按照输出进程中的假脱机文件队列，但这些任务已经不受CPU控制了，这样看起来就是多个文件共享了打印机。 4）设备的分配与回收 ①考虑因数​ 固有属性：要考虑该设备是独占（打印机）还是共享设备（磁盘） ​ 分配算法：资源分配的算法和进程的调度算法类似 ​ 安全性： ​ 安全分配：IO的时候进行该进程进行阻塞 ​ 不安全分配：IO的时候进程继续运行，并且还可以请求其它IO ​ ​ ②静态分配和动态分配 ​ 静态分配：一次性分配完所有资源，否则不分配；运行结束后归还所有资源 ​ 动态分配：在运行过程中需要了再申请，可能发生死锁，可用银行家算法避免 ③设备分配管理的数据结构 一个通道控制表对应多个IO控制器表，一个IO控制器表（HP打印机）对应多个设备控制表（多台相同的打印机） 每张表都有一个等待队列指针，缺少对应资源的进程会将PCB挂在该队列上 ④设备分配的步骤 若让用户使用“物理设备名”扩展性较低，应使用逻辑设备名，每个用户可享有独立的 逻辑设备名和物理设备名映射表 5）缓冲区管理 注意缓冲区最重要的特性： ​ 缓冲区满的时候，才能读取缓冲区的数据 ​ 缓冲区空的时候，才能往缓冲区写数据 ①单缓冲 ②双缓冲 ​ ​ 单缓冲和双缓冲在通信时的区别： ​ 单缓冲： ​ 双缓冲： ​ 管道实际上就是一种缓冲区，要想实现双向通信，必须实施两个管道 ③循环缓冲 ④缓冲池","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"操作系统笔记-进程与锁","slug":"2.操作系统-进程和锁","date":"2022-03-06T11:17:48.000Z","updated":"2022-06-23T10:29:51.084Z","comments":true,"path":"2022/03/06/2.操作系统-进程和锁/","link":"","permalink":"http://example.com/2022/03/06/2.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E5%92%8C%E9%94%81/","excerpt":"操作系统! * !","text":"操作系统! * ! 1.进程的概念、组成、特征 进程是动态的，是一次程序运行的过程，同一程序多次启动会对应多个进程。 2.进程的状态及进程状态的转换 进程首先会进入创建态（完成新建PCB等准备工作），然后进入就绪态等待CPU的调度，当CPU运行该进程后进程进入运行态。当运行时出现异常，如整数&#x2F;0就会终止掉该进程，进程进入终止态。若进程在运行过程中需要请求资源但资源还未空闲，如IO设备，那么进程就会进入阻塞态等待资源空闲。当资源空闲，进程有了需要的资源，那么进程将进入就绪态等待CPU调动，CPU在运行该进程后又会重新进入运行态。同时运行态也有可能因为时钟中断进入就绪态。 对于同一状态的进程，操作系统会将它们的PCB组织起来：队列和索引两种方式 3.进程控制1）原语 ​ 原语是程序段，实现了原子性。主要由两条特权指令实现：关中断指令执行后，中断信号将不会影响该任务执行，等到开中断指令执行后，改程序段才能被中断。 ​ 关中断指令和开中断指令必须是特权指令，若是非特权指令，那某一程序就能够一直霸占CPU了。 2）进程控制原语 注意： ​ PCB中存储了上次进程执行的相关信息，在被唤醒后，进程可以根据这些信息还原上次的运行状态。 4. 进程通信1）共享内存 ​ 共享内存就是开辟一片空间供通信进程使用： ​ 基于数据结构—只能根据数据结构进行存储，较低级； ​ 基于存储区—划出一片共享存储区，存储的形式和位置等都由通信进程控制。 2）消息传递 直接通信： ​ 发送进程P直接将msg发送到接收进程Q，并将msg挂到接收进程Q的消息队列中，接收进程Q通过接收原语取得消息 间接通信： ​ 可以有多个发送方向信箱A发送信息，也可以有多个接收方从信箱A接收信息 3）管道通信 管道对于数据的接收相当于于一个单向队列，FIFO。 管道实际上就是一个缓冲区，只有写满数据才能取，只有取完数据管道空了才能写。 要想实现双向通信，必须要要两个管道。 5.线程的实现方式 1）用户级线程 如while（true）循环判断一个值就是一个傻瓜用户级线程，若其中一个线程堵塞了，整个进程都会被堵塞 2）内核级线程 内核级线程的管理由操作系统内核完成，一个用户进程会占用多个内核级线程，线程切换需要系统内完成，切换内核态是有成本的 3）多线程一对一： ​ 其实就是内核级线程 多对一： 一个内核级线程管理多个用户级线程，用户级线程切换不需要经过内核态，但是一个用户级线程阻塞后，其他也会被阻塞 多对多： 一个进程包含多1，2，3个用户级线程，1可由内核级线程1执行，2，3可由内核级线程2并发执行。即一个进程可能对应多个内核级线程。当一个进程对应的所有内核级线程都被阻塞后，才称该进程被阻塞。 6.调度1）高级调度 高级调度是面向队列的，启动一个程序并创建相关进程。外存的作业后备队列-&gt;调入内存，并创建响应PCB，当调出的时候才会撤销。 2）中级调度 ​ 当内存空间不足的时候，会将某些数据调出外存，这些进程的PCB会被组织成挂起队列，中级调度会根据某种策略决定将某个处于挂起状态的进程重新调入内存。 3）低级调度 按照某种策略，从就绪队列中挑选一个进程并将处理机分配给它。 4）七状态模型 挂起的进程是在外存的挂起队列中，阻塞的进程是在内存的阻塞队列中的。 ​ 当内存空间不足，会将某些进程从就绪队列调入外存的就绪挂起队列中，默写阻塞态进程夜游可能会被调入阻塞挂起队列，当需要的事件出现以后该进程就有可能从阻塞挂起变为就绪挂起。运行态的进程也有可能进入就绪挂起。 5）三种调度对比 7.进程调度的时机 切换和过程方式1）切换时机 中断处理不能调度 操作系统内核程序临界区： ​ 临界资源是互斥访问资源，一个进程访问就会上锁，临界区就是这段资源的代码 ​ 如就绪队列就是一种内核程序临界区，访问的时候会上锁，但需要快速释放，如果进行进程调度会浪费时间 ​ 而打印机设备就是普通临界区，访问的时候也会上锁，但是使用这些资源的时候，CPU处于空闲状态，可以进行调度 原语：原子性不能被中断 2）切换过程 从就绪队列中选择一个进程，然后切换该进程： 保存原来运行进程的各种数据：保存现场 恢复选择的进程的现场：通过保存的数据恢复 8.批处理调度算法1）FCFS 先来先服务 https://www.scimall.org.cn/article/detail?id=4813361 2）SJF 短作业优先非抢占式： 抢占式： 注意： 非抢占式中每个进程一旦开始运行会运行到结束，期间如果有新的进程就绪也不会被剥夺处理机。而抢占式则是每当有一个新的进程进入等待队列就会动态计算剩余时间，会产生抢占现象 3）HRRN 高响应比优先 4）对比 9.交互式处理调度算法1）时间片轮转 时间片太大： ​ 会退化成先来先服务FCFS 时间片太小： ​ 导致频繁的进程切换，浪费系统资源 2）优先级调度算法抢占式和非抢占式的区别：前者在执行完一个进程后做判断（主动失去），后者在有新的进程进入就绪队列后就会做判断（剥夺） 抢占式： 非抢占式： 3）多级反馈队列 饥饿情况：持续有高优先级的短进程进入第1级队列，那么低级队列的进程就可能会饥饿。 4）对比 10.进程的同步和互斥1）进程同步​ 制约进程的执行顺序，无论整体顺序如何，吃饭一定要在洗澡的前面 2）进程互斥 临界资源： 进入区：给该资源上锁，保证其它进程无法访问到该资源 临界区：访问临界资源的代码 退出区：解锁 11.进程互斥的软件实现1）单标志法 ​ 缺点：但是若此时turn&#x3D;0，允许进程P0访问，但P0一直不访问，那么P1就无法访问，违反“空闲让进” 2）双标志先检查法 ​ 先检查他人意愿，再表达自己意愿flag ​ 缺点：违反忙则等待，两个进程都可能会进入临界区，因为检查 和 表达意愿 操作不具原子性，违反忙则等待 3）双标志后检查法 ​ 先表达自己意愿，再检查别人意愿 ​ 缺点：可能会导致双方都有意愿，双方都堵塞住进不了，违反空闲让进和有限等待 4）Peterson算法（结合了1 3） 先表达意愿，再谦让，然后判断对方是否有意愿且自己已经谦让了：该算法后谦让的会丧失执行权（改变了之前turn的值） 12.进程互斥的硬件实现 中断屏蔽： ​ 其实就是加入了开中断和关中断（类似原语）：若有多个CPU，那么中断屏蔽只能在一个CPU1上实现互斥，若在CPU2上有对该临界资源的访问，CPU1的约束无法生效；且关中断和开中断属于特权指令，只能运行在内核态，不能让普通程序使用，所以中断屏蔽的方法只适合操作系统的内核进程 TestAndSet和Swap指令： 实际逻辑都是检查是否上锁，若没上锁，自己再上锁：类似双标志先检查法，但硬件实现具有原子性，不用考虑并发 13.信号量机制信号量代表了某一资源的值，如int src代表了打印机数量，那么int src&#x3D;2，说明打印机有两台。 1）整型信号量 ​ ​ P、V操作使用了原语，保证了原子性，但仍然不满足让权等待，会发生忙等问题。 2）记录型信号量 忙等： ​ 当某进程访问资源，但是资源不够的时候，会进入while死循环，这时候无法访问资源但是仍然在占用CPU，所以会浪费CPU资源， 进入忙等状态。 为什么记录型信号量不会发生盲等？ ​ 定义的信号量数据结构中带有等待队列的指针，可以操作相应进程挂在等待队列上等待唤醒 ​ 因为在P（wait）操作的时，当信号量&lt;0，即资源数量不够后，该进程会主动进入阻塞态，让出CPU资源。 ​ 而当V（signal）操作的时候，判断信号量++后是否&lt;&#x3D;0，如果&lt;&#x3D;0，说明仍然有进程在等待资源，那么V操作会唤醒该进程。 14.信号量实现进程互斥和同步 前驱关系1）实现进程互斥 ​ 初始化互斥信号量&#x3D;1（说明该资源只有一个，只允许一个进程使用完后再还回去），进程A在进入区前P操作（申请一个资源并让资源-1，那么唯一的一个资源已经被占用）；进程B要想P申请一个，发现mutex&lt;0，资源没了，进入阻塞状态；进程A用完该资源后会通过V操作mutex++（还回该资源），并唤醒进程B。 2）实现进程同步 ​ 保证12 4相对顺序 初始化mutex&#x3D;0（相当于没有该资源），代码1和代码2的结果相当与生成了一个该资源，那么V(S)使mutex++，代表有了一个该资源，那么P(S)就可以获得该资源并执行接下来的代码。 ​ 若向先执行4，那么P(S)操作没有获得相应的资源，所以会执行block原语进入阻塞态无法执行，只有当12执行产生了对应资源S后才能继续执行，这样就保证了同步的相对 15.各类问题1）生产者和消费者问题 为什么要互斥：因为虽然容量为5，但是多个生产者进程可能会并发修改同一个地址的数据，这样就会导致数据覆盖。 full-&gt;目前产品数量 ，一开始数量要为0，生产者v生产并放入缓冲区+1，消费者才能从缓冲区p消耗取出一个。 empty-&gt;容器剩余容量，一开始数量要为5，生产者p消耗一个容量生产，消费者才能v获得一个产品。 ​ 生产者：先消耗一个容量P(empty)，生产一个产品并放入缓冲区，增加一个目前产品数量V(full) ​ 消费者：消费者先消耗一个目前产品P(full)，从缓冲区拿出一个产平，增加一个缓冲区容量，使用产品 ​ 实现互斥的P操作一定要在实现同步的P操作之后！！！ 2）多类生产者和多类消费者问题 本体可以不用互斥信号量，因为容量总共为1，若为2就不行 3）吸烟者问题 finish：这里也可以理解为桌子上剩下的容量，当吸烟者拿走组合后并吸烟后，容量就会+1，这时候生产者就能生成组合并放桌上 4）读者写者问题 写进程1和其它所有写进程和读进程都互斥，写进程之前需要所有进程的工作都结束 rw：保证读进程和写进程之间的互斥，count：记录有多少个读进程 ②：第一个进程获得文件资源后上rw锁，并使count+1，最后一个读进程读完后count–，并释放rw锁，唤醒写进程 ①：当两个读进程同时执行，这时候两个count都&#x3D;&#x3D;0，而此时读进程A P(rw)上锁，那么读进程2就会被rw锁阻挡，这是不对的 ​ 导致这个问题的原因是这段代码不是一气呵成的，所以可以加一个mutex锁，保证各个读进程在访问该段代码的时候是互斥的 注：以上实现有一个缺点，如果有无限读进程进入，那么写进程就会因为得不到rw锁而被饿死 再增加一个w变量，该变量来保证写进程不会被饿死 ​ 当读进程1 P(w)上锁，此时后来读进程和写进程都会因为w锁没被释放而被阻塞，按照先后顺序排列在一个阻塞队列中 （读进程2-&gt;写进程1），当读进程1在读文件前V(w)释放锁，这时候队首的写进程1就会获得该锁并会堵在rw锁…… w锁保证了 读进程和写进程是按照来的顺序 来获得操作文件的机会 rw：保证读进程和所有写进程之间的互斥 w：保证读进程和写进程按照来的顺序获得机会，不会因为大量读进程而被阻塞 mutex：保证rw上锁的过程一气呵成，不会导致多个读进程的堵塞，保证对count变量操作的互斥 5）哲学家进餐问题 三种解决方案： 16.管程 管程实际上就相当于一个类，成员变量就是需要加锁的对象，一组过程就是定义的函数 每次仅允许一个进程在管程内执行某个函数，编译器负责各进程互斥进入管程 17.死锁相关1）死锁、饥饿、死循环的区别 死锁：死锁是多个进程循环等待对方手里的资源而发生的，并且死锁的进程一定处于阻塞态，等待对方释放资源将自己唤醒 饥饿：可能只有一个进程发生饥饿，如短进程优先算法，如果一直有短进程进入，那么长进程就会发生饥饿 ​ 发生饥饿的进程可能是阻塞态，长期得不到I&#x2F;O设备 ​ 可能是就绪态，如长期得不到处理机 死循环：程序员编码导致 2）死锁发生的4个条件 ​ 互斥条件：对互斥资源的争抢才会导致死锁 ​ 不剥夺条件：各进程持有的资源不能被剥夺，只能主动释放 ​ 请求和保持条件：进程在吃持有别的进程想要的资源时，又在请求其他资源 ​ 循环等待条件：存在一种进程资源的循环等待链 注意： 发生了循环等待不一定发生死锁，如有第6个哲学家持有3号能用的筷子，虽然3在循环等待，但是6若释放则不会死锁：当有其它可替代资源的时候就未必发生死锁 3）死锁的处理策略 18.预防避免死锁1）破坏发生死锁的4个条件 2）银行家算法 安全序列：一个能满足所有进程资源需求的分配序列 不安全状态：当分配了某一些资源后，如果各进程不主动归还一些资源，那么系统有可能不能再满足接下来的资源分配而导致死锁 银行家算法： 银行家算法其实就是在分配资源的时候进行检查，看手上的资源能否满足剩下进程的最大需求，通过回收进程能够得到一条安全序列 19.死锁的检测和解除1）死锁的检测 实际上就是找到了一条安全序列 死锁检测算法：依次消除不阻塞进程相连的边，直到无边可消 2）死锁的解除 剥夺某进程资源（将进程挂起），将资源给其它进程 强制终止某些死锁进程，这样对运行快结束的进程可能代价很高 回退到某一步，可以避免死锁","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"操作系统笔记-文件和磁盘","slug":"4.操作系统-文件和磁盘","date":"2022-03-06T11:17:48.000Z","updated":"2022-06-23T10:30:08.666Z","comments":true,"path":"2022/03/06/4.操作系统-文件和磁盘/","link":"","permalink":"http://example.com/2022/03/06/4.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E6%96%87%E4%BB%B6%E5%92%8C%E7%A3%81%E7%9B%98/","excerpt":"操作系统+ . +","text":"操作系统+ . + 1.文件逻辑结构 1）无结构文件 无结构不文件中的数据就是一系列 二进制bit流 和 字符流，txt文件就是一系列 字符流 2）有结构文件 有结构文件中存储的是一条条数据，每条数据的各列可能是定长的，也有可能是不定长的 ①顺序文件 可变长记录： ​ 顺序存储无法随机存取，因为不像数组每一个[]的大小都是相等的 定长记录： ​ 串结构——对每一条记录都随机存储 ​ 顺序结构——按关键字存记录，添加删除都需要再重新调整 ②索引文件 由于不定长文件不能直接查找第i个记录，可以建立一张索引表来记录每条记录的地址 ③索引顺序文件 索引顺序文件是为了解决索引文件可能过大的问题： ​ 索引文件的每条记录记录的不再是单个记录地址，而是顺序的一组数据，如存储逻辑文件的前50个数据 多级顺序文件 我们可以建立多级索引进一步提高效率，类似于mysql中的B+树 2.文件目录（文件的逻辑组织方式） 1）FCB文件数据块 一个文件目录就是各文件FCB的集合，一个文件对应了一个目录项，也就是一个FCB，可以说一个目录中存储的就是FCB的集合 2）单级目录 整个操作系统只有一张目录表，存了所有FCB，所以文件不能重名 3）两级目录 两级目录中的主文件目录记录了各个用户文件目录，不同用户目录的文件可以重名 4）多级（树形）目录 多及目录中不同目录文件名可以重名 5）无环图目录 实际上就是允许了不同目录下的不同文件可以指向同一个地址，方便了文件的共享， 共享计数器记录了文件被几个用户共享了，只有当共享计数器&#x3D;0，每个用户都删除不需要后才会完全删除该文件 6）索引结点（FCB改进） FCB只存储文件名和指向其它结点的指针，其它所有信息都存储在索引结点中 3.文件保护 1）口令保护 相当于设置了一个密码，密码可能在FCB或索引结点中，打开时输入正确指令才能访问 2）加密保护 加密保护就是对原始数据按照一定方式加密转换成，要访问该文件的时候需要使用正确的方式解密，才能获得正确的文件数据。 3）访问控制 针对每个文件建立访问控制表，规定了各个用户的具体权限，也可以分组管理 4.文件共享1）基于索引结点的共享（硬链接） ​ 两个文件的索引结点指针指向同一个索引结点，当user1要删除该文件的时候，索引结点的count–，说明user1不再需要，但是user2还需要。只有当count&#x3D;0，没有人需要的时候才会真正删除该文件 2）基于符号链的共享（软连接） 对应的文件是link文件，link文件指向了如aaa文件，通过aaa来访问文件1，删除link文件不会导致 索引结点1的count– 其实就是windows中的快捷方式 5.文件的物理结构（非空闲管理） 该节主要是针对已为文件分配了磁盘块后，这些磁盘块的管理（组织方式），属于非空闲块（已分配块）的管理。 1）文件块（磁盘块） 类似于内存，磁盘也被划分成了一块一块的（一页一页） 2）连续分配 由于是连续分配，方便查找，但是不方便增删等拓展，顺序访问速度最快，但容易产生碎片 3）链接分配①隐式链接分配 FCB记录了起始块号和结束块号，每个磁盘块有指向下一个磁盘块的指针，拓展简单，不会产生碎片，查找的效率低 ②显式链接分配 不同隐式链接分配，显式链接中各个磁盘块没有指向下一个磁盘块的指针，所有的下一块信息存储在一张文件分配表中FAT， 每一个磁盘都有一张FAT表，开机时会读入内存并常驻内存 4）索引分配 逻辑块就是页面，磁盘块就是页框 索引表就类似于内存分配中的页表，一个进程对应一张或多张页表，一个文件对应一张或多张页表 ①链接索引 ​ 当一个文件的索引表较大，一个磁盘块存不了的时候，就可以存在多个磁盘块上，各个磁盘块用指指针相连，但是这样若需要访问最后一张索引表上记录的地址，那么就需要遍历其之前所有的索引表，效率较低 ②多层索引 ​ 多层索引方案就是分页存储中的多级页表方案，通过一级索引表来记录各个二级页表的地址，在通过二级索引表来查询逻辑地址对应的磁盘块地址 ​ 但这样有一个缺点，一个文件总共只有1KB，采用这种方式会查询三次 ③混合索引 顶级索引就是FCB对应的索引节点，如某一大文件A含几个小文件，A-1小文件只有8个磁盘块，只需要通过直接地址，2次查询就够了（访存2次），某个大文件A-3需要256*256个磁盘块，那么就可以建立二级间接索引，查询3次（访存4次）。 6.逻辑结构和物理结构回顾 ​ 用户存储的数组Stu[]，我们可以通过Stu[1]、Stu[2]这种方式来访问1、2号学生，在我们看来他们的地址是连续的，实际上他们的逻辑地址是连续的。在文件中他们的逻辑地址是数组连续存储的，但是我们需要将将这些文件分块存储在不同的磁盘块，把它们分配在不同的磁盘块，这是操作系统来解决的，这样他们的物理地址是不连续的，但对我们来说，我们可以通过其连续的逻辑地址来访问，而逻辑地址转化成物理地址的过程我们并不关心，这是操作系统需要解决的。 1——逻辑地址 5——物理地址 7.存储空间管理（空闲管理）文件的分配是指对一个文件，我们采用什么样的方式将这个文件的数据组织起来 文件的管理是指对磁盘中的空闲磁盘块，我们应该采用怎样的方式将其组织起来，方便管理 1）文件卷、目录区、文件区 文件卷：C、D、E盘就是一个个文件卷（逻辑卷） 目录区：每一个文件卷中包含了目录区，主要存储了FCB及超级块等用于磁盘存储空间管理的信息 文件区：存储数据的区域 2）空闲表法 空闲表法很类似内存管理中 连续分配管理方式中 的 动态分区分配 类似 空闲表记录了第一个空闲块的块号，并且记录了从该块开始的空闲块数量，如0、1号空闲，记录就是0 2：块号从0开始，有两块空闲 对于磁盘的回收主和动态分区分配类似： 3）空闲链表法①空闲盘块链 ​ 该方式就是将所有空闲的磁盘块连接成一个链表，操作系统记录了链头、链尾指针。 ​ 若某文件申请k个磁盘块，只需要卸掉k个node就行，并且修改操作系统所记录的联投、链尾指针。 ​ 回收的时候只需要将回收的磁盘块接在链尾即可，并且修改链尾指针。 ②空闲盘区链 空闲盘区链和空闲盘块链最大的区别就是，node不再是一个磁盘块而可能是好几块磁盘块组成的一个磁盘区。 同样，操作系统也记录了链头、链尾。 这个和空闲表法很相似，所以分配的方法也很相似。 回收的时候若周围有链表中存储的空闲区了，需要和该区合并在一起，如果没有则作为一个单独的空闲区挂到链尾 4）位示图法（常考） 位示图的每一个格子就代表了一个盘号，本例中1代表已分配，0代表空闲 每一行有0-15格子，16个空闲块0。第0行就是0-15地址块，第一行就是（1 * 16+0）- （1 *16+15）地址块 如31号地址块对应的位示图位置，31&#x2F;16&#x3D;1，31%16&#x3D;15，即第1行15号位置 如何分配：顺序扫描位示图，找到k个相邻或不相邻的0空闲块，算出盘块号并分配，填1 如何回收：计算出回收的字号、位号，在表中位置填0 5）成组链表法 文件卷（如C盘）的目录区记录了超级块，超级块在系统启动的时候需要读入内存并保证内存中的超级块与外存中的超级块数据一致 超级块实际上类似于一个链头，该链表的每个结点结构如下： ①代表了该组的第一个磁盘块，该磁盘块不用作数据存储，而是存储了下一组的磁盘块数量，并记录了下一组所有磁盘块的指针 ②出第一个磁盘块外的所有磁盘块都用作数据存储 eg：100个磁盘块，1个用于存储下一个组的信息，99个用于存储分配的信息 而超级块就是①，存储了第一个组的所有信息 如何分配： ​ 分配的时候若某一组的无剩余，那么需要将该组记录的下一组的信息，修改超级组的数据，因为分配是从前往后分配，而且每一组所挂磁盘块数是定好的 如何回收： 若每一组的限制是100块，当某一块挂的数据块不够99个的时候，直接挂在该组，若满了则作为一个分组并修改超级块的数据 8.文件的基本操作 1）创建文件 使用了“create系统调用” 需要的参数： ​ 申请的大小（盘块数量）、存放路径、文件名（有默认值） steps： ​ 1.在外存中分配所需空间（空闲管理） ​ 2.通过地址找到该目录的目录文件，根据信息创建对一个目录项FCB 2）删除文件 需要的参数： ​ 文件的存放路径、文件名 steps： ​ 1.通过文件的存放路径找到对应的目录文件，并通过文件名找到对应的目录项（FCB） ​ 2.通过FCB记录的索引结点找到对应的磁盘块，回收磁盘块 ​ 3.删除该FCB 3）打开文件 打开一个文件就是将目录文件中该文件的目录项FCB，复制到系统的的打开文件表中。 需要参数： ​ 文件的存放路径、文件名、对文件的操作类型(r、rw、rwx) steps： 1.通过文件存放路径找到对应目录文件，通过文件名找到对应FCB，检查该用户的权限 ​ 2.将目录项复制到内存的打开文件表中，并返回其在该表编号，用户打开该文件需要编号 打开文件表： 每个进程都有一张属于自己的打开文件表，系统中有一张打开文件总表，每个进程打开文件表会由指正指向，系统打开文件表的对应表项 ①读写指针记录了该进程对文件读写进行到的位置 ②访问权限限制了进程对文件的操作 ③每一个进程对应系统打开文件表的一个表项就会使打开计数器+1，只有当计数器为0才会删除该表项 ​ 打开计数器作用： ​ 如要删除一个文件，这时候该文件还在被打开，说明打开计数器!&#x3D;0，就会提醒该文件正在被使用，不能删除 4）关闭文件 某一个进程关闭该文件就会使系统的打开文件表中的打开计数器-1，当打开计数器的值&#x3D;0的时候删除该表项 5）读文件和写文件 ​ 各进程读写文件都可以从本进程的打开文件表中的该文件项的系统索引号找到其在系统打开文件表中的位置，并分别调用 read和write系统调用。 9.文件系统的层次结构 ①8.文件基本操作的知识：系统调用 ②2.文件目录的知识：根据提供的地址找到对应FCB ③3.文件保护的知识：验证访问权限 ④1.逻辑结构的知识：逻辑地址的处理 ⑤5.物理结构的知识：逻辑地址转化成物理地址 ⑥7.存储空间的知识：文件存储空间的分配和回收 ⑦：硬件设备的管理，磁盘的调度等 10.磁盘的基本知识1）磁盘、磁道、扇区 每个扇区的数据量是相等的，磁道就是一圈一圈半径不同的圆 2）读写数据 读写数据需要磁头定位到对应的磁道，磁盘spin的时候磁头滑过对应扇区就能完成读写操作 3）定位磁盘块 柱面号：对应多个盘面的半径相同的磁道 盘面号：某一盘面的编号 扇区号：找到对应盘面的某一扇区 4）一次磁盘读&#x2F;写操作所需时间 1.寻找时间： ①启动磁头臂的时间：物理因数决定 ​ ②移动磁头(寻道时间)：磁头臂移动到对应磁道的时间，可以设计算法改进 2.延迟时间 ​ 旋转磁盘到达对应扇区的时间 3.传输时间 ​ 对应磁盘块的数据读入写入的时间 11.磁盘调度算法（寻道时间） 该部分算法是用来解决寻道时间的 1）先来先服务（FCFS） ​ 按照请求到达的顺序进行移动，若磁道很分散，效率就会很低 2）最短寻找时间优先（SSTF） ​ 优先移动至与当前磁道最近的磁道（贪心，未必全局最优），若有不段近距离请求加入可能造成远距离磁道的”饥饿” 3）扫描算法（Scan） ​ 移动到最右侧才能向左侧移动，移动到最左侧才能向最右侧移动。到达最右侧慢慢想最左侧移动 4）Look调度算法 ​ 和扫描算法相似，最大的不同就是不用移动到最右侧才想左搜索，在移动到184后观察到最左边已经没有请求了，那么直接想左移动 5）循环扫描算法（C-SCAN） ​ 循环扫描算法和扫描算法最大的不同就是到达最右侧以后，不再是一步一步从右侧往左侧扫描，而是立马到达最左侧，中途不处理任何请求，从最左侧往右扫描 ​ 6）C-Look调度算法 ​ C-Lool算法对循环扫描算法的最大改进就是往右扫描的时候不需要到达最右边，到达184后观察到左边已经没有请求了，那么就直接到最左边的一个请求18，而不是最左边的0号磁道 12.延迟时间 若2、3、4逻辑上是连续区域，物理上也设计为连续区域的话是不合适的。 ​ 因为当磁头读取完一个扇区中磁盘块的内容以后，需要一段时间处理，而盘片在不断旋转，那么读取完2后，3就无法马上读取，而是要等待再spin一圈后才能读取 1）交替编号 交替编号可以解决等待磁头臂处理时间的问题，这里还有一个问题 ①为什么磁盘物理地址是 （柱面号，盘面号，扇区号）？（柱面号，盘面号，扇区号）：（000，00，000 ）~（000，01，111） ​ 这样两个相邻的地址，他们的扇区号虽然不同，但是他们的柱面号都是00，说明他们的都是00，01盘面的00号磁道，磁头臂不用移动 ​ 即这两个相邻地址的柱面号都是相同的，不用移动磁头臂（不消耗物理时间） （盘面号，柱面号，扇区号）：（000，00，000 ）~（000，01，111） ​ 这样两个地址都是在同一盘面上，但是柱面号不相同，所以需要移动磁头臂 2）错位命名 ​ 假设：两盘的对应扇区都是相对的0-0,1-1（vertically） ​ 当第一个盘面读取完第0盘0号磁道第1扇区数据后，刚好走到需要读的第1盘的0号磁道第2扇区开头，但是因为磁头臂需要一定时间处理数据，那么第1盘的0号磁道第2扇区就需要第二次spin到的时候才能读取，那么这种方式就是不对的，我们需要扇区编号在vertically 上错开 13.磁盘的管理 1）磁盘的初始化 step1： ​ 划分扇区，扇区可分为头、数据区域、尾，尾部存有FAT ​ FAT：每个磁盘独有的，FAT记录了该磁盘中磁盘块的 物理块号 和 下一块地址 2）引导块 ​ 计算机开始要执行一系列初始化工作（执行自举程序），ROM中存储的数据是不能改变的，开机先启动ROM中的自举装入程序，执行该程序后会找到磁盘启动块中存储的完整的自举程序（可以修改）完成初始化。 3）坏块的管理 坏块的处理： ①FAT上表明，对操作系统不透明（操作系统知道哪些是坏块） ​ ②保留一些备用扇区，这些扇区来替换坏块，对操作系统透明（操作系统并不知道哪些是坏块）","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]}],"categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://example.com/categories/Spring-Boot/"},{"name":"mysql","slug":"mysql","permalink":"http://example.com/categories/mysql/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"},{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://example.com/tags/Spring-Boot/"},{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"},{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]}